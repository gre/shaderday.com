_N_E=(window.webpackJsonp_N_E=window.webpackJsonp_N_E||[]).push([[15],{"+bvG":function(e,n,t){"use strict";t.r(n),n.default=""},"/41s":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Noisy fibers"\nthumbnail: /images/plots/117.jpg\ndescription: "Exploration of fibers with a centered noise. two color tones."\ntags:\n  - fibers\n  - perlin\n---\n\nAnother exploration of [plots#112](/plots/112), more delicate than [plots#115](/plots/115), with a centered noise of fibers. It uses two fountain pen inks for different color tones (Aurora Borealis and Writer\'s Blood from Diamine). I could try with even more lines in future but these are already almost 2 hours of plotting time! A4 on Bristol.\n'},"/HDy":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Hack-a-plot avatar hatching 1"\nthumbnail: "/images/plots/172.jpg"\ndescription: "Plots made during an internal Hackathon at Ledger using profile picture, hatching and contouring techniques."\ntags:\n  - contour\n  - hatching\n---\n\nPlots made during an internal Hackathon at Ledger using profile picture, hatching and contouring techniques.\n\nhttps://opensea.io/collection/ledger-nft-hackathon-team'},"/vfr":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Promisify your games\'\ndescription: \'a game showcase using Q Promise as first-class citizen and driven with CSS3 Animations via Zanimo.\'\nthumbnail: /images/2014/01/ld28.png\nauthor: Gaetan\nlayout: post\ntags:\n - gamedev\n - promise\n - Q\n - ludumdare\n---\n\n [promise]: /2013/07/q-a-promise-library/\n [ld]: http://www.ludumdare.com/compo/\n [game]: http://greweb.me/ld28/\n [qimage]: https://npmjs.org/package/qimage\n [qajax]: https://npmjs.org/package/qajax\n [submission]: http://www.ludumdare.com/compo/ludum-dare-28/?action=preview&uid=18803\n [zanimo]: https://github.com/peutetre/Zanimo\n [npmjs]: https://npmjs.org/\n [github]: https://github.com/gre/ld28\n [app.js]: https://github.com/gre/ld28/tree/master/src/app.js\n\nOne month ago was the [LudumDare][ld] #28 gamejam theming *"You Only Get One"*.\n\n<a href="http://greweb.me/ld28/">\n  <img src="/images/2014/01/ld28.png" alt="" class="thumbnail-left" />\n</a>\n\nI [submitted][submission] a [mini-game][game] which ranked 105th out of 2064 entries and also 26th in the "theme" category.\n\nThis is of-course a web game implemented in JavaScript and using HTML and CSS.\n\nBut actually, my main goal was not really making a game done \nbut more about technically **making a state-of-the-art Promise-based game**.\n\nI think [Promises][promise] contains very interesting advantages in a game development design:\n*Resource loading managment*, *game scenes chaining*, *animations*... are some use-cases.\n\n\n* Checkout the [source code][github] on Github - [`src/app.js`][app.js] is the entry point\n* LudumDare entry is [here][submission].\n* [Play the Game][game].\n\n\n\x3c!--more--\x3e\n\n## FP in game development\n\nUsing some Functional Programming paradigm in game development is interesting,\nand here I\'m just talking at least about the basic stuff:\n**Avoid globals, Minimize state variables**.\n\nI\'ve written a few games where restarting the game without using `location.reload()` was a challenge\nbecause the game variable states was so spread everywhere!\n\nBy doing more FP, you can have this restart feature by design without need to "reset" all variables\nbecause your start function just takes everything it needs in parameter and restarting is just about re-calling that function.\n\n## Promises as first-class citizen\n\n### Game scenes chaining\n\nLike maybe 99% of games, my game has an **intro** (menu), a **main** scene and an **outro** scene (gameover / finish).\n\nWhen you develop a game with just one big `render()` loop,\nit easily becomes a pain when you want to add more steps to the scene,\nit doesn\'t scale and fastly become spaghetti code:\nyou tend to have to figure out in which state you are (or which part of the animation timeline) from the game state.\n\nHopefully, scene management is very easy to do with Promises:\n\n```javascript\nfunction start () {\n  return Q()\n    .then(intro)\n    .then(_.partial(runMiniGames, 20))\n    .then(outro);\n}\n\nQ.all([/*..something to load..*/])\n .then(start/*, ..*/) // start game when ready\n .done(); // just help Q to trigger errors if some.\n```\n\nHow beautiful to read! Call `intro` then run 20 mini-games then perform `outro`.\n\n#### No game state shared, pure functions\n\n**intro** is the menu screen where you can choose the game difficulty.\n**outro** is the game end screen where the final score is displayed.\nThere is however **no global variables shared**, those are just passed from one function to another.\n\nLet\'s look deeper in how it works:\n\n* The `intro()` function just returns a Promise resolved when the user made a "difficulty" choice. That Promise actually contains the difficulty (0, 1 or 2).\n* The `runMiniGames` function takes 2 parameters: the number of games and the difficulty. `_.partial(runMiniGames, 20)` is just an helper for making a 20 mini-games function which takes the difficulty in parameter. This difficulty is given by the previous Promise. The `runMiniGames` function returns a Promise of Score (integer).\n* That score is then fed into the `outro(score)` function which displays this score to the user.\n\n> **TL;DR.** This is just about plumbing 3 functions together!\n\nCheckout also the [`runMiniGames` implementation](https://github.com/gre/ld28/blob/master/src/app.js#L24-L37).\n\n#### Speed up the development\n\nAnd you know what? It make development easier and faster because you can easily skip some part in any Promises chain:\n\n```javascript\nfunction start () {\n  return Q(0)\n    //.then(intro) // Directly jump to the games\n    .then(_.partial(runMiniGames, 20))\n    .then(outro);\n}\n```\n\nI used that a lot and not only for this part, but for all part during the game development.\n\n\n### Loading resources\n\nPromises also help you to wait resources before starting the game.\nYou don\'t have to make yet another loading library, Promise already are ready for that, \nand you can also have proper error managment or even "progress" loading display (Q has Progress event in a Promise).\n\nEach loading resource is a Promise and you can combine them all using `Q.all`.\n\nHere is an example using [Qajax][qajax] and [Qimage][qimage].\n\n```javascript\nQ.all([\n  Qajax("music.wav").then(mapToAudio),\n  Qajax.getJSON("map.json"),\n  Qimage("images/logo.png"),\n  Qimage("images/textures.png")\n]).spread(function (music, map, logo, textures) {\n  \n  // Start the game !\n\n}, function (error) {\n\n  // display proper error\n\n}, function (progressEvent) {\n\n  // maybe you want to display a loading progress bar \n  // with that third progress callback.\n\n});\n```\n\nHere is a similar example:\n\n```javascript\nvar musicPromise = Qajax("music.wav").then(mapToAudio);\nvar mapPromise = Qajax.getJSON("map.json");\nvar texturesPromise = Qimage("images/textures.png");\nQ.all([ mapPromise, texturesPromise ]).spread(startGame, errorLoading);\n// because maybe you don\'t want to wait the music for starting the game:\nmusicPromise.then(function (a) { a.play(); });\n\nfunction startGame (map, textures) {\n  // ...\n}\nfunction errorLoading (e) {\n  // ...\n}\n```\n\n### Mini games workflow\n\nMy games is divided into a set of mini-games which are all independent but share a common interface.\nThis interface was quite a WIP at the end of the weekend development but it does the job.\n\nHere is the template I used for my game: [src/games/\\_template.js](https://github.com/gre/ld28/blob/master/src/games/_template.js).\n\nA Game instance has different methods, and especially `enter` and `leave` method which are call on game enter and on game leave. It also has a `.end` Promise which is resolved when the Game end.\n\n* A mini-game when solved gives a score depending on how well the user succeed it (through the `end` Promise).\n* A mini-game have a timeout and if the player doesn\'t terminate it, it passes to the next game without scores.\n\nThose `enter()` and `leave()` methods return Promise in order to be plugged in the game workflow (we can wait them to finish before moving to next state).\n\nFor instance, we don\'t start the game timeout before it actually starts (just wait the `enter()` Promise to be resolved) and also we don\'t switch to the next game before the `leave()` Promise is done).\n\nCheckout also the [`nextMiniGame` implementation](https://github.com/gre/ld28/blob/master/src/app.js#L51-L76).\nThe result of that function is the score of the mini-game and that we sum up all scores from the previous score.\n\n#### Composability\n\nThe `enter()` and `leave()` methods can be composed of animations which can themselves be composed of animations.\n\n**We can easily subdivided work into different level of Promises chain.**\nHere is a little schema to summary that composability:\n\n![](/images/2014/01/ld28_composition_schema.svg)\n\n### Promise Animations\n\nIn my game, all the animations are controlled with Promises more exactly using CSS3 Transitions \nvia **[Zanimo][zanimo] Promise library** because it fits my game (DOM-based game).\nThe fact that a Promise can be waited and chained **gives a powerful controls over CSS Transitions for making animations**.\n\nYou can easily trigger animations **one after another** for moving an element in multiple places.\nYou can also perform **multiple animations at the same times** (on 2 different elements) and **wait for both to finish**\nbefore triggering a third animation.\n\nSee for instance how `enter()` and `leave()` animations are done in mini-games.\n\nIn the animation ending the "memo" game I used concurrent animations:\nall memo cards are randomly moved out.\n\n```javascript\n/* // FYI\nCard.prototype.transform = function (x, y, scale, duration) {\n  return Zanimo.transition(this.el, "transform",\n    "translate("+x+"px, "+y+"px) scale("+scale+")", duration||0);\n};\n*/\n\nfunction animateOut (dispersion) {\n  return Q.all(_.map(cards, function (card) {\n    if (card.destroyed) return Q(); // no animation because card is destroyed\n    return Q()\n      .then(function(){\n        return card.transform(card.x, card.y, card.number === 1 ? 1 : 0.8, 100);\n      })\n      .delay(Math.floor((card.number===1 ? 500 : 0)+300*Math.random()))\n      .then(function () {\n        var x = Math.round((Math.random()<0.5 ? -card.w/dimensions.width-dispersion*Math.random() : 1+dispersion*Math.random())*dimensions.width);\n        var y = Math.round((Math.random()<0.5 ? -card.h/dimensions.height-dispersion*Math.random() : 1+dispersion*Math.random())*dimensions.height);\n        return card.transform(x, y, 0, 500);\n      });\n  }));\n}\n\n// Usage in Memo.leave() :\nreturn Q.delay(50)\n  .then(function(){ return animateOut(0.5); })\n  .delay(100);\n```\n\n\nIn the calculation game I used a chain of animations subdivided in functions:\n\n```javascript\nreturn Q.delay(50)\n  .then(fadeOutInvalids)\n  .then(displaySolution)\n  .then(displayEquality)\n  .delay(500)\n  .then(fadeOut)\n  .then(hideEquality)\n  .delay(200);\n```\n\n[Full code here](https://github.com/gre/ld28/blob/master/src/games/calculation.js#L411-L500).\n\n### "Wait for next click"\n\nWhile my game are just based on click user interaction,\nI\'ve made a [`waitNextClick`](https://github.com/gre/ld28/blob/master/src/waitNextClick.js) function\nwhich returns a Promise of click for the given element.\n\n```javascript\nvar Q = require("q");\n\nmodule.exports = function waitNextClick (btn) {\n  var d = Q.defer();\n  btn.addEventListener("click", function listener (e) {\n    btn.removeEventListener("click", listener);\n    d.resolve(e.target);\n  }, false);\n  return d.promise;\n};\n```\n\nThis was quite an interesting solution which is just like a jQuery "once" event but in Promise paradigm.\n\nI was able to combine that function with `Q.race` which wait for one of the given Promise to be redeemed.\n\n> `Q.race(_.map(btns, waitNextClick))`\n\nFor instance in the cats game, I just wait the first "This one" button to be clicked:\n\n```javascript\nvar houseChoice = Q.race(_.map(this.houses, function (catHouse) {\n    return waitNextClick(catHouse.btn)\n    .then(function () {\n      return catHouse;\n    });\n// houseChoice is a Promise of House choosen by the player.\n```\n\n### Using the "progress" event\n\nI also used a bit the "progress" event of a Q Promise, which is a way to notify that a Promise is being resolved.\n\n* I used that "progress" event on the `game.end` Promise for notifying that the player is winning some scores in a mini-game while playing.\n* I also used it to make a timeout ticking the remaining time before the timeout is reached and that Promise resolved.\n\nSee both usages [here](https://github.com/gre/ld28/blob/master/src/app.js#L62-L70):\n\n```javascript\nreturn Q.race([\n  gameEnd\n    .progress(function (score) {\n      stats.setScore(totalScore+score);\n    }),\n  timeoutWithTicks(gameEnd, timeout)\n    .progress(stats.setTimeProgress)\n    .then(_.bind(game.submit, game))\n]);\n```\n\n## Code organization using NPM + Browserify\n\nNPM & Browserify has also been used because I find this stack very productive,\nespecially when writing a game from scratch.\n\nBrowserify has been trendy the last past year, but there is here an interesting way of organizing your code\nand especially reusing it.\nYou can find a lot of [available modules using NPM][npmjs], \nBrowserify will just make you able to require them using `require("modulename")`.\n\n'},0:function(e,n){},"0JaZ":function(e,n,t){"use strict";var a=t("pYlj");e.exports=a},"0RtR":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "brushed ball"\nthumbnail: /images/plots/142.jpg\ndescription: "A reboot of the \'wool ball\' done with 2 pen brushes."\n---\n\nA reboot of the \'wool ball\' done with 2 pen brushes.\n\nAlso had another try:\n\n<img src="/images/plots/142bis.jpg" width="100%">\n'},"0dpp":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Orange"\nthumbnail: /images/plots/148.jpg\ntags:\n  - perlin\n  - parametric\n---\n'},"0hcx":function(e,n,t){"use strict";t.r(n),n.default="---\ntweet: https://twitter.com/greweb/status/1382769606591459332\ntags:\n  - lines\n---\n"},"0mXd":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Panzer Dragoon 1k\'\ndescription: \'Panzer Dragoon 1k is a 2D remake of Panzer Dragoon in 1k of JavaScript I made for JS1K 2014\'\nthumbnail: /images/2014/03/js1k.png\nauthor: Gaetan\nlayout: post\ntags:\n - gamedev\n - js1k\n - javascript\n - canvas\n---\n\n[demo]: http://js1k.com/2014-dragons/demo/1790\n[source]: https://gist.github.com/gre/9504494\n[jscrush]: http://www.iteral.com/jscrush/\n[jscrush-npm]: https://github.com/gre/jscrush/\n[demojs]: http://demojs.org/\n[js1k]: http://js1k.com/\n[p01]: http://www.p01.org/\n\n[<img src="/images/2014/03/js1k.png" alt="" class="thumbnail-left" />][demo]\n\nThis article introduces my journey into the JS1K world\nand a few tricks I\'ve used for my entry ["Panzer Dragoon 1k"][demo] ([source][source]).\n\nWelcome to the world of hacks, tricks and getting-things-done-at-any-price.\nYou will turn the worst JavaScript practices and ugliest JavaScript facts to your advantage.\nWelcome to the world where coding the bad way is satisfying!\n\nPanzer Dragoon 1k\n---\n\n- **[Play the JS1K entry][demo]**\n- [Source Code][source]\n\nPanzer Dragoon Original Game\n---\n\n<iframe width="640" height="480" src="//www.youtube.com/embed/peoRBj9U-jI" frameborder="0" allowfullscreen></iframe>\n\n\x3c!--more--\x3e\n\nJS1K\n===\n\n**[JS1K][js1k]** is a competition where you have to make a demo (or a game, or anything)\nin less than **1 kilobytes** of JavaScript: **less than 1024 characters of source code**.\n\nTo reach that goal you will need ideas, JS ninja tricks \nand most important: **patience and perseverance**!\nBut really, **anyone can participate**.\n\nI recommend that you take a look at [js1k.com][js1k] and browse the existing entries.\nThere is awesome guys participating to this yearly event,\nI had the chance to meet some of them at [DemoJS 2013][demojs] Paris event.\nAlso checkout [www.p01.org][p01] which contains some very good examples of crazy short demos.\n\nTools\n---\n\nBut first things first: you need tools to minimize source code (it can simply be removing comments and spaces, minifiers, or it can be much more crazy tools like crushers).\n\nPersonally, I\'m using:\n\n```bash\ncat source.js | uglifyjs -c unused=false | tee minified.js | jscrush > crushed.js && wc -c *.js\n```\n\nThis small homemade command (to use in a npm script) results for my game in:\n\n```\n    1019 crushed.js\n    1756 minified.js\n    7241 source.js\n```\n\nIf you are interested, I\'ve made this toolkit available in a complete boilerplate \nthat you can easily fork for your own usage: \n[https://gist.github.com/gre/9364718](https://gist.github.com/gre/9364718).\n\n> **P.S.** [`jscrush`][jscrush-npm] is a npm module that you can directly use from the CLI \nbut it is a port of the awesome [www.iteral.com/jscrush/][jscrush].\n\nThe beginning: Saving bytes\n===\n\nIt quickly becomes frustrating to compete in JS1K\nbecause you are basically trying to put a cow in a car (or an elephant if you are ambitious!).\nBut this frustration actually becomes addictive!\n\n**Saving bytes** is your job - once you get your first working prototype, and inevitably blow your byte limit.\n\nWhen you reach that limit, a good idea is to practice an **"add feature -> remove code"** development loop \nthat really makes you think hard about your ultimate goal, and helps improve your entry.\n\n> **The JS1K-based development:**\n> Adding more and more features,\n> figuring out how to fill everything in,\n> re-thinking your demo to only keep the essential features.\n> This will keep making your demo better.\n\nYou have to make a very hard choice: ***Which feature to remove?***\nIt is all about budget, not in term of money but in term of bytes!\nA bit like in daily life: making choices with limited resources!\n\nJSCrush\n---\n\n***JSCrush*** is a crazy tool you may want to use to go deeper in the bytes reducing.\n\nIt basically implements a compression algorithm which is based on substring occurences.\nThe challenge of such a tool is not only to make a good compression but to make \na very small decompressor embedded in the result code because \nthis decompressor might be an overhead *(~ +60 bytes with small code)*.\n\nIf you are using *JSCrush* which I recommend for saving extra bytes,\nyou may want to use some tricks to go even further with it!\n\nThe first time, you usually can save about 20% of bytes with classic 1k minified code.\nBut if you optimize your code **for** *JSCrush*, you can save much more!\nI\'ve achieved about a 40% code reduction in my demo!\n\nMost of the tricks is about finding code patterns (same succession of JavaScript source code characters) \nand trying to duplicate them.\n\nWhen I say **duplicating code**, it is really about **DUPLICATING code!**\n\n> Once "indexed", a duplicated code is likely to just take one more byte in the final crushed JavaScript!\n\nSome tips and tricks\n===\n\n[<img src="/images/2014/03/js1k_2.png" alt="" class="thumbnail-right" />][demo]\n\nThis section will share with you a non-exhaustive list of tricks.\nI\'m not going to talk so much about the basic and classic ones, \nbut a few novel ones that I found to work well in my entry.\nYou may prefer to directly read the [annotated source code of "Panzer Dragoon 1K"][source] instead!\nOf course, most of those tricks work closely with the `| minify | jscrush` transformation.\n\n> Careful! Some tricks might be counter-intuitive as first glance, \n> again it ties-in with the way JSCrush is working.\n\nReduce your language\n---\n\nAll existing functions and properties are costly in bytes,\neach time you use another one, it definitely add bytes.\nTo save bytes, you have to limit your set of functions/properties to use\nor find ways to access them indirectly.\n\n  - **Use as few variables as you can**: this is valid in computer science in general: the best systems are those with the fewest possible variables (states). if one variable can be computed out of others, it should be removed. Also consider allocating some temporary variables to re-use like in an assembly registry (e.g. `i`, `j`).\n  - **Reduce the set of functions** you authorize yourself to use! You may just need to use "fillRect" for everything, or "arc". Also don\'t use both `Math.min` and `Math.max`, one can be implemented with the other.\n  - **Minimize the different values / colors** you are using (most of the time digits are fine, but `#RGB` colors are costy).\n\nDuplicated wins!\n---\n\n- Generally: try to **duplicate the exact same code everywhere**!\n\n- **Do not use explicit aliasing** like `M=Math` and `C=M.cos`, JSCrush does that job for you.\n- **Get rid of intermediary computation.** Prefer inline and duplicated computation over variable assigment.\n- Also, `a*(b+c)` might be more bytes than `a*b+a*c` if `a` is an expression. (but doesn\'t work in all cases)\n\n**A few examples:**\n\n```javascript\na = b+c; translate(a, a); // NOPE!\ntranslate(b+c, b+c); // YES!\n```\n\n```javascript\nsize = a+b+10; fillRect(x-size, y-size, 2*size, 2*size); // no please don\'t!\nfillRect(x-(a+b+10), y-(a+b+10), 2*(a+b+10), 2*(a+b+10)); // YEAH!\n```\n\n```javascript\nfillRect(10,10,20,20);\n...\nfillRect(9,9,18,18); // Can you afford to use 10,10,20,20 instead?\n```\n\nIn my demo, I was able to factorize some code. For instance the way I draw and update the x,y of my opponents and particles are the same duplicate chunk of code:\n\n```javascript\n    bga();\n    arc(\n      // Update\n      e[0] += e[3],\n      e[1] += e[4],\n      e[2],\n      0, 9);\n    fl();\n```\n\n- You sometimes can **save bytes by adding more code**! For instance, if you need `fillStyle` and `strokeStyle`, it may save bytes to always set both color at the same time! `fillStyle = strokeStyle = ...` even if you only need once.\n- Always **use the same `function parameters`**. In my game, I use `function(e){` everywhere even if I don\'t use that `e` in all my functions. This is saving a bunch of bytes with JSCrush.\n- **Here\'s a particularly crazy trick:** If you have different collections of complex objects, you can simply represent each item by a vector (an array) and figure out how you can make use the same indexes for the use-case.\n\nIn my game:\n\n```javascript\no = []; // an opponent: [ 0: x, 1: y, 2: health, 3: vx, 4: vy, 5: locked, 6: hitTime ]\np = []; // a particule: [ 0: x, 1: y, 2: size,   3: vx, 4: vy, 5: damage ]\n```\n\n- You also may find better way of managing collections. Instead of using `t.push(o)` to add, `t.splice(i, 1)` to remove, and `for(i=0;e=o[i];i++){...}` to iterate. I am using `t[Math.random()]=o` to add, `delete t[i]` to remove and `for(i in o){ e=o[i]; ... }` to iterate. It saved a lot of bytes if you already use `Math.random()` somewhere else! For-in loops are also quite short and can by used for other tricks (e.g. *Programmatical aliasing*).\n\n<blockquote class="twitter-tweet" lang="fr"><p>My <a href="https://twitter.com/search?q=%23js1k&amp;src=hash">#js1k</a> uses `t[Math.random()]=insert`, for-in loops and `delete t[i]` rather than push and splice. Saving bytes with jscrush</p>&mdash; Ga\xebtan Renaudeau (@greweb) <a href="https://twitter.com/greweb/statuses/439324052403277824">28 F\xe9vrier 2014</a></blockquote>\n\n\n- Use just **one letter variable names** (mangling variables won\'t work because they are in window scope, and IMHO it is better for you to write them by hand)\n- You will probably need to **initialize some variables**, but do it only if necessary (if you have `ReferenceError`) and **use the multi-assignment syntax**: `A = B = 0` if you can. You should never have constant variables, it saves bytes to directly use the value inline.\n- **`with(c){ ... }`** in your main loop may save bytes. It makes all functions and properties of c (the drawing context) in the scope.\n\nLanguage tricks\n---\n- **Never use `var`**, just put everything in `window`\n- **Programmatically aliasing `c`\'s method** may save you a lot of bytes (or may not, you have to check!). You also have to find the code which suit the best your use case. Be careful about collision. Here is mine: `for (e in c) c[e[0]+e[2]+(e[6]||"")] = c[e];`\n- Do not waste ANY value returned by assignment and operators (i++, x=.., x+=...). I\'m sure you can do it somewhere else!\nTypical example:\n\n```javascript\nx += vx; y += vy; /* ... */ fillRect(x, y, s, s); // NOPE!\n/* ... */ fillRect(x += vx, y += vy, s, s); // YES!\n```\n\n- Try to not separate update from drawing logic. Mixing them may save bytes.\n- You don\'t want to use `addEventListener`, just define listeners straight on window! e.g. `onclick = function(){...`\n\nMake your JS1K now!\n---\n\n[<img src="/images/2014/03/js1k_3.png" alt="" class="thumbnail-left" />][demo]\n\nI\'m really eager to see all JS1K entries \nbecause I usually enjoy reading people\'s code and \nespecially all the crazy tricks that I can learn from your code :-)\n\nThis article was just sharing a bunch of tricks which work for my entry,\nbut you will find much better tricks for your demo -\nso please do it and make your crazy work!\n\n\n---\n*Special thanks to [@mrspeaker](http://twitter.com/mrspeaker) for fixing my English*.\n'},"0tIW":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "ink drops in square spiral"\nthumbnail: "/images/plots/139.jpg"\ndescription: "I used a dropper to drop some ink on a canvas while the plotter was running."\ntags:\n  - inkdrop\n  - spiral\n---\n\nI used a dropper to drop some ink on a canvas while the plotter was running.\n\nIt it the best opportunity to use the glitter ink which have great effect:\n\n<img width="100%" src="/images/plots/139.gif">\n\nThis is really hard to master and very unpredictable. I tried many different ideas:\n\n<img width="100%" src="/images/plots/139b.jpg">\n<img width="100%" src="/images/plots/139c.jpg">\n<img width="100%" src="/images/plots/139d.jpg">\n<img width="100%" src="/images/plots/139e.jpg">\n<img width="100%" src="/images/plots/139f.jpg">\n<img width="100%" src="/images/plots/139g.jpg">\n'},"0wZB":function(e,n,t){"use strict";t.r(n),n.default=""},"11Sj":function(e,n,t){"use strict";t.r(n),n.default=""},"1Hz/":function(e,n,t){"use strict";t.r(n),n.default=""},"1UPy":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "glsl.js, a Javascript + GLSL library = DRY & efficient"\ndescription: WebGL is super powerful and efficient. This library abuses this power for efficient 2D.\nthumbnail: /images/2013/02/glsl_mario.jpg\nauthor: Gaetan\nlayout: post\npermalink: /2013/02/glsl-js-a-javascript-glsl-library-dry-efficient/\ntags:\n  - gamedev\n  - javascript\n  - library\n  - GLSL\n  - WebGL\n---\n\n[2]: http://gre.github.io/glsl.js/examples/balls\n[3]: http://gre.github.io/glsl.js/examples\n[4]: http://gre.github.io/glsl.js/docs\n[5]: http://github.com/gre/glsl.js\n[6]: http://gre.github.io/glsl.js/test\n[7]: http://gre.github.io/glsl.js/examples/pong/\n[8]: http://glsl.heroku.com\n[13]: http://gre.github.io/glsl.js/examples/helloworld\n[15]: http://www.khronos.org/registry/gles/specs/2.0/GLSL_ES_Specification_1.0.17.pdf\n[16]: http://glsl.heroku.com/\n[24]: http://gre.github.io/glsl.js/examples/canvas-text/\n[25]: http://gre.github.io/glsl.js/examples/video/\n[26]: http://gre.github.io/glsl.js/examples/mario_sprites/\n\n[![glsl_mario](/images/2013/02/glsl_mario.jpg)][2]\n\n**TL;DR. WebGL is super powerful and efficient. This library abuses this power for efficient 2D.**\n\nglsl.js is a subset of a WebGL library which focuses on making the GLSL (OpenGL Shading Language) easy and accessible for vizualisation and game purposes (2D or 3D).\n\n- **[Bouncing balls example video tutorial][2]**\n- [Open other examples][3]\n- [API Documentation][4]\n- [Fork me on Github][5]\n- [Unit tests][6]\n\n[![glsl_pong](/images/2013/02/glsl_pong.jpg)][7]\n\n## Why?\n\n**WebGL is a very low level and stateful API**. Actually the WebGL API **is** the OpenGL API.\n\nI wanted to make a graphic library where you wouldn\u2019t have to know about this API but still have access to the powerful OpenGL Shading Language called GLSL.\n\nDo you know [glsl.heroku.com][8]? It\u2019s a cool platform for demoscene where you can experiment some nice effects in GLSL. My library extends this concept of rendering in one whole fragment shader (which takes the plain canvas) but also provides a way to inject your own Javascript variables.\n\n### DRY\n\n**WebGL is not DRY at all**, you always have to repeat yourself both on the GLSL and on the Javascript part (especially for synchronizing variables).  \nWorse than that, you have to know in your Javascript code what are the GLSL types of every variable to synchronize.\n\nHow boring is that:\n\n```javascript\n// Synchronizing the new values of 2 variables in pure WebGL.\n\nvar myInt = 1;\nvar myIntLocation = gl.getUniformLocation(program, "myInt");\nmyInt;\ngl.uniform1i(myFloatLocation, myInt); // 1i means one integer\n\nvar myVector2 = { x: 1.3, y: 2.4 };\nvar myVector2Location = gl.getUniformLocation(program, "myVector2");\ngl.uniform2f(myVector2Location, myVector2.x, myVector2.y); // 2f means float[2]\n```\n\n**glsl.js** provides a DRY and simple way to synchronize Javascript variables.\n\nFirst, the library will handle for you the UniformLocations.\n\nMore important, and unlike the WebGL API and many WebGL libraries, **you will never have to define the type of your variables from the Javascript with glsl.js!** You just define it once in your shader!\n\nHow it works behind is the framework will statically parse your GLSL and infer types to use for the synchronization. The right `gl.uniform*` function is called by Javascript reflection.\n\nIt now simply becomes:\n\n```javascript\n// Set the values of 2 variables in glsl.js\nthis.set("myInt", 1);\nthis.set("myVector2", { x: 1.3, y: 2.4 });\n// ... see also this.sync() and this.syncAll()\n```\n\n\x3c!--more--\x3e\n\nMore technically, **glsl.js** is a subset\\* of a WebGL library which focus on **making the GLSL (OpenGL Shading Language) easy and accessible** for vizualisation and game purposes (2D or 3D).\n\n> \\* Subset, because we only focus on using a _fragment shader_ (the _vertex shader_ is static and take the full canvas size), But don\u2019t worry, you have a long way to go with just one _fragment shader_.\n\nThe concept is to split the **rendering part in a GLSL fragment** from the **logic part in Javascript** of your app/game. Both part are linked by **a set of variables** (the state of your app/game).\n\n![schema](https://f.cloud.github.com/assets/211411/133026/5ed79ff8-709b-11e2-85dd-60332f74dc31.png)\n\n**glsl.js** aims to abstract every GL functions so you don\u2019t have to learn any OpenGL API.  \nWhat you only need to care about is the logic in Javascript and the rendering in GLSL.\n\nBy design, **you can\u2019t mix logic and render part**, this approach really helps to focus on essential things separately.\n\n### Efficiency\n\nBasically, this design is efficient because the Javascript logic will take some CPU while the rendering will take the graphic card.\n\nToday, WebGL is widely supported on modern desktop browsers. It\u2019s not yet the case on mobile and tablet.\n\nHowever, using Chrome Beta, I\u2019m able to run my HTML5 game at 60fps on my Nexus 4, which is quite promising for the future.\n\n<iframe width="640" height="360" src="http://www.youtube.com/embed/EzTCdjpdTfk?feature=player_embedded" frameborder="0" allowfullscreen></iframe>\n\n_Enough talking, let\u2019s see some examples now\u2026_\n\n### [][11]Hello World Example\n\n[11]: #hello-world-example\n\nHere is an Hello World example. For more examples, see [/examples][3].\n\n```html\n<canvas id="viewport" width="600" height="400"></canvas>\n<script id="fragment" type="x-shader/x-fragment">\n  #ifdef GL_ES\n  precision mediump float;\n  #endif\n  uniform float time;\n  uniform vec2 resolution;\n  void main (void) {\n    vec2 p = ( gl_FragCoord.xy / resolution.xy );\n    gl_FragColor = vec4(p.x, p.y, (1.+cos(time))/2., 1.0);\n  }\n<\/script>\n<script src="../../glsl.js" type="text/javascript"><\/script>\n<script type="text/javascript">\n  var glsl = Glsl({\n    canvas: document.getElementById("viewport"),\n    fragment: document.getElementById("fragment").textContent,\n    variables: {\n      time: 0, // The time in ms\n    },\n    update: function (time, delta) {\n      this.set("time", time);\n    },\n  }).start();\n<\/script>\n```\n\n[![screenshot](https://f.cloud.github.com/assets/211411/132729/e702c2b4-7090-11e2-8904-49e904e6c5a2.png)][13]\n\n### [][14]GLSL: OpenGL Shading Language\n\n[14]: #glsl-opengl-shading-language\n\n> GLSL is a high-level shading language based on the syntax of the C programming language. (Wikipedia)\n\nGLSL gives a very different way of thinking the rendering: basically, in a main function, you have to **set the color (`gl_FragColor`) of a pixel for a given position (`gl_FragCoord`)**.\n\nAs a nice side effect, GLSL is vectorial by design: it can be stretch to any dimension.\n\nGLSL is efficient because it is compiled to the graphic card.\n\nGLSL provides an interesting collection of **types** (e.g. `int`, `float`, `vec2`, `vec3`, `mat3`, `sampler2D`,\u2026 and also arrays of these types) and **functions** (e.g. `cos`, `smoothstep`, \u2026).\n\n[Here is a good reference for this][15].\n\nYou can also deeply explore the awesome collection of [glsl.heroku.com][16]. Any of glsl.heroku.com examples are compatible with **glsl.js** if you add some required variables (\\*time\\*, _mouse_, \u2026).\n\n### [][17]App/Game Logic\n\n[17]: #appgame-logic\n\nYou must give to Glsl a `canvas` (DOM element of a canvas), a `fragment` (the GLSL fragment code), the `variables` set, and the `update` function.\n\nThen you can start/stop the rendering via method (`.start()` and `.stop()`).\n\nThe `update` function is called as soon as possible by the library. It is called in a `requestAnimationFrame` context.\n\nYou must define all variables shared by both logic and render part in a Javascript object `{varname: value}`.  \nVariables must match your GLSL uniform variables. Every time you update your variables and you want to synchronize them with the GLSL you have to manually call the `sync` function by giving all variables name to synchronize.\n\n**Exemple:**\n\n```javascript\nGlsl({\n\xa0 canvas: canvas,\n\xa0 fragment: fragCode,\n\xa0 variables: {\n\xa0 \xa0 time: , // The time in seconds\n\xa0 \xa0 random1:\n\xa0 },\n\xa0 update: function (time, delta) {\n\xa0 \xa0 this.set("time", time);\n\xa0 \xa0 this.set("random1", Math.random());\n\xa0 }\n}).start();\n```\n\n**Note:** _under the hood, a type environment of uniform variables is inferred by parsing your GLSL code._\n\n### [][18]Using arrays\n\n[18]: #using-arrays\n\nHopefully, GLSL also supports arrays. You can actually bind a Javascript array to a GLSL uniform variable.\n\n**Example:**\n\nIn GLSL,\n\n```glsl\nuniform float tenfloats[10];\n```\n\nIn Javascript,\n\n```javascript\nvar glsl = Glsl({\n\xa0 ...\n\xa0 variable: {\n\xa0 \xa0 tenfloats: new Float32Array(10)\n\xa0 },\n\xa0 update: function () {\n\xa0 \xa0 this.tenfloats[3] = Math.random();\n\xa0 \xa0 this.sync("tenfloats");\n\xa0 }\n}).start();\n```\n\nAlternatively, you can still use a classical javascript Array (but native Javascript arrays are prefered because more efficient).\n\nUse `Int32Array` for `int[]` and `bool[]`.\n\nVector arrays are also possible. In Javascript, you will have to give a linearized array.  \nFor instance,  \na `vec2[2]` will be `[vec2(1.0, 2.0), vec2(3.0, 4.0)]` if `Float32Array(1.0, 2.0, 3.0, 4.0)` is used.\n\n### [][19]Using objects\n\n[19]: #using-objects\n\nEven more interesting now, you can synchronize a whole object into the GLSL world. This is very interesting for Object-Oriented approach.\n\n**Example:**\n\nIn GLSL,\n\n```glsl\nstruct Circle {\n\xa0 vec2 center;\n\xa0 float radius;\n}\nuniform Circle c1;\nbool inCircle (vec2 p, Circle c) {\n\xa0 vec2 ratio = resolution/resolution.x;\n\xa0 return distance(p*ratio, c.center*ratio) < c.radius;\n}\nvoid main (void) {\n\xa0 vec2 p = ( gl_FragCoord.xy / resolution.xy );\n\xa0 if (inCircle(p, c1))\n\xa0 \xa0 gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);\n\xa0 else\n\xa0 \xa0 gl_FragColor = vec4(0.0, 0.0, 0.0, 1.0);\n}\n```\n\nIn Javascript,\n\n```javascript\nfunction Circle (x, y, radius) {\n\xa0 this.center = { x: x, y: y };\n\xa0 this.radius = radius;\n\xa0 this.originalRadius = radius; // not visible by GLSL\n}\nCircle.prototype.update = function () {\n\xa0 this.radius = this.originalRadius Math.sin(Date.now()/100);\n}\nvar c1 = new Circle(0.5, 0.5, 0.1);\nGlsl({\n\xa0 ...\n\xa0 variable: {\n\xa0 \xa0 c1: c1\n\xa0 },\n\xa0 update: function (time, delta) {\n\xa0 \xa0 c1.update();\n\xa0 \xa0 this.sync("c1");\n\xa0 }\n}).start();\n```\n\nstructs inside structs are also supported:\n\n```glsl\nstruct Circle {\n\xa0 vec2 center;\n\xa0 float radius;\n}\nstruct Player {\n\xa0 Circle circle;\n\xa0 bool visible;\n}\n```\n\n### [][20]Using Arrays of Objects\n\n[20]: #using-arrays-of-objects\n\nThe two previous chapters can be assemble!\n\nYes man, Array of JS object is possible!\n\n```glsl\nuniform Circle circles[2];\n// circles[0].radius\n// \u2026\n```\n\n```javascript\nGlsl({\n\xa0 ...\n\xa0 variable: {\n\xa0 \xa0 circles: [ new Circle(0.1, 0.1, 0.2), new Circle(0.2, 0.3, 0.2) ]\n\xa0 },\n\xa0 ...\n}).start();\n```\n\n### [][21]Using images\n\n[21]: #using-images\n\nGLSL:\n\n```glsl\nuniform sampler2D img;\n```\n\nJavascript:\n\n```javascript\nvar image = new Image();\nimg.src = "foo.png";\nvar glsl = Glsl({\n\xa0 ...\n\xa0 variable: {\n\xa0 \xa0 img: image\n\xa0 }\n});\nimg.onload = function () {\n\xa0 glsl.start();\n}\n```\n\nNote: Using an image loader library can be a good idea.\n\nIn GLSL, you will need to use the texture lookup functions to access the image color for a given coordinate. E.g. `texture2D(img, coord)`. (see the [specs][15]).\n\n#### See also\n\n[The mario_sprites example][26]\n\n### [][22]Using another canvas\n\n[22]: #using-another-canvas\n\n[![hello_world_text_glsl_js](/images/2013/02/hello_world_text_glsl_js.png)][24]\n\n### Using\n\n[![glsl_js_video](/images/2013/02/glsl_js_video.png)][25]\n\n## See also\n\n<iframe width="480" height="360" src="http://www.youtube.com/embed/kxBkfy_8JEs" frameborder="0" allowfullscreen=""></iframe>\n'},"1cPK":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Anneaux muscl\xe9s"\nthumbnail: "/images/plots/084.jpg"\ndescription: "interleaving curves following a parametric function. 2 fountain pens on Bristol."\ntags:\n  - parametric\n---\n\ninterleaving curves following a parametric function. 2 fountain pens on Bristol.\n'},"1hZm":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "centers of illusion"\nthumbnail: /images/plots/165.jpg\ndescription: "square marching the distance to centers produced this interesting illusion. Combined with a bit of smoothing to make close center a bit more blobby."\n---\n\nsquare marching the distance to centers produced this interesting illusion. Combined with a bit of smoothing to make close center a bit more blobby.\n'},"1tWJ":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Elevation 02"\nthumbnail: /images/plots/158.jpg\ndescription: "Did you find the alien head? You may also find a bird! But it\'s up to your imagination. Marching squares of perlin noise domain warping."\n---\n\n**Did you find the alien head?** You may also find a bird! But it\'s up to your imagination. Marching squares of perlin noise domain warping.\n'},"2/YE":function(e,n,t){"use strict";t.r(n),n.default=""},"214X":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Packing disc"\nthumbnail: /images/plots/186.jpg\ndescription: "Continuation of packing circle experiments."\ntags:\n  - shape-packing\n---\n\nContinuation of packing circle experiments.'},"2SOq":function(e,n,t){"use strict";t.r(n),n.default=""},"2VMy":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Same Game Gravity: 6 platforms, 1 codebase\'\nthumbnail: /images/2011/07/gravity_exemple.png\ndescription: The Same Game is available for 6 different platforms. And I can pump out new builds for them all in around 15 minutes. Here\u2019s how\u2026\nauthor: Gaetan\nlayout: post\npermalink: /2011/07/same-game-gravity-technical-notes/\ntags:\n  - mobile\n  - gamedev\n  - canvas\n---\n\n [1]: /2011/07/same-game-gravity-for-ipad-iphone-android-facebook-chrome-and-web/\n [2]: http://gre.github.io/same-game-gravity\n [4]: /2011/06/automating-web-app-development-for-multiple-platforms/\n [5]: https://github.com/gre/same-game-gravity\n [6]: https://github.com/gre/same-game-gravity/blob/master/game.html\n [7]: https://github.com/gre/same-game-gravity/blob/master/game.css\n [8]: https://github.com/gre/same-game-gravity/blob/master/game.js\n [9]: https://github.com/gre/same-game-gravity/blob/master/game.js#L324\n [10]: https://github.com/gre/same-game-gravity/blob/master/game.js#L687\n [11]: https://github.com/gre/same-game-gravity/blob/master/game.js#L850\n [12]: https://github.com/gre/same-game-gravity/blob/master/game.desktop.js\n [13]: https://github.com/gre/same-game-gravity/blob/master/game.desktop.js#L137\n [14]: http://docs.phonegap.com/phonegap_accelerometer_accelerometer.md.html\n [15]: http://dev.w3.org/geo/api/spec-source-orientation.html\n [16]: http://twitter.com/42loops\n [17]: https://github.com/peutetre/test-mobile-safari/blob/master/devicemotionevent.html\n [18]: /images/2011/07/c-rotation.png\n [19]: https://github.com/gre/same-game-gravity/blob/master/game.desktop.js#L31\n [20]: https://github.com/gre/same-game-gravity/blob/master/index.css#L35\n [21]: http://playframework.org/\n [22]: /images/2011/07/same_game_gravity_schema.jpg\n [23]: http://same.greweb.fr/public/javascripts/same.scores.js\n\nsee also [Same Game Gravity presentation][1].\n\n2 years ago, I started to developed the [Same Game][2] as an HTML Canvas experiment. I\u2019ve enjoyed developing this game, mostly because playing with HTML5 Canvas is so easy. Recently I\u2019ve seen a nice increase in the user base (now around 250 visitors a day) \u2013 despite it being perhaps the simplest games I\u2019ve ever developed. Simplicity is good, but my increase in users is thanks to the power of HTML5: The Same Game is available for 6 different platforms. And I can pump out new builds for them all in around 15 minutes. Here\u2019s how\u2026\n\n\n**It\u2019s often the simplest games which work. Too much complexity is not good.**\n\n[  \n![](/images/2011/07/gravity_exemple.png)\n][2]\n\n\x3c!--more--\x3e\n\nIn 2010, I learned how to make mobile web applications. It was also the year of the iPad. Out of interest I tried my same game canvas experiment on the iPad, and was surprised to find that it worked pretty well out of the box! Seeing it run on multiple devices was exciting \u2013 and the touch screens offered a new dimension for creating highly intuitive interactions. I mean, today, **even my mum can play Same Game Gravity without any help!** (That\u2019s unfortunately not the case for her desktop)\n\nThat\u2019s why I wanted to make Same Game for mobile. I started out developing and testing it as an Android application \u2013 because I have an Android phone. I created my own micro framework with some MVC concept (views, controllers, a router, etc.). The goal was to create **a simple and light web app that look like a native application**. For views? Portions of HTML. For transitions between views? CSS transitions. Supporting the \u201cback\u201d button of Android devices as a native application? I played with the hash (onhashchange event). \n\nIn short, the web is wide and worldly enough to do pretty much everything you want with\u2026\n\nSo I implemented the Same Game on Android. But (naturally) the game already existed on Android! I had to find something new! I was itching to fully exploit the possibilities of a new technology. Mobile has great potential \u2013 so it would be bad not to make use of new APIs. I discovered **the Accelerometer**. My idea was gravity: change the balls position by rotating the device.\n\nBut, many of my friends don\u2019t have Android phones!\n\nThe Same Game Gravity is now available for iPad, iPhone, Android, Facebook, Chrome Store and desktop browsers. That\u2019s a lot of platforms, with a lot of APIs to learn \u2013 and potentially a LOT of work in maintenance. But thankfully I didn\u2019t have to go off learning Objective-C and Java Android, or keep track of arm-fulls of repositories! All the platforms are supported from **a single codebase**: thanks to the power and awesomeness of JavaScript, HTML, and CSS \u2013 combined with a nifty tool I developed [WebAppBuilder][4] to easily build each instance.\n\n\n**I added a cool scoring system that spreads via multiple social networks simultaneously and easily \u2013 and now I have a truly cross-platform game!**\n\n### The code\n\nDesktop version source code is available on [Github][5].\n\n\n#### The HTML\n\n(see [game.html][6])\n\n\nThe HTML code is pretty simple.  \nBasically, there is a **container which contains different**. Each section is a view of the game.\n\nFor instance here is the game view :  \n\n```html\n<section id="game">\n  <div class="turnleft"></div>\n  <div class="turnright"></div>\n  <div class="gameStatus">\n    <a class="i18n-back back" href="#!/">Back</a>\n    <span class="timeline">\n      <span class="remainingSeconds"><span class="remainingSecondsTime"></span> s</span>\n    </span>\n  </div>\n  <div id="gameContainer">\n    <canvas class="highlight" width="400" height="300"></canvas>\n    <canvas class="main" width="400" height="300"></canvas>\n  </div>\n</section>\n```\n\nIn the desktop version, **game.html** is wrapped into **index.html** in an iframe to keep the game independent of the context.\n\n#### The CSS\n\n(see [game.css][7])\n\n\nCSS 3 is very rich.\n\nCSS Transitions and CSS Transforms has been used to do view change.  \n\n```css\n/* Pre conditions :\n * With Javascript: \n   - A class "current" is setted for the current section view. \n   - All section after "current" must take a "after" class. \n */\n#main.enabletransition > section { /* #main must take "enabletransition" after the DOM load to avoid a first transition */\n  transition-duration: 1s, 0s;  /* transform takes 1s duration, opacity doesn\'t have transition */\n}\n#main > section {\n  z-index: -1;\n  opacity: 0;\n  transition-delay: 0s, 1s; /* opacity go to 0 in 1s */\n  transition-property: transform, opacity;\n  transform: translateY(-100%); /* go above the page */\n}\n#main > section.current {\n  z-index: 0;\n  opacity: 1;\n  transition-delay: 0s, 0s;\n  transition-transform: translateY(0%); /* go to the bottom */\n}\n#main > section.after { /* same as "#main > section.current ~ section" but without bugs */\n  opacity: 0;\n  transition-delay: 0s, 1s;\n  transform: translateY(100%); /* go below the page */\n}\n \n/* Note that this is a part of the css code \n * (you need to add -webkit-, -moz-, ... in some properties)\n */\n```\n\n#### The game core\n\n(see [game.js][8])\n\n\nCode is organized in different javascript \u201cclasses\u201d.\n\nThe main components are :\n\n*   [game.Grid][9] contains all the algorithm of the game.\n*   [game.GameCanvasRenderer][10] is a game renderer (graphic part of the game) based on HTML Canvas element. It contains different functions called by **game.Game**.\n*   [game.Game][11] contains all the game logic, the game loop and bind DOM events (touch, click, \u2026).\n\n\n#### game.desktop.js: a game instance for the desktop\n\n(see [game.desktop.js][12])\n\n\nThis file contains all the specific code for the desktop version (it overrides existing classes). But it mainly contains the [game controller][13] handling different views and using all game classes.\n\n\n##### Some significant code\n\n```javascript\n// Colors.get(nb) : pick nb random colors \nvar Colors = function() {\n  var clrs = [ new Color(\'#D34040\'), new Color(\'#82D340\'), new Color(\'#40C2D3\'), new Color(\'#8B40D3\'), new Color(\'#D3C840\') ];\n  return {\n      get: function(nb) {\n      return clrs\n      .sort(function(){ return Math.random() - 0.5; })\n      .slice(0, nb);\n    }\n  }\n}();\n \n/** Game instanciation **/\n \nvar gridSizeByDifficulty = [ // Size of grid for each difficulty\n  {w:8, h:8},\n  {w:12, h: 12},\n  {w: 16, h: 16}\n];\nvar colorNumberByDifficulty = [3, 4, 5]; // Nb of colors for each difficulty\n \nvar difficulty; // can be 0 (easy), 1 (normal) or 2 (hard)\ncurrentGame = new game.Game({\n  gridSize: gridSizeByDifficulty[difficulty],\n  colors: colors=Colors.get(colorNumberByDifficulty[difficulty]),\n  container: \'#game\', // container selector\n  rendererClass: \'GameCanvasRenderer\', // The class to use for rendering the game\n  difficulty: difficulty,\n  drawHover: true,\n  globalTimer: new Timer().pause(),\n  keepSquare: true // Keep a square ratio\n});\n```\n\n### The gravity\n\nThe game gravity was maybe the hardest part of the game development. \n\n#### Using device Accelerometer for mobile/tablet version\n\nI needed to find ways to access to the device accelerometer. For Android I used [PhoneGap Accelerometer][14]. But on iPhone I wasn\u2019t able to get PhoneGap\u2019s accelerometer.getCurrentAcceleration to work properly, so I used DeviceMotion event supported by iOS 4.2 . (see [DeviceOrientation spec][15]).\n\n(A big thanks to [@42loops][16] for that: [devicemotionevent.html][17])\n\n\n![Device orientation schema][18]\n\n\n#### CSS Transforms and Transitions for the desktop version\n\nComputers don\u2019t have an Accelerometer. *Except maybe some macbook but I\u2019m not sure people would like to turn macbook in 360\xb0!* but the gravity concept is crucial to the game. I ended up implementing \u201cgravity\u201d via the arrow keys.  \nThe game is entirely rotated with [CSS Transforms][19] and animated with [CSS Transitions][20].\n\n\n### The score system\n\nI\u2019ve written a web service with [Play! framework][21] to receive scores or retrieve them from Twitter, validate them and spread them with a json API and widgets.\n\n\n![tweet example][22]\n\n\n**This web service will be available soon for game developers.**\n\nThe power of this web service is the usage of **social networks**. It will retrieve peoples names, avatars, and their social links without needing to prompt the user.  \nFor game developers, social scores sharing is a nice way of **advertising your game**: someone shares his scores to his friends: so your game can spread virally.\n\nSee that little hash \u201c$4f005\u2033? That\u2019s a way to check if sent scores are valid.  \nIn fact the web service allows you to handle your own security, via your own \u201ctwitter to scores\u201d transformer. You can add a small Javascript function that is executed by the server when transforming a twit to scores \u2013 to ensure there hasn\u2019t been any cheating.\n\nThe web service also provides **generic widgets** to easily embed game scores in websites.  \nIf a player has played a few different games using this web scores service, we can provide a \u201ctransversal\u201d widget contains all scores of a player.\n\n#### The Same Game Gravity Widget\n\nSame Game Gravity use its own widget ([source code here][23]).\n\nThis widget is very customizable. Here\u2019s an example of the code used to embed the widget anywhere (like in this blog post) :\n\n```html\n<script type="text/javascript" src="http://same.greweb.fr/public/javascripts/same.scores.js"><\/script>\n<script type="text/javascript">\n  new same.Scores({\n    width: \'250px\',\n    height: \'400px\',\n    items: 3,\n    period: \'all\',\n    platform: [\'web\', \'mobile\', \'tablet\'],\n    type: [\'hs_hard\', \'hs_normal\', \'hs_easy\'],\n    title: \'Best highscores ever\',\n    theme: {\n      bg: \'rgb(218, 236, 244)\',\n      color: \'#000\',\n      scores_bg: \'rgba(255, 255, 255, 0.5)\',\n      scores_color: \'rgba(0, 0, 0, 0.8)\',\n      link: \'#1F98C7\'\n    }\n  }).init().fetch();\n<\/script>\n```\n\n### Conclusion\n\nAnd here we are! 6 months to develop a game and release it on different platforms! I learn a lot about mobile development and I\u2019m now more capable to develop other games.  \nI learned that you should avoid using Canvas if you can use DOM instead because performance are bad on some mobile device whereas CSS Transitions / Animations are hardware accelerated.\n\nFinally, I learned that game development is not only about programming! The marketing and the graphical parts are so important too.\n\nWant to checkout the code or contribute to the game i18n? Just fork the [game repository][5].\n\n\n\n#### Thanks\n\nBig thanks to all game testers. Friends and colleagues, thank you very much!  \nSpecial thanks to @mrspeaker for English help !\n\n'},"2Xg7":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Caves 01"\nthumbnail: /images/plots/151.jpg\ndescription: "This is a continuation of yesterday\'s plot loop to try to reuse similar noises on a more arbitrary structure. This is a crossfade of two fountain pen inks: Red Dragon and Turquoise."\ntags:\n  - noise\n---\n\nThis is a continuation of yesterday\'s plot loop to try to reuse similar noises on a more arbitrary structure. This is a crossfade of two fountain pen inks: Red Dragon and Turquoise.\n'},"2bZF":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Illuminated.js \u2013 2D lights and shadows rendering engine for HTML5 applications"\ndescription: Illuminated.js is designed to add some awesome effects to your existing applications. Adding a cool atmosphere for your applications and games can make the difference!\nthumbnail: /images/2012/05/illuminatedjs.jpg\nauthor: Gaetan\nlayout: post\npermalink: /2012/05/illuminated-js-2d-lights-and-shadows-rendering-engine-for-html5-applications/\ntags:\n  - gamedev\n  - canvas\n  - javascript\n  - library\n---\n\n[1]: http://bit.ly/LZ2dq1\n[2]: http://gre.github.io/illuminated.js\n[3]: http://github.com/gre/illuminated.js\n[4]: /2012/05/illuminated-js-2d-lights-and-shadows-rendering-engine-for-html5-applications/#gettingstarted\n[5]: /2012/05/illuminated-js-2d-lights-and-shadows-rendering-engine-for-html5-applications/#underthehood\n[6]: http://en.wikipedia.org/wiki/Canvas_element\n[7]: http://gre.github.io/illuminated.js/gettingstarted.html\n[8]: http://en.wikipedia.org/wiki/Ray_tracing_(graphics)\n[9]: /images/2012/05/step11.jpg\n[10]: /images/2012/05/step21.jpg\n[11]: /images/2012/05/step31.jpg\n[12]: /images/2012/05/step4.jpg\n[13]: http://blog.marmakoide.org/?p=1\n[14]: /images/2012/05/sampling.jpg\n[15]: http://en.wikipedia.org/wiki/Tangent_lines_to_circles\n\n[![](/images/2012/05/illuminatedjs.jpg)][1]\n\n[Click on the image to open it!][1]\n\n## Wow! what\u2019s this?\n\nIt\u2019s a **2D scene** containing 2 **lights** and 13 different **objects** rendered in **real-time** by a **Javascript library** I made called **Illuminated.js**.\n\nThe library is designed to add some **awesome effects to your existing applications**. Adding **a cool atmosphere for your applications and games** can make the difference!\n\n**[Try the editor][2]** and **[Get the source code][3]**.\n\nIn this article, we will introduce the basic usages of _Illuminated.js_ and APIs, and then explain how the engine works step-by-step.\n\n- [API \u2013 Getting started][4]\n- [Technical notes \u2013 how does it work?][5]\n\n\x3c!--more--\x3e\n\n## How can I use it?\n\nThe library uses [HTML5 Canvas][6] to draw lights and shadows \u2013 so you can simply drop it straight into your existing Canvas applications: you just need to add some code in your render function and maintaining a binding between your application logic and the _Illuminated.js_ objects.  \nNot using canvas? No worries! In theory, if you have an existing application or game made in full DOM, you could use _Illuminated.js_ behind this, playing with z-index.\n\n## <a id="gettingstarted"></a> Getting started\n\n### Basic concepts\n\nAll the classes of the package live in `window.illuminated`.\n\nA **Light** describes a light emit source.  \nAn **OpaqueObject** specifies an 2D object used by a Lighting.  \nA **Lighting** defines the lighting of a light through a set of opaque objects, each object stops the light and casts shadows.  \nA **DarkMask** defines a dark layer which hides dark area not lighted by a set of lights. It should be drown on the top-layer to hide objects which are far from the light. This effect produces a better atmosphere and is perfect for game where light are essential (where hiding invisible area is part of the difficulty).\n\n### Example of a basic scene rendering\n\n[  \nClick here to open this example.  \n![](/images/2012/05/gettingstarted.jpg)\n][7]\n\n## Lights and Objects\n\n### Vec2\n\n```javascript\nnew Vec2(x, y);\n```\n\nVec2 represents a 2d position or a 2d vector. It is used everywhere in _Illuminated.js_.\n\nVec2 is inspired from Box2d\u2019s Vec2 except that in _Illuminated.js_ a Vec2 vector is immutable. It means every methods create a new Vec2 instance and you can safely use a same Vec2 instance everywhere because the immutability guarantees the non-modification of properties.\n\n### Lights\n\nFor now, we have only implemented one kind of light: a **Lamp** which is basically a radial gradient. A Lamp can also be \u201coriented\u201d, it means lighting more far in a given direction.\n\n#### Lamp\n\n```javascript\nnew Lamp();\n\nnew Lamp({ position: new Vec2(12, 34) });\n```\n\nevery parameters:\n\n```javascript\nnew Lamp({\n\xa0 position: new Vec2(12, 34),\n\xa0 distance: 100,\n\xa0 diffuse: 0.8,\n\xa0 color: \'rgba(250,220,150,0.8)\',\n\xa0 radius: ,\n\xa0 samples: 1,\n\xa0 angle: ,\n\xa0 roughness:\n})\n```\n\nIt defines a **Lamp** placed at a **position**, with a maximum emiting **distance**, a **diffuse** parameters to define the light penetration in objects.  \nThe **radius** defines the size of the light. Bigger the size is, Higher shadows are smoothed. The **samples** is an important parameters to define the quality of this smooth.  \nThe **angle** and **roughness** parameters are used for oriented lamp: angle defines the orientation while roughness defines the roughness of the effect.\n\n### Light methods\n\nYou can easily create your own Light type by implementing its methods.\n\n#### .mask(ctx)\n\nRender a mask representing the visibility (used by DarkMask).\n\n#### .render(ctx)\n\nRender the light (without any shadows).\n\n#### .bounds()\n\nReturn the Rectangle bound of the light representing where the light emission limit. `{ topleft: vec2, bottomright: vec2 }`\n\n#### .forEachSample(fn)\n\nApply a function fn for each light sample position. By default it\u2019s called once with the light position.\n\n### Opaque Objects\n\nIn _Illuminated.js_, an object which cast shadows is called an opaque object. That\u2019s why every types inherits OpaqueObject.\n\nDiscObject and PolygonObject are the two available primitive objects.\n\n#### DiscObject\n\nA \u201cDiscObject\u201d is basically a 2D circlar object. You must define its center **position** and its **radius**:\n\n```javascript\nnew DiscObject({ position: new Vec2(80, 50), radius: 20 });\n```\n\n#### PolygonObject\n\nPolygonObject also has some derivated classes you can use: **RectangleObject**, **LineObject**.\n\nYou can instanciate these different objects like this:\n\n```javascript\nnew PolygonObject([ new Vec2(, ), new Vec2(10, 10), ... ]) // an array of points\nnew RectangleObject(topleft, bottomright) // topleft and bottomright positions of the rectangle\nnew LineObject(a, b) // an object defined by the line from a to b.\n```\n\n### OpaqueObject methods\n\nYou can easily create your own object type by implementing OpaqueObject methods.\n\n#### .bounds()\n\nReturn the Rectangle bound of the object. `{ topleft: vec2, bottomright: vec2 }`\n\n#### .contains(point)\n\nReturn `true` if the object contains a **point**.\n\n#### .path(ctx)\n\nBuild the path of the object shape in a 2d context **ctx**.\n\n#### .cast(ctx, origin, bounds)\n\nFill every shadows with **ctx** projected by the **origin** point in the object and in a given **bounds**.\n\n## Lighting and DarkMask\n\nPrevious defined classes was representing datas we will now use to perform lightings and masks.\n\n### Lighting\n\nA Lighting defines the lighting of one light through a set of opaque objects.\n\n```javascript\nnew Lighting({ light: light, objects: [ object1, object2, ... ] })\n```\n\n#### .compute(width, height)\n\nwill compute shadows casting.\n\n#### .cast(ctx)\n\nwill draw black shadows on the **ctx** canvas 2d context.  \nYou usually don\u2019t have to use it if you use `render()`.\n\n#### .render(ctx)\n\nwill draw the light with its shadows on **ctx** canvas 2d context.\n\n### DarkMask\n\nA DarkMask defines a dark layer which hides dark area not lighted by a set of lights.\n\n```javascript\nnew DarkMask({ lights: [light1, light2, ...], color: \'rgba(0,0,0,0.9)\' })\n```\n\n#### .compute(width, height)\n\nwill compute the dark mask.\n\n#### .render(ctx)\n\nwill draw the computed dark mask on **ctx** canvas 2d context.\n\n### about compute and render\n\nBoth Lighting and DarkMask objects have `compute()` and `render()` methods.\n\nWe think that **you** know the best when to recompute the lights because it\u2019s closely link to the application you are making (we will not check at each time if something has changed, you know it).  \nCall the `compute()` method when something has changed in your scene so we can recompute lights and shadows.\n\n## <a id="underthehood"></a> How does it work under the hood?\n\n_Illuminated.js_ divides its work into several layers.\n\n### Real-time example\n\n<iframe src="http://gre.github.io/illuminated.js/howdoesitwork.html" border="0" height="2700" width="450"></iframe>\n\n### The art of composing layers\n\nThe layers are all stored in a Canvas which allows us to cache it. The light is drawn using a Canvas Radial Gradient in a cache canvas only once. This is interesting because canvas gradient are processor intensive  \nAt the end, layers are combine on the global canvas with `drawImage`.  \nBut the library lets you reuse these layers to combine them the way you want.\n\nCanvas\u2019 `globalCompositeOperation` is very useful to compose layers together.  \nFor instance, in the following example, the \u201cLight shadow casting\u201d layer is combined with the \u201cLight rendering\u201d layer to generate the \u201cLight rendering with shadows\u201d layer. The composition mode used is \u201cdestination-out\u201d which remove the color of the destination image where the source image has color.\n\n```javascript\nlight.render(ctx);\nctx.globalCompositeOperation = "destination-out";\nthis.cast(ctx);\n```\n\nAnother very useful composite operation is `"lighter"` which adds color values. It is used to combine two lightings.\n\n### How shadows are projected\n\nSome rendering engine use [ray tracing][8] to render a scene, a concept very close to physics which trace from a light source a lot of rays with different paths which will collide with object and will be subject of absorption/diffraction/reflexion in accordance with the object properties\u2026  \nRay casting is a very **realistic** rendering solution **but consuming** (you need a lot of rays to avoid noises in the result image).  \n_Illuminated.js_ doesn\u2019t use ray tracing because it aims to be efficient for a real-time usage. It uses some heuristics for casting shadows.\n\n#### Let\u2019s see how shadows are projected for a polygon object.\n\nWe have a scene with a light and a triangle.\n\n![][9]\n\nWe select each edge of the polygon which is visible by the light (and in the light bounds).\n\n![][10]\n\nFor every selected edge, we project it to generate a polygon area.\n\n> **N.B.** In the current implementation, we generate an hexagon projection to ensure it goes outside of the light bounds because a quadrilateral didn\u2019t garantee it, if a light is very close to it. The projecting vector used is enough big to work for most case, but it\u2019s still an heuristic.\n\n![][11]\n\nWe draw black color in this polygon area. Some improvments can be made by not drawing black in the shape / ajusting the opacity of the color.\n\n![][12]\n\nFor casting blured shadows, we repeat this algorithm for each \u201csamples\u201d of the light. Samples are distribute around the light with a [\u201cspiral algorithm\u201d][13].\n\n![][14]\n\n```javascript\nvar GOLDEN_ANGLE = Math.PI * (3 - Math.sqrt(5));\nLamp.prototype.forEachSample = function (f) {\n  for (var s = 0; s < this.samples; ++s) {\n    var a = s * GOLDEN_ANGLE;\n    var r = Math.sqrt(s / this.samples) * this.radius;\n    var delta = new Vec2(Math.cos(a) * r, Math.sin(a) * r);\n    f(this.position.add(delta));\n  }\n};\n```\n\n## To be continued\u2026\n\nThe current version of _Illuminated.js_ needs more work, I\u2019m aware of some bugs and some parts I need to improve:\n\n- Implementing new kinds of lights like \u201cSpot\u201d, \u201cNeon\u201d, \u2026\n- The dark mask doesn\u2019t follow the Lamp orientation.\n- The shadow casting of Circle objects are not projected nicely, I need to compute [tangent lines to the circle][15].\n- Shadows go sometimes wrong especially when having objects behind objects\n- The shadow sampling implementation is a bit hacky and wrong (changing the samples parameter changes the shadow opacity\u2026)\n\n## Get involved\n\n[Try the editor][2] and [Get the source code][3].\n\nThis article is translated to [Serbo-Croatian](http://science.webhostinggeeks.com/masina-za-renderovanje) language by Jovana Milutinovich from Webhostinggeeks.com.\n'},"353+":function(e,n,t){"use strict";t.r(n),n.default=""},"3PTt":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "squares warping"\nthumbnail: /images/plots/162.jpg\ndescription: "Squares warping implements marching squares (contouring algorithm) on square distance and apply domain warping noise displacement onto it. There is a variety of different unique results and i\'ve plotted 4 of them."\n---\n\nSquares warping implements marching squares (contouring algorithm) on square distance and apply domain warping noise displacement onto it. There is a variety of different unique results and i\'ve plotted 4 of them.\n\n<img src="/images/plots/162b.jpg" width="100%">\n<img src="/images/plots/162c.jpg" width="100%">\n<img src="/images/plots/162d.jpg" width="100%">\n'},"3SEp":function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: 'Improve your web navigation experience \u2013 Flexible Nav jQuery library'\ndescription: Flexible Nav is a small jQuery library which add a smart navigation bar on the right of the page. It improves a web page navigation and helps to visualize different sections of a document, an article,.. any web page.\nauthor: Gaetan\nlayout: post\npermalink: /2011/07/improve-your-web-navigation-experience-flexible-nav-jquery-library/\ntags:\n  - javascript\n  - library\n  - navigation\n---\n\n [1]: http://gre.github.io/flexible-nav/demo\n [3]: https://github.com/gre/flexible-nav\n [4]: javascript:(function(){window.flexibleNavBase='http://gre.github.io/flexible-nav/lib/';var%20a=document.getElementsByTagName('head')[0],b=document.createElement('script');b.type='text/javascript';b.src=flexibleNavBase+'bookmarklet.min.js';a.appendChild(b);})();%20void%200\n\n## [Demo][1]\n\n> Flexible Nav is a small jQuery library which add a smart navigation bar on the right of the page. It improves a web page navigation and helps to visualize different sections of a document, an article,.. any web page.\n> \n> Nav links are distributed proportionally to the page sections. See how your scrollbar \u201cweds\u201d these links.\n\nFlexible Nav is both a **library** and a **bookmarklet** which can be used easily in any website.\n\nThe bookmarklet demonstrate the **hackability of the web** by using the semantic of web headings (*h1, h2, h3, ..*).\n\n### Links\n\n* [Documentation and Demos][1]\n* [fork me on Github][3]\n* [FlexibleNav bookmarklet][4] (drag me in your bookmarks bar)\n\n"},"3XcB":function(e,n,t){"use strict";t.r(n),n.default=""},"3rKx":function(e,n,t){"use strict";var a=t("Ga6R"),i=t("XCGq"),o=t("NdRM");function r(e,n,t){var a=[];return e.include.forEach((function(e){t=r(e,n,t)})),e[n].forEach((function(e){t.forEach((function(n,t){n.tag===e.tag&&n.kind===e.kind&&a.push(t)})),t.push(e)})),t.filter((function(e,n){return-1===a.indexOf(n)}))}function s(e){this.include=e.include||[],this.implicit=e.implicit||[],this.explicit=e.explicit||[],this.implicit.forEach((function(e){if(e.loadKind&&"scalar"!==e.loadKind)throw new i("There is a non-scalar type in the implicit list of a schema. Implicit resolving of such types is not supported.")})),this.compiledImplicit=r(this,"implicit",[]),this.compiledExplicit=r(this,"explicit",[]),this.compiledTypeMap=function(){var e,n,t={scalar:{},sequence:{},mapping:{},fallback:{}};function a(e){t[e.kind][e.tag]=t.fallback[e.tag]=e}for(e=0,n=arguments.length;e<n;e+=1)arguments[e].forEach(a);return t}(this.compiledImplicit,this.compiledExplicit)}s.DEFAULT=null,s.create=function(){var e,n;switch(arguments.length){case 1:e=s.DEFAULT,n=arguments[0];break;case 2:e=arguments[0],n=arguments[1];break;default:throw new i("Wrong number of arguments for Schema.create function")}if(e=a.toArray(e),n=a.toArray(n),!e.every((function(e){return e instanceof s})))throw new i("Specified list of super schemas (or a single Schema object) contains a non-Schema object.");if(!n.every((function(e){return e instanceof o})))throw new i("Specified list of YAML types (or a single Type object) contains a non-Type object.");return new s({include:e,explicit:n})},e.exports=s},"3yhu":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Flower parametric stack"\nthumbnail: "/images/plots/123.jpg"\ndescription: "Sakura Gelly Roll on dark red A4 card."\ntags:\n  - parametric\n---\n\nSakura Gelly Roll on dark red A4 card.\n'},"4/z1":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Bubbles"\nthumbnail: /images/plots/166.jpg\ndescription: "Marching squares on cosinus \ud83d\ude02"\n---\n\n**Marching squares on cosinus \ud83d\ude02**\n\n<img src="/images/plots/166zoom.jpg" width="100%">'},"4EJ6":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: Minimize your Javascript files with cURL\ndescription: use Google Closure Compiler web service to minimize a Javascript file with only cURL.\nauthor: Gaetan\nlayout: post\npermalink: /2012/05/minimize-your-javascript-files-with-curl/\ntags:\n  - javascript\n  - linux\n---\n\nI\u2019ve always been fascinated by the power of **using existing web applications as external tools**: you don\u2019t need to install anything on your computer but you can **rely on the web**.\n\nWe can **externalize the intelligence of applications in servers** and **easily make updates**, while having any terminal consuming them with a **minimal OS environment**.  \n*Cloud* or whatever you call it, it\u2019s awesome.\n\nWOA is our common architecture for making applications. Clients of web servers can be anything you want, not only desktop browsers, but also mobiles, tablets, other web services, and\u2026 **command-line**!\n\nAnd today, as an example, we will use [Google Closure Compiler web service][1] to **minimize a Javascript file with only cURL**.\n\n [1]: https://developers.google.com/closure/compiler/docs/api-ref\n\n\x3c!--more--\x3e\n\n**cURL** is a CLI swiss army knife of transferring data and it is perfect for testing, debugging and consuming web services.\n\n**Google Closure Compiler** check and \u201ccompile\u201d your Javascript file. By compile, it means optimizing its size by renaming variables and removing spaces and comments. Javascript compilation has because an essential phase of major javascript libraries.\n\n## Bash script examples\n\n### Download and minimize the last version of Illuminated.js\n\n```bash\nURL=https://raw.github.com/gre/illuminated.js/master/src/illuminated.js  \nOUTPUT=illuminated.min.js  \ncurl -d compilation_level=SIMPLE_OPTIMIZATIONS -d output_format=text -d output_info=compiled_code -d code_url=$URL http://closure-compiler.appspot.com/compile > $OUTPUT\n```\n\n### Minimize a local JS file\n\n```bash\nLOCAL_FILE=./mysuperlib.js  \nOUTPUT=mysuperlib.min.js  \ncurl -d compilation_level=SIMPLE_OPTIMIZATIONS -d output_format=text -d output_info=compiled_code --data-urlencode "js_code@${LOCAL_FILE}" http://closure-compiler.appspot.com/compile > $OUTPUT\n```\n'},"5/hP":function(e,n,t){"use strict";t.r(n),n.default=""},"55eu":function(e,n,t){"use strict";var a=t("NdRM"),i=Object.prototype.hasOwnProperty,o=Object.prototype.toString;e.exports=new a("tag:yaml.org,2002:omap",{kind:"sequence",resolve:function(e){if(null===e)return!0;var n,t,a,r,s,l=[],c=e;for(n=0,t=c.length;n<t;n+=1){if(a=c[n],s=!1,"[object Object]"!==o.call(a))return!1;for(r in a)if(i.call(a,r)){if(s)return!1;s=!0}if(!s)return!1;if(-1!==l.indexOf(r))return!1;l.push(r)}return!0},construct:function(e){return null!==e?e:[]}})},"5Tfx":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Pentaflower"\nthumbnail: "/images/plots/128.jpg"\ndescription: "Parametric flower plotted with two brush pens."\ntags:\n  - parametric\n  - brush\n---\n\nParametric flower plotted with two brush pens. It is challenging to get the correct pen height when working with brush pens. I used two parametric functions with a slight displacement to reveal some moir\xe9 patterns created by the divergence.\n'},"6Q0G":function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: CSS3 Transitions\nauthor: Gaetan\nlayout: post\npermalink: /2010/05/css3-transitions-available-on-firefox-3-7/\ntags:\n  - css\n  - animation\n  - transition\n---\n\n [1]: http://www.w3.org/TR/css3-transitions/\n\n[CSS3 transitions][1] are now available on Firefox, Chrome, Safari, Opera and \u2026 IE9!, and it\u2019s awesome.\n\n> CSS Transitions allows property changes in CSS values to occur smoothly over a specified duration.\n\n**Javascript is not anymore required for simple animation.**\n\nSpecifically, we don\u2019t need Javascript to manage animation with **setInterval** or with any library like **jQuery.animate** : Forget the animation management, stay focused on the real work.\n\nIn this article, I will try to explain why and how using css3-transition with some examples.\n\n\x3c!--more--\x3e\n\n## Why ?\n\n*   It\u2019s **simple** and **smart** : adding one line of css code.\n*   It **let the browser rendering animation instead of using javascript complex code**. You don\u2019t have to worry about animation and performance. So you can stay focused on real part of your project.\n*   It\u2019s **cleaner** than some javascript animation implementation because you don\u2019t modify style attribute during animations. So, it\u2019s also probably more efficient.\n*   **Degradation is great.** If your browser doesn\u2019t support CSS Transition, it\u2019s not really bad, only the animation is not available. **Other behaviors aren\u2019t alterate**. For example, imagine a photo slide-show with zoom effect when changing photo. With an old browser, photos are just instantly zoomed without animation. That\u2019s not bad.\n*   And off course, It\u2019s **standard**.\n\n## How ?\n\nCSS Transition are **extremely simply to use**.\n\n### transition-duration\n\nBasically, you set a **css time properties** in a css selector *like `-moz-transition-duration: 1s;` for mozilla*. This time define the animation duration. Browser will determine the transition between this selector and a descendant selector.\n\nNot that css3 transition is currently in draft mode, so there are multiple property for each browser (the prefix change). \n\nFor Firefox (3.7 ), Chrome (and other webkit browser) and Opera, you have to use : \n\n```css\n-moz-transition-duration: 1s;  \n-webkit-transition-duration: 1s;  \n-o-transition-duration: 1s;\n```\n\nDon\u2019t panic, in the future (on CSS3 release), only one property will be used.\n\n#### Example\n\n```css\n.box {  \n\xa0 -moz-transition-duration: 1s;  \n\xa0 -webkit-transition-duration: 1s;  \n\xa0 -o-transition-duration: 1s;  \n  \n\xa0 margin: 10px;  \n\xa0 background-color: red;  \n}  \n.box:hover {  \n\xa0 margin: 50px;  \n\xa0 background-color: green;  \n}\n```\n\nOn mouse over the **.box**, during one second : margin will move from **10px** to **50px** and background-color will move from **red** to **green**. That\u2019s all!\n\n### transition-property\n\nYou can also specify the name of the CSS property to which the transition is applied.\n\nFor instance, **color**, **width**, **opacity**, \u2026\n\n#### Like this\n\n```css\n-moz-transition-property: margin, background-color;  \n-webkit-transition-property: margin, background-color;  \n-o-transition-property: margin, background-color;\n```\n\n### Others properties\n\nMore properties are available to specify more deeply transition effects. Retrieve them on [CSS Transitions Working Draft][1].\n\n*   transition-timing-function\n*   transition-delay\n\n## Examples\n\nHere are some CSS transition examples.\n\n* [A box with color, text, shapes transformation.](/demo/css3/transition/box1/)\n* [Letters animation.](/demo/css3/transition/letters/)\n* [Image slider.](http://sliderjs.org/)\n* [Navigation bar.](/demo/css3/transition/navbar/)\n\n"},"6d7H":function(e,n,t){"use strict";t.r(n),n.default=""},"6oDM":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Anomalie carr\xe9e (4/4)"\nthumbnail: /images/plots/170.jpg\ndescription: "One of the 4 plots of the series of \'Anomalie carr\xe9e\'. made with 2 fountain pens on A4 Bristol paper. The first buyer of this NFT sold by achetezdelart can collect the original copy. No other copy will be made. See information in the NFT."\n---\n\n<nft-card contractAddress="0x495f947276749ce646f68ac8c248420045cb7b5e" tokenId="47428341271170390733253974222101382154768714392453356712130950049108347322369"> </nft-card> <script src="https://unpkg.com/embeddable-nfts/dist/nft-card.min.js"><\/script>\n\nOne of the 4 plots of the series of \'Anomalie carr\xe9e\'. made with 2 fountain pens on A4 Bristol paper. The first buyer of this NFT sold by achetezdelart can collect the original copy. No other copy will be made. See information in the NFT.'},"6ubZ":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Dancing mountain (4 frames)"\nthumbnail: /images/plots/195.gif\ndescription: "@greweb\'s #11 plot loop."\ntags:\n  - plotloop\n---\n\n@greweb\'s #11 plot loop. This is an highlight of the recent work, animated.'},"6ykQ":function(e,n,t){"use strict";t.r(n),n.default=""},7104:function(e,n){var t=Object.prototype.toString;function a(e){return"function"===typeof e.constructor?e.constructor.name:null}e.exports=function(e){if(void 0===e)return"undefined";if(null===e)return"null";var n=typeof e;if("boolean"===n)return"boolean";if("string"===n)return"string";if("number"===n)return"number";if("symbol"===n)return"symbol";if("function"===n)return"GeneratorFunction"===a(e)?"generatorfunction":"function";if(function(e){return Array.isArray?Array.isArray(e):e instanceof Array}(e))return"array";if(function(e){if(e.constructor&&"function"===typeof e.constructor.isBuffer)return e.constructor.isBuffer(e);return!1}(e))return"buffer";if(function(e){try{if("number"===typeof e.length&&"function"===typeof e.callee)return!0}catch(n){if(-1!==n.message.indexOf("callee"))return!0}return!1}(e))return"arguments";if(function(e){return e instanceof Date||"function"===typeof e.toDateString&&"function"===typeof e.getDate&&"function"===typeof e.setDate}(e))return"date";if(function(e){return e instanceof Error||"string"===typeof e.message&&e.constructor&&"number"===typeof e.constructor.stackTraceLimit}(e))return"error";if(function(e){return e instanceof RegExp||"string"===typeof e.flags&&"boolean"===typeof e.ignoreCase&&"boolean"===typeof e.multiline&&"boolean"===typeof e.global}(e))return"regexp";switch(a(e)){case"Symbol":return"symbol";case"Promise":return"promise";case"WeakMap":return"weakmap";case"WeakSet":return"weakset";case"Map":return"map";case"Set":return"set";case"Int8Array":return"int8array";case"Uint8Array":return"uint8array";case"Uint8ClampedArray":return"uint8clampedarray";case"Int16Array":return"int16array";case"Uint16Array":return"uint16array";case"Int32Array":return"int32array";case"Uint32Array":return"uint32array";case"Float32Array":return"float32array";case"Float64Array":return"float64array"}if(function(e){return"function"===typeof e.throw&&"function"===typeof e.return&&"function"===typeof e.next}(e))return"generator";switch(n=t.call(e)){case"[object Object]":return"object";case"[object Map Iterator]":return"mapiterator";case"[object Set Iterator]":return"setiterator";case"[object String Iterator]":return"stringiterator";case"[object Array Iterator]":return"arrayiterator"}return n.slice(8,-1).toLowerCase().replace(/\s/g,"")}},"7GSA":function(e,n,t){"use strict";t.r(n),n.default=""},"88+z":function(e,n,t){"use strict";t.r(n),n.default=""},"8Qj+":function(e,n,t){"use strict";const a=t("7104"),i=t("VQEG"),o=t("tfEw");function r(e){return"\n"!==e.slice(-1)?e+"\n":e}e.exports=function(e,n,t){if(null==n&&null==t)switch(a(e)){case"object":n=e.data,t={};break;case"string":return e;default:throw new TypeError("expected file to be a string or object")}const s=e.content,l=o(t);if(null==n){if(!l.data)return e;n=l.data}const c=e.language||l.language,u=i(c,l);if("function"!==typeof u.stringify)throw new TypeError('expected "'+c+'.stringify" to be a function');n=Object.assign({},e.data,n);const h=l.delimiters[0],d=l.delimiters[1],p=u.stringify(n,t).trim();let m="";return"{}"!==p&&(m=r(h)+r(p)+r(d)),"string"===typeof e.excerpt&&""!==e.excerpt&&-1===s.indexOf(e.excerpt.trim())&&(m+=r(e.excerpt)+r(d)),m+r(s)}},"8VEi":function(e,n,t){"use strict";t.r(n),n.default=""},"8pr5":function(e,n,t){"use strict";t.r(n),n.default=""},"91iZ":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'PlayCLI: Play Iteratees + UNIX pipe\'\ndescription: PlayCLI is a new Scala library to work with UNIX commands and Play-Iteratees (a scala implementation of Iteratees facilitating the handling of data streams reactively)\nauthor: Gaetan\nlayout: post\npermalink: /2013/01/playcli-play-iteratees-unix-pipe/\ntags:\n  - iteratee\n  - playframework\n  - reactive\n  - unix\n  - library\n---\n\n [1]: http://scala-lang.org\n [2]: http://www.playframework.org/documentation/2.0/Iteratees\n [3]: http://gre.github.io/playCLI-examples/api\n [4]: http://github.com/gre/playCLI\n [5]: http://github.com/gre/playCLI-examples\n [6]: /2012/08/zound-a-playframework-2-audio-streaming-experiment-using-iteratees/\n [7]: http://mandubian.com/2012/08/27/understanding-play2-iteratees-for-normal-humans/\n [8]: http://gre.github.io/playCLI-examples/api/#enumerate(command:scala.sys.process.ProcessBuilder,chunkSize:Int,terminateTimeout:Long)(implicitec:scala.concurrent.ExecutionContext):play.api.libs.iteratee.Enumerator[Array[Byte]]\n [9]: http://www.playframework.org/documentation/api/2.1-RC1/scala/index.html#play.api.libs.iteratee.Enumerator\n [10]: http://gre.github.io/playCLI-examples/api/#pipe(command:scala.sys.process.ProcessBuilder,chunkSize:Int,terminateTimeout:Long)(implicitec:scala.concurrent.ExecutionContext):play.api.libs.iteratee.Enumeratee[Array[Byte],Array[Byte]]\n [11]: http://www.playframework.org/documentation/api/2.1-RC1/scala/index.html#play.api.libs.iteratee.Enumeratee\n\n [12]: http://gre.github.io/playCLI-examples/api/#consume(command:scala.sys.process.ProcessBuilder,terminateTimeout:Long)(implicitec:scala.concurrent.ExecutionContext):play.api.libs.iteratee.Iteratee[Array[Byte],Int]\n [13]: http://www.playframework.org/documentation/api/2.1-RC1/scala/index.html#play.api.libs.iteratee.Iteratee\n [14]: http://www.scala-lang.org/api/current/index.html#scala.sys.process.package\n [15]: http://www.playframework.org/documentation/api/2.1-RC1/scala/index.html#play.api.libs.iteratee.Done$\n [16]: #pipe(command:scala.sys.process.ProcessBuilder,chunkSize:Int,terminateTimeout:Long)(implicitec:scala.concurrent.ExecutionContext):play.api.libs.iteratee.Enumeratee[Array[Byte],Array[Byte]]\n [17]: http://www.playframework.org/documentation/api/2.1-RC1/scala/index.html#play.api.libs.iteratee.Input$$EOF$\n\n\n> **TL;DR.** PlayCLI is a new [Scala][1] library to work with UNIX commands and [Play-Iteratees][2] (a scala implementation of Iteratees facilitating the handling of data streams reactively). Here\u2019s an overview:\n\n<iframe src="http://gre.github.io/playCLI-examples/embedder.html#index.html" frameborder="0" width="550" height="452"></iframe>\n\n## Links\n\n*   [The scala API][3].\n*   [PlayCLI source code (Github)][4].\n*   [PlayCLI Examples application (Github)][5].\n\n### SBT\n\n```scala\n"fr.greweb" %% "playcli" % "0.1"\n```\n\n\x3c!--more--\x3e\n\n## Why PlayCLI\n\nAfter having made [Zound][6] in a HackDay (an experiment to generate an audio stream with playframework iteratees and through the WAVE format), I figured out this was going to be hard to make it work with multiple audio format: *tell me if I\u2019m wrong but*, there are not so much audio libraries in Java/Scala, or most of them does not support stream handling (and not reactively), and it was going to be crazy to re-implement everything in Scala (both in term of cost and performance).\n\nBesides, **UNIX has plenty of tools** to do this and:\n\n1.  they are **complete** and provide a lot of options\n2.  they are **easy to use** (see how Bash is powerful as a consequence)\n3.  Most of them **support streams** out of the box (via stdin / stdout)\n4.  They are very **efficient** (written in C / assembly)\n\nSo why not re-use them from our reactive code?\n\n### Similarities with UNIX pipes\n\n> Take the expressivity of UNIX pipes, bring the power of Scala, mix it with Play Framework and you got a powerful framework for handling real-time and web streaming.\n\nPlay Iteratees are an elegant & powerful way to handle streams reactively, and I\u2019ve actually always understood them like UNIX pipes, you have the same reactive code style: linearized declarative way of handling streams.\n\n**Bash:**\n\n```bash\ncat words.txt | grep $word > result.txt\n```\n\n**Scala:**\n\n```scala\nEnumerator.fromFile("words.txt") &>   \n\xa0 splitByNl &> // split a stream of Array[Byte] into stream of String (not impl here)  \n\xa0 Enumeratee.filter(_.containsSlice(word)) \xa0|>>>   \n\xa0 fileWriter // consume the steam while storing in a file (not impl here)\n```\n\nor if you prefer the \u201cwithout symbol\u201d version:\n\n```scala\nEnumerator.fromFile("words.txt").  \n\xa0 through splitByNl.  \n\xa0 through Enumeratee.filter(_.containsSlice(word)).  \n\xa0 run fileWriter\n```\n\nHowever, It\u2019s biased to say Iteratees are only UNIX pipes, they are more than that, but I\u2019m not going to extend on that subject, they are at least statically typed and safe (it\u2019s more than just a stream of bytes, see [this article][7]).\n\nSo if Iteratees are at least UNIX pipes, why can\u2019t we use Unix pipes from iteratees?\n\n**PlayCLI provides a bridge to use scala.sys.Process with play-iteratees.**\n\n## More about PlayCLI\n\n*(this is a copy of the API documentation)*\n\n### Overview\n\nDepending on your needs, you can **Enumerate / Pipe / Consume** an UNIX command:\n\n[CLI.enumerate][8] is a way to create a stream from a command which **generates output**  \n(it creates an [Enumerator][9][Array[Byte]] )\n\n[CLI.pipe][10] is a way to pipe a command which **consumes input and generates output**  \n(it creates an [Enumeratee][11][Array[Byte],Array[Byte]])\n\n[CLI.consume][12] creates a process which **consumes a stream** \u2013 useful for side effect commands  \n(it creates an [Iteratee][13][Array[Byte],Int])\n\n\n#### Examples\n\n```scala\nimport playcli._  \nimport scala.sys.process._  \n  \n// Some CLI use cases  \nval tail = CLI.enumerate("tail -f /var/log/nginx/access.log")  \nval grep = (word: String) => CLI.pipe(Seq("grep", word))  \nval ffmpeg = CLI.pipe("ffmpeg -i pipe:0 ... pipe:1") // video processing  \nval convert = CLI.pipe("convert - -colors 64 png:-") // color quantization  \n  \n// Some usage examples  \nval sharedTail = Concurrent.broadcast(tail)  \nOk.stream(sharedTail).withHeaders(CONTENT_TYPE -> "text/plain") // Play framework  \n  \nval searchResult: Enumerator[String] = dictionaryEnumerator &> grep("able") &> aStringChunker  \n  \nOk.stream(Enumerator.fromFile("image.jpg") &> convert).withHeaders(CONTENT_TYPE -> "image/png")  \n  \nEnumerator.fromFile("video.avi") &> ffmpeg &> ...\n```\n\n### Process\n\nCLI uses [scala.sys.process][14]  \nand create a Process instance for each UNIX command.\n\nA CLI process is terminates when:\n\n*   The command has end.\n*   stdin and stdout is terminated.\n*   [Done][15] is reached (for [enumerate][8] and [pipe][16]).\n*   [EOF][17] is sent (for [pipe][10] and [consume][12]).\n\nCLI still waits for the Process to terminate by asking the exit code (via `Process.exitCode()`).  \nIf the process is never ending during this phase, it will be killed when `terminateTimeout` is reached.\n\nPS: Thanks to implicits, you can simply give a String or a Seq to the CLI.* functions a `ProcessBuilder`.\n\n### Mutability\n\n[enumerate][8] and [pipe][10] are **immutable**, in other words, re-usable  \n(each result can be stored in a val and applied multiple times).  \n**A new process is created for each re-use**.\n\n[consume][12] is **mutable**, it should not be used multiple times: it targets side effect command.\n\n### Logs\n\nA \u201cCLI\u201d logger (logback) is used to log different information in different log levels:\n\n*   **ERROR** would mean a CLI error (not used yet).\n*   **INFO** used for the process\u2019 stdout output of a [CLI.consume][12].\n*   **DEBUG** used for the process life cycle (process creation, process termination, exit code).\n*   **WARN** used for the process\u2019 stderr output.\n*   **TRACE** used for low level information (IO read/write). \n\n## Conclusion\n\nI\u2019m eager to see what you guys can do with such an API, it enables a lot of possibility, I\u2019m especially thinking about multimedia purposes (using powerful commands like: ImageMagick, ffmpeg, sox,\u2026).\n'},"96bJ":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: Blender as a 2D game level editor \u2013 Proof Of Concept\ndescription: Here is how you can design and export your 2D game map with Blender (both the logic and the graphics).\nthumbnail: /images/2012/04/map1.png\nauthor: Gaetan\nlayout: post\npermalink: /2012/04/blender-as-a-2d-game-map-editor-proof-of-concept/\ntags:\n  - gamedev\n  - blender\n  - javascript\n---\n\n#\n\nA long time ago, video games were only two-dimensional. Of-course this was due to our poor hardware capabilities, but when computers became faster and faster 3D games appeared in mass.  \n**Did it kill 2D games? Nope.** They continue to exist because it offer a different gameplay and are easier to make. Maybe also a bit because we are nostalgic of old-school games!\n\nWe can distinguish two kinds of 2D games:\n\n<img src="/images/2012/04/bomberman93.jpg" alt="" class="thumbnail-left" />\n[**Tile based games**][2] where the game world is simplified with a big grid \u2013 each grid position has some properties.  \nA map editor is not always needed for tile based games, because the map can be straighforward to represent and maintain like in a *Bomberman* or in a *Pacman*. A simple editor is generally used to make graphism with sprites.\n\n[2]: http://www.tonypa.pri.ee/tbw/tut00.html\n[4]: http://higherorderfun.com/blog/2012/05/20/the-guide-to-implementing-2d-platformers/\n[5]: http://www.masswerk.at/JavaPac/JS-PacMan2.html\n[6]: http://impactjs.com/documentation/weltmeister\n[7]: http://gre.github.io/blazing-race\n[12]: http://gre.github.io/blazing-race/maps/converter/\n\n<br style="clear:both" />\n\n<img src="/images/2012/04/woarpc001.jpg" alt="" class="thumbnail-left" />\n**Non-tile based games**, which can be called \u201cpolygon based games\u201d are more complex.  \nIn such game, like a *Worms* or a *Sonic*, it\u2019s totally crazy to write the map by hand (objects positions, polygons coordinates, \u2026). The alternative, is not to use predefined maps, but on-the-fly generated maps which doesn\u2019t fit every games.\n\n<br style="clear:both" />\n  \n[Here are more detailed work on these different game designs][4].\n\n**Making the game engine** is one thing, but **designing the game levels** can be one big work too and **we need tools to make it easier**.\n\n\x3c!--more--\x3e\n\n## Tile based game maps\n\nIn tile based games, maps are usually quite simple to represent.\n\nFor instance, here is how we can code the maze of [Pacman][5]:\n\n```javascript\n[\n  "ahhhhhgxbhhdxehhhhhc",\n  "vp....o......o....pv",\n  "v.lhm...lhhm...lhm.v",\n  "v.....n......n.....v",\n  "v.n.n.v.ahhc.v.n.n.v",\n  "d.v.o.v.vxxq.v.o.v.b",\n  "x.v...v.vxxt.v...v.x",\n  "c.bhm.o.bhhr.o.lhd.a",\n  "v........x.........v",\n  "em.lc.am.lm.lc.am.lg",\n  "v...v.v......v.v...v",\n  "v.k.o.o.lhhm.o.o.k.v",\n  "vp................pv",\n  "bhhhhhcxahhcxahhhhhd",\n];\n```\n\nwhere every character is a tile and has a given meaning.\n\nFor more complex games, we can also represent the map with a set of objects, and each object has position and size properties (x, y, width, height) and other properties for the game logic.\n\nFor instance, see the _ImpactJS_ tile based games editor:\n\n[![](/images/2012/04/weltmeister-tutorial-entities.png)][6]\n\n## But what about polygons based game?\n\nWell, some have tried to make dedicated 2D game map editor like shown in this video:\n\n<iframe width="640" height="360" src="http://www.youtube.com/embed/kvvEmm2Vyoc?feature=player_embedded" frameborder="0" allowfullscreen></iframe>\n\nbut it sounds a bit unfinished and specific.\n\n### Do it yourself, but don\u2019t reinvent the wheel.\n\n**But finally, isn\u2019t it what a 3D editor is doing?**\n\nIsn\u2019t it the most generic tool we can find?\n\nThey have done a lot of awesome work in term of user interface, polygon modeling, textures (procedural / bitmap), \u2026let\u2019s profit of all this work to generate awesome texture map while exporting polygons.\n\nRelying on such tools, you don\u2019t have to learn a brand new map editor, you can relax on what you know if you have the chance to know Blender or Maya or anything.\n\n### The Z magic\n\nLet\u2019s ignore the Z dimension, or rather, let\u2019s **use the Z-dimension as a way to represent the semantics of the game map!**\n\nThis is the map I made for [Blazing Race][7], a HTML5 against-the-clock platform game where you control a fireball:\n\n![](/images/2012/04/zs.png)\n\nFor my game needs, I used **different Z layers to represent different kind of materials and game objects**:\n\n- z=1 : candles\u2019 position \u2013 the objective of the game is to light them all\n- z=0 : the game grounds \u2013 where collision occurs\n- z=-1 : the water areas \u2013 where your flame dies\n- z=-2 : special areas where you miss oxgyen \u2013 your flame dies in a few seconds\n\nBut I also used **objects ids** as an another way to distinguish objects:  \na \u201cstart\u201d object to define the game start position and two \u201ctopleft\u201d and \u201cbottomright\u201d objects to define the game bound.\n\n### Maintain your map source in one file\n\nAnother powerful feature of this, is you can maintain your map polygons AND your map textures in a single way. Use your 3D editor as a polygon editor and use its render engine to generate textures:\n\n![](/images/2012/04/map1.png)\n\nTake benefits from what your 3D editor can do.\n\n### Export polygons to the Javascript game\n\n![](/images/2012/04/path4850.png)\n\nI\u2019ve made a transformer which take a COLLADA file in input (the most commonly supported standard format to describe a 3D scene, you can export it from any 3D editor like Blender, Maya, 3DS\u2026) which extract and transform relevant informations from it and give you a json map for your game in output.\n\n_It was quite simple to implement, thanks to the Three.js COLLADA importer!_\n\nHere is the current (unfinished) interface for this:\n\n[![](/images/2012/04/demo_screenshot.png)][12]\n\nAs a proof of usability of the output JSON map, the preview was only made in a few lines of Javascript code.\n\nExtract:\n\n```javascript\nfunction draw(map) {\n  var container = $("#viewport").empty();\n  $("#legend").empty();\n  a = 0;\n  var w = 500;\n  var h = Math.floor((w * map.height) / map.width);\n  var CROSS_SIZE = 3;\n  var canvas = $(\'<canvas width="\' + w + \'" height="\' + h + \'"></canvas>\');\n  var ctx = canvas[0].getContext("2d");\n  for (var name in map) {\n    var objs = map[name];\n    if (objs[0] && objs[0].faces) {\n      var color = randomColor(70, 0.8);\n      ctx.fillStyle = color;\n      for (var i = 0; i < objs.length; ++i) {\n        var obj = objs[i];\n        for (var f = 0; f < obj.faces.length; ++f) {\n          var face = obj.faces[f];\n          ctx.beginPath();\n          for (var v = 0; v < face.length; ++v) {\n            var vertice = obj.vertices[face[v]];\n            var x = (ctx.canvas.width * vertice.x) / map.width;\n            var y = ctx.canvas.height * (1 - vertice.y / map.height);\n            if (v == 0) ctx.moveTo(x, y);\n            else ctx.lineTo(x, y);\n          }\n          ctx.fill();\n        }\n      }\n      addLegend(color, name, true);\n    }\n  }\n  for (var name in map) {\n    var objs = map[name];\n    if (objs[0] && objs[0].x) {\n      var color = randomColor(50);\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 2;\n      for (var i = 0; i < objs.length; ++i) {\n        var p = objs[i];\n        var x = (ctx.canvas.width * p.x) / map.width;\n        var y = ctx.canvas.height * (1 - p.y / map.height);\n        ctx.beginPath();\n        ctx.moveTo(x - CROSS_SIZE, y);\n        ctx.lineTo(x + CROSS_SIZE, y);\n        ctx.moveTo(x, y - CROSS_SIZE);\n        ctx.lineTo(x, y + CROSS_SIZE);\n        ctx.stroke();\n      }\n      addLegend(color, name, false);\n    }\n  }\n  container.append(canvas);\n}\n```\n\n## What is next?\n\nBlazing Race, is not finished yet, I need to improve a lot of things.\n\nI\u2019ll try to release a standalone version of this converter soon with tutorials and examples.\n'},"98/W":function(e,n,t){"use strict";t.r(n),n.default=""},"9aUE":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Anomalie carr\xe9e (1/4)"\nthumbnail: /images/plots/167.jpg\ndescription: "One of the 4 plots of the series of \'Anomalie carr\xe9e\'. made with 2 fountain pens on A4 Bristol paper. The first buyer of this NFT sold by achetezdelart can collect the original copy. No other copy will be made. See information in the NFT."\n---\n\n<nft-card contractAddress="0x495f947276749ce646f68ac8c248420045cb7b5e" tokenId="47428341271170390733253974222101382154768714392453356712130950045809812439041"> </nft-card> <script src="https://unpkg.com/embeddable-nfts/dist/nft-card.min.js"><\/script>\n\nOne of the 4 plots of the series of \'Anomalie carr\xe9e\'. made with 2 fountain pens on A4 Bristol paper. The first buyer of this NFT sold by achetezdelart can collect the original copy. No other copy will be made. See information in the NFT.'},"9i9n":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "squares packing 002"\nthumbnail: /images/plots/180.jpg\ndescription: "Second iteration on packing rotated squares in a square. Black fountain pens on 300g/m paper."\ntags:\n  - shape-packing\n---\n\nContinuation of [plot#179](/plots/179).\n\nSecond iteration on packing rotated squares in a square. Black fountain pens on a 300g/m paper. It\'s interesting how the paper makes the ink having different shade of greys.\n\nThis time, the rotations are less random and aligned on 10 possible angles. (but these are squares so not it repeats)\n\nThere is also two concentric squares drawn each time.\n\n## Technical notes\n\nThis is also a continuation of the code of [plot#179](/plots/179).\n\nI did an improvement of the search algorithm using a dichotomic search:\n\n**search**\n\n```rust\nfn poly_square_scaling_search(\n    boundaries: (f64, f64, f64, f64),\n    polys: &Vec<Polygon<f64>>,\n    x: f64,\n    y: f64,\n    angle: f64,\n    min_scale: f64,\n    max_scale: f64,\n) -> Option<f64> {\n    let overlaps = |size| {\n        let poly = rotated_square_as_polygon(x, y, size, angle);\n        let bounds = poly.bounding_rect().unwrap();\n        let topleft: Point<f64> = bounds.min().into();\n        let bottomright: Point<f64> = topleft + point!(\n            x: bounds.width(),\n            y: bounds.height()\n        );\n        out_of_boundaries(topleft.x_y(), boundaries)\n        || out_of_boundaries(bottomright.x_y(), boundaries)\n        || poly_collides_in_polys(polys, &poly)\n    };\n\n    let mut from = min_scale;\n    let mut to = max_scale;\n    loop {\n        if overlaps(from) {\n            return None;\n        }\n        if to - from < 0.1 {\n            return Some(from);\n        }\n        let middle = (to + from) / 2.0;\n        if overlaps(middle) {\n            to = middle;\n        }\n        else {\n            from = middle;\n        }\n    }\n}\n```'},"9nhf":function(e,n,t){"use strict";t.r(n),n.default=""},"9x/r":function(e,n,t){"use strict";t.r(n),n.default=""},ABVm:function(e,n,t){"use strict";t.r(n),n.default=""},ADEy:function(e,n,t){"use strict";t.r(n),n.default=""},AccM:function(e,n,t){"use strict";t.r(n),n.default=""},B0EA:function(e,n,t){"use strict";t.r(n),n.default=""},BF22:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: gl-react v3\nthumbnail: /images/2016/12/thumbnail.png\ndescription: gl-react has been reimplemented from scratch, feedback from previous mistake and overview of new features.\nauthor: Gaetan\nlayout: post\ntags:\n  - react\n  - gl-react\n  - webgl\n---\n\n[cookbook]: https://gl-react-cookbook.surge.sh\n[github]: https://github.com/gre/gl-react\n[jest]: https://github.com/facebook/jest\n[headless-gl]: https://github.com/stackgl/headless-gl\n[bus]: https://gl-react-cookbook.surge.sh/api#bus\n\n# Happy to release **[https://gl-react-cookbook.surge.sh][cookbook]** containing 43 unique examples and API documentation!\n\n[![](/images/2016/12/gl-react-v3.gif)][cookbook]\n\n> If you don\'t want to be "spoiled" by this article, go through [the cookbook examples][cookbook]. This article will explore some of them.\n\n\x3c!--more--\x3e\n\n## gl-react has been rewritten from scratch\n\n**gl-react v3 is a complete rewrite of the v2 implementation for better performance and compatibility with React paradigm.**\n\nThis is not yet published on NPM as it\'s [still in development][github] (the Web version is pretty ready, React Native version is not implemented).\n\nMost features provided by gl-react v2 are preserved (API haven\'t changed, [see how similar is the HelloGL example](https://gl-react-cookbook.surge.sh/hellogl)), but v3 fixes most Github issues accumulated for a year.\n\n### The biggest mistake of the previous implementation\n\nIf there is one lesson learned from previous gl-react implementation: **"unfolding" / consuming the `children` prop by yourself is (probably) wrong, let React solve this job!** Using React, you can benefit [React reconciliation and diff algorithm](https://facebook.github.io/react/docs/reconciliation.html).\nIn other words, always prefer to keep users\' VDOM tree rather than consuming it with `React.Children.*` functions.\n\nI feel dumb not having discovered this before, but if you are not actually rendering DOM it\'s an easy path for a library to just map, traverse, consume the children tree and just render what you needs (like just a `<canvas/>`). But this is probably a mistake! First, this makes it impossible to use React Devtools and see the original tree, but more importantly, it breaks interoperability with other libraries (e.g. don\'t forbid someone to use [react-motion](https://github.com/chenglou/react-motion) or [React Router](https://github.com/ReactTraining/react-router) in the middle of your components!).\n\nA better idea is to preserve the user `children`. Keep your logic in each Component and use the React lifecycle to create and destroy things, and **use [React context](https://facebook.github.io/react/docs/context.html) to connect children to parent**.\n\n> You should better keep user `children`, even if it means rendering it in an empty `<span>`, _current workaround of `gl-react`, looking forward to hearing from you, idea inspired from the great [react-music](https://github.com/FormidableLabs/react-music)_\n\n### What it means for gl-react\n\nThe gl-react v3 implementation truly uses React lifecycle: **a React Component update triggers a GL redraw**. That way, `shouldComponentUpdate` allows to do partial GL re-rendering. Each Node holds a [framebuffer object](https://www.opengl.org/wiki/Framebuffer_Object) (created on mount, destroyed on unmount) that only get redrawn when component updates and schedules a Surface reflow.\n\n`<Node>` receives the `gl: WebGLRenderingContext` from the ancestor `<Surface>` thanks to [React context](https://facebook.github.io/react/docs/context.html). There is also a `glParent` context (a Surface or another Node) that is used to make GL components discoverable each other so we can build a dependency graph. This dependency graph allows to implement the correct `draw` pipeline (and it\'s pretty trivial, see [_Section "under the hood of Surface and Node redraw"_](#under_the_hook_redraw)).\n\n## `<Bus>`, a better way to share computation\n\n[gl-react used to automatically factorize the duplicates elements of the GL tree](http://greweb.me/2016/06/glreactconf/) but **it has been decided to remove this feature**: _This was actually a complex mechanism (a bit too "magic"), hard to implement and a premature optimization that can have slower performance._\n\nThe new gl-react embraces the React paradigm: The new way to express a Graph (and share computation) is **using a [`<Bus>`][bus]**...\n\n### The `` `()=>ref` `` pattern\n\nThe problem we want to solve is to **express a graph with React**, which, at first glance, only allow to represent trees, not graphs!\n\nThe way we can solve this is by using refs and a "ref getter function":\n\n1. **a Bus with a ref:** `<Bus ref="myBus">{content to inject}</Bus>`.\n2. **pass a function that resolves the ref** to pipe Bus into another Node. e.g: `()=>this.refs.myBus`.\n\n[blurmapdyn example ![](/images/2016/12/blurmapdyn.gif)](https://gl-react-cookbook.surge.sh/blurmapdyn)\na single ConicalGradient should be used for all blur pass:\n![](/images/2016/12/blurmapdynschema.png)\n\nThere are a few other good examples of ref usages:\n\n- [blurmapmouse](https://gl-react-cookbook.surge.sh/blurmapmouse)\n- [blurimgtitle](https://gl-react-cookbook.surge.sh/blurimgtitle) (same example that was features in 2016 React conf!)\n- [behindasteroids](https://gl-react-cookbook.surge.sh/behindasteroids), crazy port of a game I made for js13k.\n\n> The `()=>ref` pattern works only if you call the function after component did update (refs are set at this time).\n\n## The good ol\' children function\n\nThere is another pattern for more specific needs: instead of composing by giving an element, you can also compose by giving a **Function that returns an element**. Why that? Because, it\'s a way to nicely give you the redraw function: `redraw => <Video onFrame={redraw} />`:\n\n[Checkout video example ![](/images/2016/12/videoredraw.png)](https://gl-react-cookbook.surge.sh/video?menu=true)\n\n> We really just want to redraw if there is a new video frame.\n\nWe have merged the 2 patterns into one: if you provide a function, it\'s just called with `redraw`, and the returned value is used as a texture. We have a few cases to detect what kind of texture it is (and also an [extensible mechanism](https://gl-react-cookbook.surge.sh/api#textureloaders) used by implementations to load platform specific objects).\n[(checkout this if you want to see the code)](https://github.com/gre/gl-react/blob/a33e6aa685479d588646b20dd62e1e25a64a5a47/packages/gl-react/src/Node.js#L704-L783)\n\n## Node backbuffering & Backbuffer symbol\n\nA new feature allows to inject the previous Node state as a texture. This is called backbuffering. One simple usecase is to implement Motion Blur persistence (like the GIF on top of this article).\n\nWe can also accumulate a state, for instance, to implement Game of Life!\n\n[Game of life glider example ![](/images/2016/12/gol.gif)](https://gl-react-cookbook.surge.sh/golglider)\n\nAnd the whole idea of gl-react (and React) is about composition. For instance, doing a rotating effect of that Game of Life is basically just `<Rotate> <GameOfLife /> </Rotate>`.\n\nAn interesting part is that you can update the GameOfLife at a rate that is independent from the **Rotate** rendering: just by making GameOfLife a pure component that receives a tick, or implementing shouldComponentUpdate update (you have as many choices as React have to [shortcut the rendering](https://facebook.github.io/react/docs/react-api.html#react.purecomponent)).\n\n[golrotscu example![](/images/2016/12/golrot.gif)](https://gl-react-cookbook.surge.sh/golrotscu)\n\n> See the counters that indicate the number of redraw. (the capture preview in the Box only get snapshot each 100ms, but in the real canvas, it runs at 60 FPS)\n\nFinally, please checkout [ibex example](https://gl-react-cookbook.surge.sh/ibex) (extracted from another JS13K game! xD).\n\n> You can\'t leave this article before seeing [ibex example](https://gl-react-cookbook.surge.sh/ibex)! I\'m serious, this is probably the most accomplished code I ever wrote! xD\n\n## <a name="under_the_hook_redraw"></a> under the hood of Surface and Node redraw\n\nIn order to make redraw efficient, `gl-react` have 2 phases: the `redraw()` phase and the `flush()` phase (reflecting the respective methods available both on `Surface` and `Node`). This is a bit like a rendering engine:\n\n- **`redraw()` phase** sets a dirty flag to a Node and all its "dependents" (other nodes, buses, surface). _redraws happen generally bottom-up to the Surface._\n- **`flush()` phase** draws all nodes that have the redraw flag. _draws happens top-down from the Surface._\n\n`redraw()` is directly hooked to React update lifecycle (re-rendering a Node will calls `redraw()` for you).\nTo make this system efficient, **the flush() is by default asynchronous**, i.e. `redraw()` means scheduling a new gl draw.\nSurface have a main loop that runs at 60 fps and call `flush()`. This is very efficient because if Surface does not have the redraw flag, `flush()` does nothing.\n\n> In gl-react inspector, clicking on the redraw count will call `redraw()` on the node / bus. We can illustrate that only "dependents" get redrawn using the advanced [blurimgtitle example](https://gl-react-cookbook.surge.sh/blurimgtitle):\n\n[only "dependents" get redrawn ![](/images/2016/12/blurimgtitle-redraw.gif)](https://gl-react-cookbook.surge.sh/blurimgtitle)\n\nThis redraw/flush phases allow to prevent and skip rendering multiple times a Node. In some cases, we still want to redraw synchronously: with `<Node/>` `sync` prop. For instance, in Game of Life, we don\'t want to skip an update (the initial update set the initial GoL state, if it was async it might get skipped).\n\n## Bonus\n\n### Flow types\n\nFlow types has been used for more robust code and better user experience. BTW, [WebGLRenderingContext will soon be released in flow](https://github.com/facebook/flow/pull/2764).\n\n### Atom highlighting\n\nIf you are using Atom Editor, you can have JS inlined GLSL syntax highlighted.\n\n![](https://cloud.githubusercontent.com/assets/211411/20623048/0527cce2-b306-11e6-85ee-5020be994c10.png)\n\n_To configure this:_\n\n- add `language-babel` package.\n- Configure `language-babel` to add `GLSL:source.glsl` in settings "_JavaScript Tagged Template Literal Grammar Extensions_".\n- (Bonus) Add this CSS to your _Atom > Stylesheet_:\n\n```css\n/* language-babel blocks */\natom-text-editor::shadow .line .ttl-grammar {\n  /* NB: designed for dark theme. can be customized */\n  background-color: rgba(0, 0, 0, 0.3);\n}\natom-text-editor::shadow .line .ttl-grammar:first-child:last-child {\n  display: block; /* force background to take full width only if ttl-grammar is alone in the line. */\n}\n```\n\n### Tests: almost 100% coverage!\n\nThe library is tested directly on the command line, thanks to [Jest][jest] and [headless-gl][headless-gl] _(Big up to [mikolalysenko](https://github.com/mikolalysenko) for [headless-gl][headless-gl]!)_.\n**gl-react have 2000 line of tests, involving a lot of gl calls, and readPixels, and it runs... in a few seconds!** _(to Jest devs: you are wizards!)_\n\n```\n\n PASS  ./all.test.js\n  \u2713 renders a red shader (75ms)\n  \u2713 renders HelloGL (15ms)\n  \u2713 ndarray texture (27ms)\n  \u2713 renders a color uniform (18ms)\n  \u2713 composes color uniform with LinearCopy (21ms)\n  \u2713 no needs to flush if use of sync (24ms)\n  \u2713 Node can have a different size and be scaled up (18ms)\n  \u2713 Surface can be resized (32ms)\n  \u2713 bus uniform code style (17ms)\n  \u2713 bus example 1 (17ms)\n  \u2713 bus example 2 (18ms)\n  \u2713 bus example 3 (17ms)\n  \u2713 bus example 4 (22ms)\n  \u2713 bus example 5 (14ms)\n  \u2713 bus example 6 (24ms)\n  \u2713 bus: same texture used in multiple sampler2D is fine (14ms)\n  \u2713 a surface can be captured and resized (16ms)\n  \u2713 a node can be captured and resized (17ms)\n  \u2713 Uniform children redraw=>el function (22ms)\n  \u2713 Bus redraw=>el function (16ms)\n  \u2713 many Surface updates don\'t result of many redraws (18ms)\n  \u2713 many Surface flush() don\'t result of extra redraws (10ms)\n  \u2713 GL Components that implement shouldComponentUpdate shortcut Surface redraws (27ms)\n  \u2713 nested GL Component update will re-draw the Surface (24ms)\n  \u2713 Node `clear` and discard; (24ms)\n  \u2713 Node `backbuffering` (32ms)\n  \u2713 Node `backbuffering` in `sync` (36ms)\n  \u2713 texture can be null (12ms)\n  \u2713 array of textures (22ms)\n  \u2713 Node uniformsOptions texture interpolation (17ms)\n  \u2713 can be extended with addTextureLoaderClass (70ms)\n  \u2713 Surface `preload` prevent to draw anything (59ms)\n  \u2713 Surface `preload` that fails will trigger onLoadError (59ms)\n  \u2713 renders a shader inline in the Node (15ms)\n  \u2713 testing connectSize() feature (17ms)\n  \u2713 handle context lost nicely (43ms)\n  \u2713 Bus#uniform and Bus#index (25ms)\n  \u2713 VisitorLogger + bunch of funky extreme tests (140ms)\n\n-------------------------------|----------|----------|----------|----------|----------------|\nFile                           |  % Stmts | % Branch |  % Funcs |  % Lines |Uncovered Lines |\n-------------------------------|----------|----------|----------|----------|----------------|\nAll files                      |    97.85 |     88.8 |    95.96 |    99.35 |                |\n src                           |    97.82 |    88.95 |     95.9 |    99.35 |                |\n  Backbuffer.js                |      100 |      100 |      100 |      100 |                |\n  Bus.js                       |    96.15 |    74.29 |      100 |      100 |                |\n  GLSL.js                      |      100 |       50 |      100 |      100 |                |\n  LinearCopy.js                |      100 |      100 |      100 |      100 |                |\n  NearestCopy.js               |      100 |      100 |      100 |      100 |                |\n  Node.js                      |    97.65 |    92.71 |    97.01 |    99.01 |    214,216,358 |\n  Shaders.js                   |      100 |    76.92 |      100 |      100 |                |\n  Texture2DLoader.js           |      100 |      100 |      100 |      100 |                |\n  TextureLoader.js             |      100 |      100 |      100 |      100 |                |\n  TextureLoaderNDArray.js      |      100 |      100 |      100 |      100 |                |\n  TextureLoaders.js            |      100 |      100 |      100 |      100 |                |\n  Visitor.js                   |      100 |      100 |       75 |      100 |                |\n  VisitorLogger.js             |      100 |    92.59 |      100 |      100 |                |\n  Visitors.js                  |      100 |      100 |      100 |      100 |                |\n  connectSize.js               |      100 |    85.71 |      100 |      100 |                |\n  copyShader.js                |      100 |      100 |      100 |      100 |                |\n  createSurface.js             |    97.09 |    83.61 |    94.55 |    99.32 |            361 |\n  genId.js                     |      100 |      100 |      100 |      100 |                |\n  index.js                     |      100 |      100 |      100 |      100 |                |\n src/helpers                   |      100 |       75 |      100 |      100 |                |\n  disposable.js                |      100 |       50 |      100 |      100 |                |\n  invariantNoDependentsLoop.js |      100 |      100 |      100 |      100 |                |\n-------------------------------|----------|----------|----------|----------|----------------|\nTest Suites: 1 passed, 1 total\nTests:       38 passed, 38 total\nSnapshots:   4 passed, 4 total\nTime:        2.655s\nRan all test suites.\n```\n\nOne limitation is that all tests need to be in a single file. [I created an issue here](https://github.com/facebook/jest/issues/2029). I think it\'s either an issue in [Jest][jest] or in [headless-gl][headless-gl].\n\n## Tradeoffs and remaining work\n\nThe library tradeoffs are written in [TRADEOFFS.md](https://github.com/gre/gl-react/blob/master/TRADEOFFS.md). We might cover some unexplored direction in a near future and solve some of them.\n\nv3 is still in development, the main unfinished part is the React Native implementation which is now the main priority of the library.\nIt will probably rely on an awesome initiative: a React Native WebGL implementation started in Exponent by [@nikki](https://github.com/nikki93)!\n\nFor more information, see [v3 alpha: development in progress](https://github.com/gre/gl-react#v3-alpha-development-in-progress).\n'},BHC3:function(e,n,t){"use strict";t.r(n),n.default=""},BHSx:function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: 'Tutoriel Canvas : R\xe9aliser une banni\xe8re anim\xe9e en quelques lignes de code'\nthumbnail: /images/2010/animated_banner.png\ndescription: Ce tutoriel vise \xe0 pr\xe9senter canvas comme une librairie tr\xe8s simple d\u2019utilisation et haut niveau gr\xe2ce au langage javascript.\nauthor: Gaetan\nlayout: post\npermalink: /2010/02/tutoriel-canvas-realiser-une-banniere-animee-en-quelques-lignes-de-code\ntags:\n  - animation\n  - canvas\n  - javascript\n  - bezier\n---\n\n [1]: /2011/03/html-canvas-pour-les-neophytes\n [2]: /demo/animate-banner/canvas-cartesian.png\n [3]: /demo/animate-banner/step1.html\n [4]: /demo/animate-banner/bezier-schema.png\n [5]: /demo/animate-banner/step2.html\n [6]: /demo/animate-banner/bezier-exemple.png\n [7]: http://paulirish.com/2011/requestanimationframe-for-smart-animating/\n [8]: /demo/animate-banner/step3.html\n [9]: /demo/animate-banner/step4.html\n [10]: /demo/animate-banner/step5.html\n [11]: /demo/animate-banner/step6.html\n [12]: /demo/animate-banner/final.html\n\n![](/images/2010/animated_banner.png)\n\n**Pr\xe9-requis conseill\xe9: [Voir la vid\xe9o : HTML Canvas pour les n\xe9ophytes][1]**\n\nLe **HTML 5** int\xe8gre de nouvelles technologies comme le **canvas**, une v\xe9ritable API graphique destin\xe9e \xe0 remplacer le flash dans les ann\xe9es \xe0 venir.\n\nCe tutoriel vise \xe0 pr\xe9senter **canvas** comme une **librairie tr\xe8s simple d\u2019utilisation et haut niveau** gr\xe2ce au langage **javascript**.\n\nIl vous apprendra \xe0 r\xe9aliser une animation similaire \xe0 la banni\xe8re <del>actuelle</del> (ancienne maintenant) de mon blog en **quelques lignes de code**.\n\n\nIl est volontairement ordonnanc\xe9 de mani\xe8re didactique, si vous maitriser les concepts, n\u2019h\xe9sitez pas \xe0 avancer.\n\n\x3c!--more--\x3e\n\n## Code de base (skeleton template)\n\nNous allons travailler avec ce code **html** de base :\n\n```html\n<!DOCTYPE html>\n<html>\n  <head><title></title></head>\n  <body>\n    <canvas id=\"tuto\" width=\"500\" height=\"100\" style=\"border: 1px solid;\"></canvas>\n    <script language=\"javascript\">\n      var canvas = document.getElementById('tuto');\n      var ctx = canvas.getContext('2d');\n\n      // Le code javascript ira ici\n\n    <\/script>\n  </body>\n</html>\n```\n\nCe code nous servira dans tous le reste du tutoriel. \n\n### Deux choses notables :\n\n* Nous avons cr\xe9\xe9 un \xe9l\xe9ment **canvas** et indiqu\xe9 ses dimensions **(500\xd7100)**. Pour mieux pouvoir rep\xe9rer ses dimensions, nous lui avons ajout\xe9 une bordure.\n* En **javascript**, nous avons r\xe9cup\xe9r\xe9 l\u2019\xe9l\xe9ment DOM puis le contexte 2d qui nous servira pas la suite.\n\n## Quelques notions de base du canvas\n\n### La surface du canvas\n\nLe **canvas** occupe une surface dont la dimension est d\xe9finie par les param\xe8tres *width* et *height*.\n\nPour ceux qui ne serait pas familier avec les **biblioth\xe8ques graphiques**, cette surface peut \xeatre vu comme un quadrillage de pixel sur **deux dimensions** : **x** variant de *0 \xe0 width* et **y** variant de *0 \xe0 height*.\n\nLe point d\u2019origine de ce rep\xe8re orthonorm\xe9 est situ\xe9 **dans le coin haut gauche du canvas**:\n\n![][2]\n\n### Le concept de contexte\n\nLe contexte 2d r\xe9cup\xe9r\xe9 dans la variable **ctx** est en fait l\u2019**interface de programmation** (API) de la biblioth\xe8que graphique **canvas**.\n\nC\u2019est en quelque sorte l\u2019**interm\xe9diaire entre le programmeur et la biblioth\xe8que graphique**.\n\nAinsi par exemple, si l\u2019on veux dessiner un rectangle de dimension **20\xd710** \xe0 la position **(5,6)**, il suffit simplement d\u2019\xe9crire: \n\n```javascript\nctx.fillRect(5,6,20,10)\n```\n\n### Les param\xe8tres globaux du canvas\n\nPour dessiner, toute librairie graphique a besoin de connaitre un certain nombre de param\xe8tres tels que la *couleur du trait, la taille de la brosse, etc*.\n\nPlut\xf4t que de devoir passer en param\xe8tre ces informations aux fonctions du contexte, **canvas** met directement \xe0 disposition ses param\xe8tres afin de pouvoir les modifier facilement.\n\nAinsi, nous pourrons d\xe9finir la couleur de remplissage dans **ctx.fillStyle** et la couleur de trait dans **ctx.strokeStyle**.\n\n## Commen\xe7ons \xe0 coder\n\nAvant d\u2019attaquer l\u2019animation, nous allons commencer \xe0 manier les **outils de tracage**.\n\n### Chemins et traits simples\n\nNous allons commencer par tracer un trait simple qui va traverser tous le canvas.\n\nEssayez le code suivant:\n\n```javascript\nctx.beginPath(); \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0// commence \xe0 tracer un chemin  \nctx.moveTo(, 20); \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 // d\xe9fini le premier point de tracage \xe0 la position (0, 20)  \nctx.lineTo(canvas.width, 30); // Tracer une ligne jusqu'\xe0 la position (canvas.width, 30). canvas.width d\xe9signe la largeur du canvas (500 dans notre exemple).  \nctx.stroke(); \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 // Indique au canvas de dessiner le chemin trac\xe9 depuis le beginPath\n```\n\n[Voir le r\xe9sultat][3]\n\n### Chemins et courbes de b\xe9zier\n\n#### La notion de courbe de b\xe9zier\n\nUne courbe de b\xe9zier est d\xe9finie par 4 points :\n\n*   Deux points d\xe9signant le d\xe9but et la fin du trait.\n*   Deux points appel\xe9s **poign\xe9es** permettant de contr\xf4ler la courbe.\n\n![][4]\n\n#### Application en canvas\n\nEssayez le code suivant :\n\n```javascript\nctx.beginPath();  \nctx.moveTo(, 20);  \nctx.bezierCurveTo(canvas.width/3, canvas.height, 2*canvas.width/3, , canvas.width, 20);  \nctx.stroke();\n```\n\n[Voir le r\xe9sultat][5]\n\n**De la m\xeame fa\xe7on, la proc\xe9dure consiste \xe0:**\n\n* commencer un chemin,\n* se placer \xe0 une certaine position,\n* effectuer un tra\xe7age (courbe de b\xe9zier),\n* terminer le tra\xe7age (**ctx.stroke()**).\n\nInt\xe9ressons nous plus particuli\xe8rement au tra\xe7age de la courbe de b\xe9zier avec l\u2019appel de **ctx.bezierCurveTo**.\n\n##### bezierCurveTo(cp1x, cp1y, cp2x, cp2y, x, y)\n\nCette fonction prends en argument les coordonn\xe9es du premier point de contr\xf4le **(cp1x, cp1y)**, du deuxi\xe8me point de contr\xf4le **(cp2x, cp2y)** et du point final **(x, y)**. A noter que le point de d\xe9but est le point sur lequel on s\u2019est plac\xe9 au moyen de **moveTo**.\n\n**Dans notre exemple, les deux points de contr\xf4le sont plac\xe9s ainsi :**\n\n![][6]\n\n### Ajout de l\u2019animation\n\nPour animer notre courbe de b\xe9zier, nous allons faire varier les 4 points de notre courbe en fonction du temps.\n\nEn javascript, il y a deux moyen d\u2019effectuer une animation :\n\n* <del>Au moyen de **setInterval** permettant d\u2019appeler une fonction par interval de temps r\xe9gulier.</del>\n* <del>Au moyen de **setTimeout** permettant d\u2019appeler une fonction apr\xe8s un temps donn\xe9.</del>\n* **[UPDATE 2011]** Il est maintenant recommand\xe9 d\u2019utiliser **requestAnimationFrame** qui est l\u2019\xe9quivalent de setTimeout mais destin\xe9 \xe0 l\u2019animation donc plus performant. [Plus d\u2019informations i\xe7i (en)][7]\n\nLa premi\xe8re approche est parfaite pour une animation **\u201cstatique\u201d, avec peu d\u2019int\xe9raction**.\n\nLa seconde approche est int\xe9ressante lorsque l\u2019animation **doit \xeatre contr\xf4l\xe9e** (int\xe9raction). En effet, cette approche consiste \xe0 appeler setTimeout \xe0 chaque cycle d\u2019animation.\n\nNous choisirons d\u2019utiliser **setInterval**, plus simple et plus adapt\xe9e \xe0 notre tutoriel.\n\n#### Approche lin\xe9aire\n\nCommen\xe7ons simplement par une **\xe9volution lin\xe9aire des points**.\n\nEssayez le code suivant :\n\n```javascript\nvar i = 0; // variable fonction du temps\nvar cycle = function() {\n  ctx.clearRect(0,0,canvas.width,canvas.height); // clean the canvas\n  var y = Math.abs(canvas.height-i%(2*canvas.height)); // y \xe9volue par rebond entre 0 et canvas.height au cours du temps (lin\xe9arit\xe9)\n  ctx.beginPath();\n  ctx.moveTo(0, y);\n  ctx.bezierCurveTo(canvas.width/3, canvas.height/2, 2*canvas.width/3, canvas.height/2, canvas.width, y);\n  ctx.stroke();\n  i++;\n};\nsetInterval(cycle, 30); // lance le cycle chaque 30 millisecondes\n```\n\n[Voir le r\xe9sultat][8]\n\nPour l\u2019instant les poign\xe9es sont fixes et l\u2019\xe9volution lin\xe9aire de **y** donne un effet de rebond peu int\xe9r\xe9ssant.\n\nC\u2019est pour cela que nous abandonnons l\u2019id\xe9e d\u2019une \xe9volution lin\xe9aire des positions au cours du temps pour l\u2019approche sinuso\xefdale.\n\n#### Approche sinuso\xefdale\n\nComme nous l\u2019avons vu, l\u2019\xe9volution lin\xe9aire n\u2019est pas adapt\xe9e pour ce genre d\u2019animation (effet de rebond). Il faudrait rendre l\u2019animation plus fluide.\n\nPour cela, nous allons utiliser **une \xe9volution sinuso\xefdale des positions au cours du temps**.\n\nEssayez le code suivant :\n\n```javascript\nvar i = 0; // variable fonction du temps\nvar cycle = function() {\n  ctx.clearRect(0,0,canvas.width,canvas.height);\n  var offset = i/20;\n  var y = (Math.sin(offset)+1)*canvas.height/2; // y varie de 0 \xe0 canvas.height\n  var cpy1 = (Math.cos(offset)+0.5)*canvas.height; // les poign\xe9es \xe9voluent \xe9galement de fa\xe7on sinuso\xefdale\n  var cpy2 = canvas.height - cpy1;\n  ctx.beginPath();\n  ctx.moveTo(0, y);\n  ctx.bezierCurveTo(canvas.width/3, cpy1, 2*canvas.width/3, cpy2, canvas.width, y);\n  ctx.stroke();\n  i++;\n};\nsetInterval(cycle, 30);\n```\n\n[Voir le r\xe9sultat][9]\n\n### Peaufinage\n\n#### Am\xe9lioration du style du trait\n\nEssayez le code suivant :\n\n```javascript\nctx.strokeStyle = 'rgba(80,150,240,0.5)'; // couleur bleu avec opacit\xe9 de 50%\nctx.lineWidth = 5; // \xe9paisseur de trait de 5 pixels\nvar i = 0;\nvar cycle = function() {\n  ctx.clearRect(0,0,canvas.width,canvas.height);\n  var offset = i/20;\n  var y = (Math.sin(offset)+1)*canvas.height/2;\n  var cpy1 = (Math.cos(offset)+0.5)*canvas.height;\n  var cpy2 = canvas.height - cpy1;\n  ctx.beginPath();\n  ctx.moveTo(0, y);\n  ctx.bezierCurveTo(canvas.width/3, cpy1, 2*canvas.width/3, cpy2, canvas.width, y);\n  ctx.stroke();\n  i++;\n};\nsetInterval(cycle, 30);\n```\n\n[Voir le r\xe9sultat][10]\n\n#### Ajout de plusieurs courbes\n\nPour avoir un effet plus accrochant, nous allons ajouter plusieurs courbes de b\xe9zier avec un d\xe9calage temporel entre elles.\n\nNous allons \xe9galement attribuer plusieurs styles aux diff\xe9rentes courbes.\n\n```javascript\nvar numberOfLines = 5;\nvar i = 0;\nvar cycle = function() {\n  ctx.clearRect(0,0,canvas.width,canvas.height);\n  for(var j=0; j<numberOfLines; ++j) {\n    var offset = (i+j*10)/20;\n    ctx.lineWidth = 1+2*(numberOfLines-j); // \xe9paisseur variable en fonction de la ligne\n    ctx.strokeStyle = 'rgba(80,150,240,'+(j/5+0.1)+')'; // opacit\xe9 variable en fonction de la ligne\n    var y = (Math.sin(offset)+1)*canvas.height/2;\n    var cpy1 = (Math.cos(offset)+0.5)*canvas.height;\n    var cpy2 = canvas.height - cpy1;\n    ctx.beginPath();\n    ctx.moveTo(0, y);\n    ctx.bezierCurveTo(canvas.width/3, cpy1, 2*canvas.width/3, cpy2, canvas.width, y);\n    ctx.stroke();\n  }\n  i++;\n};\nsetInterval(cycle, 30);\n```\n\n[Voir le r\xe9sultat][11]\n\n### Aller plus loin\n\nIl est possible de continuer encore plus loin en ajoutant l\u2019**\xe9volution de plusieurs param\xe8tres en fonction du temps**.\nPour conclure, voici la d\xe9monstration finale:\n\n```javascript\nvar i = 0;\nvar cycle = function() {\n  ctx.clearRect(0, 0, canvas.width, canvas.height);\n  for(var j=0; j<numberOfLines; ++j) {\n    ctx.lineWidth = 1+2*(numberOfLines-j);\n    ctx.strokeStyle = 'rgba(100,200,'+Math.floor(Math.abs(Math.cos(i/80)*256))+','+(j/5+0.1)+')';\n    var offset = (i+j*10*Math.abs(Math.cos(i/100)))/20;\n    var y = (Math.sin(offset)+1)*canvas.height/2;\n    var cpy1 = (Math.cos(offset)+0.5)*canvas.height;\n    var cpy2 = canvas.height - cpy1;\n    ctx.beginPath();\n    ctx.moveTo(0, y);\n    ctx.bezierCurveTo(canvas.width/3, cpy1, 2*canvas.width/3, cpy2, canvas.width, y);\n    ctx.stroke();\n  }\n  i++;\n};\nsetInterval(cycle, 30);\n```\n[Voir le r\xe9sultat][12]\n\nNous avons ajout\xe9:\n\n* L\u2019\xe9volution de la **couleur** au cours du temps.\n* L\u2019\xe9volution du **d\xe9calage entre les courbes** au cours du temps.\n"},BbHa:function(e,n,t){"use strict";var a=t("NdRM");e.exports=new a("tag:yaml.org,2002:str",{kind:"scalar",construct:function(e){return null!==e?e:""}})},Bir5:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Growing parametric 14-20"\nthumbnail: /images/plots/114.jpg\ndescription: "stacking multiple parametric functions. Sakura Gelly Roll on black A4, revealing artifacts of the paper."\ntags:\n  - parametric\n---\n\nAnother parametric functions. Inspired from [plot#111](/plots/111) idea: stacking multiple parametric functions. The parametric used is\n\n```rust\nlet parametric = |t, p| {\n  (\n    (0.2 + 0.7 * p) * (2. * PI * t).sin()\n        + 0.1 * (14. * PI * t).sin(),\n    (0.2 + 0.8 * p) * (2. * PI * t).cos()\n        + 0.2 * (20. * PI * t).cos(),\n  )\n};\n```\n\nSakura Gelly Roll on black A4, revealing artifacts of the paper.\n'},"C+rD":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Blurry elevation"\nthumbnail: /images/plots/191.jpg\ndescription: "Lines elevation with perlin-noise warping. Fountain pen and \'Bloody Brexit\' ink on watercolour paper (300g/m)."\n---\n\nLines elevation with perlin noise warping. Fountain pen and \'Bloody Brexit\' ink on watercolour paper (300g/m).\n\nVarious other experiments:\n\n<img width="100%" src="/images/plots/191b.jpg">\n\n<img width="100%" src="/images/plots/191c.jpg">\n\n<img width="100%" src="/images/plots/191d.jpg">\n'},COZH:function(e,n,t){"use strict";t.r(n),n.default=""},CgTJ:function(e,n,t){"use strict";t.r(n),n.default=""},CybH:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle:  \ud83c\udf89 There are some OpenGL in the Project September fashion app!\nauthor: Gaetan\nlayout: post\ntags:\n  - react\n  - opengl\n  - gl-react\n---\n\n[twitter]: https://twitter.com/ProjSeptEng\n[website]: https://projectseptember.com\n[RN]: http://facebook.github.io/react-native/\n[graphql]: http://graphql.org/\n[scala]: http://scala-lang.org/\n[glreactconf]: /2016/06/glreactconf\n[glreact]: https://github.com/ProjectSeptemberInc/gl-react\n[glreactdom]: https://github.com/ProjectSeptemberInc/gl-react-dom\n[glreactnative]: https://github.com/ProjectSeptemberInc/gl-react-native\n[RNAnimation]: https://facebook.github.io/react-native/docs/animations.html\n\n \ud83c\udf89 Hooray! [We][twitter] recently released an iOS app called [Project September][website].\n\nThis application is built with nice tech stack including [React Native][RN] and [GraphQL][graphql]. The backend is powered by [Scala][scala], a robust functional language, and we use many other [cool techs][twitter].\n\nThis fashion app needed some fancy features: one was demo-ed at last [React.js conference][glreactconf] with the ability to do localized blur on text over images.\n\nWe have developed **[`gl-react`][glreact]** to abstract GL in React paradigm \u2013 with two companion libraries [`gl-react-dom`][glreactdom] and [`gl-react-native`][glreactnative] that glues React Native with OpenGL.\n\nLet\'s first see 2 demos of OpenGL usage in our app, and then we\'ll write a bit about how it\'s hard to get animations right.\n\n\x3c!--more--\x3e\n\n## The Text Over Image blur\n\n### The goal\n\n<img width="50%" src="/images/2016/07/current-1.png" /><img width="50%" src="/images/2016/07/current-2.png" />\n\n### How it works\n\n<img src="/images/2016/07/initial.png" />\n\n**+** ***(layer)***\n\n<img src="/images/2016/07/layer.png" />\n\n**=**\n\n<img src="/images/2016/07/result.png" />\n\n\n### Under the hood\n\n- The shadow intensity, size, position, is procedurally generated, we can adjust that. The shadow color is the blurry image color\n- The text color is determined by the color picked in blurred image at the shadow middle position. **If the `monochrome` value of that color is lower than 60%**, text will be white, otherwise text will be black.\n\nHere is more detail on how the shadow is generated:\n\n\n<img src="/images/2016/07/under-1.png" />\n\n\n**\\* (multiply alpha)**\n\n<img src="/images/2016/07/under-2.png" />\n\n**=**\n\n<img src="/images/2016/07/under-3.png" />\n\n**+ (layer)**\n\n<img src="/images/2016/07/under-4.png" />\n\n**=**\n\n<img src="/images/2016/07/layer.png" />\n\n### Fragment shader\n\n```glsl\nprecision highp float;\nvarying vec2 uv;\n\nuniform sampler2D img;\nuniform sampler2D imgBlurred;\nuniform sampler2D txt;\n\nconst vec2 shadowCenter = vec2(0.5, 0.9);\nconst vec2 shadowSize = vec2(0.6, 0.2);\nfloat shadow () {\n  return 0.8 * smoothstep(1.0, 0.2, distance(uv / shadowSize, shadowCenter / shadowSize));\n}\nfloat monochrome (vec3 c) {\n  return 0.2125 * c.r + 0.7154 * c.g + 0.0721 * c.b;\n}\nvec3 textColor (vec3 bg) {\n  return vec3(step(monochrome(bg), 0.6));\n}\n\nvoid main () {\n  vec4 bg = mix(texture2D(img, uv), texture2D(imgBlurred, uv), shadow());\n  vec4 fg = vec4(textColor(texture2D(imgBlurred, shadowCenter).rgb), 1.0);\n  float fgFactor = 1.0 - texture2D(txt, uv).r;\n  gl_FragColor = mix(bg, fg, fgFactor);\n}\n```\n\n### Integration\n\n```html\n<GL.Node shader={shaders.textOverImage}>\n  <GL.Uniform name="img">\n    {img}\n  </GL.Uniform>\n  <GL.Uniform name="imgBlurred">\n    <Blur factor={20} passes={6} width={width} height={height}>\n      {img}\n    </Blur>\n  </GL.Uniform>\n  <GL.Uniform name="txt">\n    <Text style={titleStyle}>{title}</Text>\n  </GL.Uniform>\n</GL.Node>\n```\n\n## Uploading Thumbnail\n\nThis is a video record of our app:\n\n![](/images/2016/07/upload.gif)\n\nThe uploading spinner effect is implemented with an OpenGL shader. This was not easy to avoid all the blinks we used to have. We have different components to render each step (uploading animation / uploaded final image) and the uploaded image needs to be downloaded again to not render as white. One solution could be to use a monolithic "thumbnail" component that do everything. We wanted to  keep independent components.\nHopefully, everything now works seamlessly with some "double buffering"/swapping mechanism we will explained at the end of this article.\n\n## Animate all the things\n\n### Designing animations\n\n> Fluid, meaningful animations are essential to the mobile user experience.\n**[\u2014 React Native Animations documentation][RNAnimation]**\n\nIt\'s not easy to design how an application should animate, to define transitions between all the different possible single state and edge-cases of your app. Designing animations, as part of UX design, is a time consuming work but it tends to be underestimated while being essential for moving from a *good app* to a *very good app*. That tends to be the last 20% remaining missing parts of your app that are the hardest but that makes the 80% of a great UX.\n\n### Implementing animations\n\nNot only it\'s hard to have figured out the animations (to find the optimal UX) but it can also be quite challenging to implement them in a maintainable and robust way. Turns out most of the times, your code is not ready for it and it implies big refactoring.\n\n#### in React Native\n\nReact Native [Animations API][RNAnimation] makes it easier: you just have to switch to one of the `Animated.*` component. In `gl-react` we even support Animated values to flow into the shaders uniforms so it\'s very convenient to animate a GL effect.\n\nThat said, React Native Animations is not the ultimate silver bullet. There are things Animations won\'t solve for you. React Native Animated is still a low level API, it\'s also imperative and not opinionated on how you should turn it into descriptive paradigm.\n\nI guess what\'s generally hard with animations in React functional/descriptive paradigm ("always `render()`ing Virtual DOM again" idea) is to figure out **how to not "break" your animations**. For instance, ugly animation interruption could happen if you `render()` a different component: because it forces the component to unmount. If you have an animation happening, you might not want it to stop, or at least you might want to smoothly customize the transition to the new state.\n\nThat\'s something CSS transitions might help solving, but in React Native we don\'t have them, so it\'s not so trivial.\n\n##### our current solution\n\nWe have built our own abstraction to solve this problem: a Component decorator manages to kill a lot of flashes and blinks cases (e.g. images not ready yet, animation getting interrupted).\n\n> What the decoration solves: when moving from A to B, you want B to be ready (e.g. images are loaded), you also want A to have finish its (animated) work.\n\n**A component can express it needs some time to mount *(e.g. an image to load!)* OR that it needs some time to unmount *(e.g. an "animating out")*. This will basically hold the rendering to happen:**\n\nThe decoration can implement "double buffering" on a Component: `render()` function keeps rendering Component with the previous "stable props" but will also render in background another instance of Component with the next props. When that next props Component is ready and loaded, we can successful swap it to be the new "stable props".\n\nYou have the basic idea, the decorator is not so trivial to implement as it also needs to handle some edge-cases, for instance if the decorator receives new props during the transition. We also have a minimal way to express "styles transitions" similarly to how CSS Transitions works.\n'},DKqw:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "triangle packing"\nthumbnail: /images/plots/181.jpg\ndescription: "Third iteration on packing iso triangles in a square. two fountain pens on 300g/m paper."\ntags:\n  - shape-packing\n---\n\nContinuation of [plot#180](/plots/180).\n\nThird iteration on packing iso triangles in a square. two fountain pens on 300g/m paper.\n'},DQgZ:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Dancing Planet"\nthumbnail: /images/plots/150.gif\ndescription: "8 frames plotted making an animated loop. A 1920p video and A4 physical art is available as an NFT."\ntags:\n  - field\n  - perlin\n  - plotloop\nobjkts:\n  - 105425\n---\n\n\x3c!--\n@greweb\'s #5 plot loop. The 1920p animation is the main digital art. NFT is available in 8 editions, one per frame. First buyer of each edition can collect related frame to acquire the physical art (selected by buy order. PM @greweb, ship anywhere in the world). Secondary market is digital only. plotted on A4 Bristol paper with fountain pen. See greweb.me/plots/150\n--\x3e\n\nHere is "Dancing Planet", my 5th [**plot loop**](/plots/tags/plotloop) [(see article)](https://greweb.me/2021/05/plot-loops). **The main digital art is a 1920p video loop of 8 frames available as a [Tezos hicetnunc NFT](https://www.hicetnunc.xyz/objkt/105425)**. The physical art are the 8 frames, plotted with 2 fountain pens on Bristol A4 paper (250g), and offered when [buying the NFT](https://www.hicetnunc.xyz/objkt/105425).\n\nThere are 8 plots available for sale and there will be no other editions of these plot loop frames. They all have the same inital price and the physical piece is selected in order of buy as each frame is relatively similar!\n\n<img src="/images/plots/150-plots.jpg" width="100%">\n\nThis is a reboot of [plot#148](/plots/148) but with a big rework of the noise technique using domain warping as well as combination with this famous \'rotating dancer\' GIF.\n\nIt is plotted with two phases, a first pass without a lot of noise and a second pass with more noise divergence:\n\n<img src="/images/plots/150-phases.gif" width="100%">\n\n<img src="/images/plots/150-zoom1.jpg" width="100%">\n<img src="/images/plots/150-zoom2.jpg" width="100%">\n<img src="/images/plots/150-zoom3.jpg" width="100%">\n\n## Early prototype, in pursuit of the good ink and paper...\n\nI started with this first prototype of the concept:\n\n<img src="/images/plots/150-proto1.jpg" width="100%">\n\nIt allowed me to see what I could adjust, for instance: adding more noise, more lines and scaling a bit the dancer.\n\nI used ink \'Quink\' by Parker plotted with a fountain pen on a Canson Bristol 250g paper (A4 format).\n\nHere is another prototype I tried: it uses a mix of two colors (dragon red and turquoise). **I ended up preferring minimalism: black on white. At the end I stayed on my first ink choice but I will revisit this idea.**\n\n<img src="/images/plots/150-proto2.jpg" width="57%"><img src="/images/plots/150-proto2-zoom.jpg" width="42.8%">\n\n## Process to find the final plot\n\nTo search for the good parameters I\'ve used a generator script with bash for loops. It kinda looked like this:\n\n```sh\nfor a in 0.5 1 2 4; do\nfor b in 0.5 1 2 4; do\nfor c in 0.5 1 2 4; do\nfor d in 0.5 1 2 4; do\n  sh $P/gen.sh --a $a --b $b --c $c --d $d\n  cp ./results/out.gif out/${a}_${b}_${c}_${d}.gif\ndone\ndone\ndone\ndone\n```\n\nThen I kept refining my "range" by fail and retry. It is quite slow to generate them so it\'s a long process.\n\nWhen I was satisfied by the parameters, I then switch to a second selection: the selection of the seed! because my noise have seed and can generate very different kind of noises, I put it against my "elector" homemade tool as explained on [plot#143](/plots/143).\n\n<img src="/images/plots/150-selection.png" width="100%">\n\n## Some highlight of the Rustlang code\n\nThere is nothing really "new" from my previous plots, especially all the parametric plot when I started this "growing parametric" exploration between [plot#114](/plots/114) and [plot#148](/plots/148).\n\nWhat is new here however is the use of a GIF as an input. It\'s very easy to do: my script takes basically an loop percentage which I can transpose to looking up a frame in the rotating dancer loop. I can then use this function I\'ve just added to my utilities:\n\n```rust\nuse image::AnimationDecoder;\nuse image::RgbaImage;\nuse image::gif::GifDecoder;\nuse image::io::Reader as ImageReader;\n\npub fn image_gif_get_color(\n    path: &str,\n    index: usize\n) -> Result<\n    impl Fn((f64, f64)) -> (f64, f64, f64),\n    image::ImageError,\n> {\n    let file_in = File::open(path)?;\n    let decoder = GifDecoder::new(file_in).unwrap();\n    let frames = decoder.into_frames();\n    let frames = frames.collect_frames()?;\n    let img = frames.get(index % frames.len()).unwrap();\n    let buffer = img.buffer();\n    return Ok(dynamic_image_get_color(buffer.clone()));\n}\n\npub fn dynamic_image_get_color(\n    img: RgbaImage\n) -> impl Fn((f64, f64)) -> (f64, f64, f64) {\n    let (width, height) = img.dimensions();\n    return move |(x, y): (f64, f64)| {\n        let xi = (x.max(0.0).min(1.0)\n            * ((width - 1) as f64)) as u32;\n        let yi = (y.max(0.0).min(1.0)\n            * ((height - 1) as f64))\n            as u32;\n        let pixel = img.get_pixel(xi, yi);\n        let r = (pixel[0] as f64) / 255.0;\n        let g = (pixel[1] as f64) / 255.0;\n        let b = (pixel[2] as f64) / 255.0;\n        return (r, g, b);\n    };\n}\n```\n\nRust really shines in having great library, this is just the classical "image" package here.\n\nApart from this, the Rust code (you can see main.rs link on top of this page) is pretty straightforward. There is just a lot of work in the parametric function which starts to be quite big:\n\n```rust\nlet parametric = |p: f64| {\n    let p1 = (splits * p).floor();\n    let p2 = splits * p - p1;\n    let t = (p1 + split_threshold * p2) / splits;\n    let mut t2 = (p1\n        + split_threshold * p2.powf(pow))\n        / splits;\n    let initial = 1. / spins;\n    t2 =\n        (t2 - initial).max(0.) / (1. - initial);\n    let scale = 1.0\n        - t2 * (1.0\n            - i as f64 * opts.size_diff / size);\n    let s = spins;\n    let mut p = (\n        scale\n            * amp1\n            * ((s * 2. * PI * t).sin()\n                + amp2\n                    * mix(\n                        (s * f1.1 * PI * t).sin(),\n                        (s * f2.1 * PI * t).sin(),\n                        t,\n                    )),\n        0.07\n        - scale\n            * amp1\n            * ((s * 2. * PI * t).cos()\n                + amp2\n                    * mix(\n                        (s * f1.0 * PI * t).cos(),\n                        (s * f2.0 * PI * t).cos(),\n                        t,\n                    )),\n    );\n    let noise_angle = p.1.atan2(p.0);\n    let noise_amp = 0.003 * perlin.get([\n            opts.a * (progress * PI).sin() +\n            4.8 * p.0 + perlin.get([\n                7.8 * p.0,\n                4.2 * p.1 + opts.b * (progress * PI).sin(),\n                40. + opts.seed\n            ]),\n            4.8 * p.1 + 0.8 * perlin.get([\n                4.5 * p.0 + opts.c * ((1. - progress) * PI).sin(),\n                6.8 * p.1 + perlin.get([\n                    20.5 * p.0 + opts.d * (2. * PI * progress).cos(),\n                    20.8 * p.1,\n                    200. + opts.seed,\n                ]),\n                20. + opts.seed,\n            ]),\n            100. + opts.seed + i as f64 * opts.seed_diff,\n        ]) +\n        0.03 * (1. - t) * perlin.get([\n            0.7 * p.0 + perlin.get([\n                2.9 * p.0 + opts.e * (2. * PI * progress).cos(),\n                1.7 * p.1,\n                2000.0\n            ]),\n            0.7 * p.1 + perlin.get([\n                3.1 * p.0,\n                2.5 * p.1 + opts.e * (2. * PI * progress).sin(),\n                2100.0\n            ]),\n            1000.,\n        ]);\n\n    p.0 += noise_amp * noise_angle.cos();\n    p.1 += noise_amp * noise_angle.sin();\n    p\n};\n```\n'},Da1f:function(e,n,t){"use strict";t.r(n),n.default=""},DlQD:function(e,n,t){e.exports=function(){"use strict";function e(e,n){for(var t=0;t<n.length;t++){var a=n[t];a.enumerable=a.enumerable||!1,a.configurable=!0,"value"in a&&(a.writable=!0),Object.defineProperty(e,a.key,a)}}function n(n,t,a){return t&&e(n.prototype,t),a&&e(n,a),n}function t(e,n){if(e){if("string"===typeof e)return a(e,n);var t=Object.prototype.toString.call(e).slice(8,-1);return"Object"===t&&e.constructor&&(t=e.constructor.name),"Map"===t||"Set"===t?Array.from(e):"Arguments"===t||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t)?a(e,n):void 0}}function a(e,n){(null==n||n>e.length)&&(n=e.length);for(var t=0,a=new Array(n);t<n;t++)a[t]=e[t];return a}function i(e,n){var a="undefined"!==typeof Symbol&&e[Symbol.iterator]||e["@@iterator"];if(a)return(a=a.call(e)).next.bind(a);if(Array.isArray(e)||(a=t(e))||n&&e&&"number"===typeof e.length){a&&(e=a);var i=0;return function(){return i>=e.length?{done:!0}:{done:!1,value:e[i++]}}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var o={exports:{}};function r(){return{baseUrl:null,breaks:!1,gfm:!0,headerIds:!0,headerPrefix:"",highlight:null,langPrefix:"language-",mangle:!0,pedantic:!1,renderer:null,sanitize:!1,sanitizer:null,silent:!1,smartLists:!1,smartypants:!1,tokenizer:null,walkTokens:null,xhtml:!1}}function s(e){o.exports.defaults=e}o.exports={defaults:r(),getDefaults:r,changeDefaults:s};var l=/[&<>"']/,c=/[&<>"']/g,u=/[<>"']|&(?!#?\w+;)/,h=/[<>"']|&(?!#?\w+;)/g,d={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&#39;"},p=function(e){return d[e]};function m(e,n){if(n){if(l.test(e))return e.replace(c,p)}else if(u.test(e))return e.replace(h,p);return e}var g=/&(#(?:\d+)|(?:#x[0-9A-Fa-f]+)|(?:\w+));?/gi;function f(e){return e.replace(g,(function(e,n){return"colon"===(n=n.toLowerCase())?":":"#"===n.charAt(0)?"x"===n.charAt(1)?String.fromCharCode(parseInt(n.substring(2),16)):String.fromCharCode(+n.substring(1)):""}))}var w=/(^|[^\[])\^/g;function b(e,n){e=e.source||e,n=n||"";var t={replace:function(n,a){return a=(a=a.source||a).replace(w,"$1"),e=e.replace(n,a),t},getRegex:function(){return new RegExp(e,n)}};return t}var y=/[^\w:]/g,v=/^$|^[a-z][a-z0-9+.-]*:|^[?#]/i;function k(e,n,t){if(e){var a;try{a=decodeURIComponent(f(t)).replace(y,"").toLowerCase()}catch(i){return null}if(0===a.indexOf("javascript:")||0===a.indexOf("vbscript:")||0===a.indexOf("data:"))return null}n&&!v.test(t)&&(t=I(n,t));try{t=encodeURI(t).replace(/%25/g,"%")}catch(i){return null}return t}var x={},A=/^[^:]+:\/*[^/]*$/,D=/^([^:]+:)[\s\S]*$/,E=/^([^:]+:\/*[^/]*)[\s\S]*$/;function I(e,n){x[" "+e]||(A.test(e)?x[" "+e]=e+"/":x[" "+e]=T(e,"/",!0));var t=-1===(e=x[" "+e]).indexOf(":");return"//"===n.substring(0,2)?t?n:e.replace(D,"$1")+n:"/"===n.charAt(0)?t?n:e.replace(E,"$1")+n:e+n}function S(e){for(var n,t,a=1;a<arguments.length;a++)for(t in n=arguments[a])Object.prototype.hasOwnProperty.call(n,t)&&(e[t]=n[t]);return e}function j(e,n){var t=e.replace(/\|/g,(function(e,n,t){for(var a=!1,i=n;--i>=0&&"\\"===t[i];)a=!a;return a?"|":" |"})).split(/ \|/),a=0;if(t.length>n)t.splice(n);else for(;t.length<n;)t.push("");for(;a<t.length;a++)t[a]=t[a].trim().replace(/\\\|/g,"|");return t}function T(e,n,t){var a=e.length;if(0===a)return"";for(var i=0;i<a;){var o=e.charAt(a-i-1);if(o!==n||t){if(o===n||!t)break;i++}else i++}return e.substr(0,a-i)}function C(e,n){if(-1===e.indexOf(n[1]))return-1;for(var t=e.length,a=0,i=0;i<t;i++)if("\\"===e[i])i++;else if(e[i]===n[0])a++;else if(e[i]===n[1]&&--a<0)return i;return-1}function F(e){e&&e.sanitize&&!e.silent&&console.warn("marked(): sanitize and sanitizer parameters are deprecated since version 0.7.0, should not be used and will be removed in the future. Read more here: https://marked.js.org/#/USING_ADVANCED.md#options")}function M(e,n){if(n<1)return"";for(var t="";n>1;)1&n&&(t+=e),n>>=1,e+=e;return t+e}var R={escape:m,unescape:f,edit:b,cleanUrl:k,resolveUrl:I,noopTest:{exec:function(){}},merge:S,splitCells:j,rtrim:T,findClosingBracket:C,checkSanitizeDeprecation:F,repeatString:M},_=o.exports.defaults,P=R.rtrim,L=R.splitCells,B=R.escape,z=R.findClosingBracket;function O(e,n,t){var a=n.href,i=n.title?B(n.title):null,o=e[1].replace(/\\([\[\]])/g,"$1");return"!"!==e[0].charAt(0)?{type:"link",raw:t,href:a,title:i,text:o}:{type:"image",raw:t,href:a,title:i,text:B(o)}}function G(e,n){var t=e.match(/^(\s+)(?:```)/);if(null===t)return n;var a=t[1];return n.split("\n").map((function(e){var n=e.match(/^\s+/);return null===n?e:n[0].length>=a.length?e.slice(a.length):e})).join("\n")}var q=function(){function e(e){this.options=e||_}var n=e.prototype;return n.space=function(e){var n=this.rules.block.newline.exec(e);if(n)return n[0].length>1?{type:"space",raw:n[0]}:{raw:"\n"}},n.code=function(e){var n=this.rules.block.code.exec(e);if(n){var t=n[0].replace(/^ {1,4}/gm,"");return{type:"code",raw:n[0],codeBlockStyle:"indented",text:this.options.pedantic?t:P(t,"\n")}}},n.fences=function(e){var n=this.rules.block.fences.exec(e);if(n){var t=n[0],a=G(t,n[3]||"");return{type:"code",raw:t,lang:n[2]?n[2].trim():n[2],text:a}}},n.heading=function(e){var n=this.rules.block.heading.exec(e);if(n){var t=n[2].trim();if(/#$/.test(t)){var a=P(t,"#");this.options.pedantic?t=a.trim():a&&!/ $/.test(a)||(t=a.trim())}return{type:"heading",raw:n[0],depth:n[1].length,text:t}}},n.nptable=function(e){var n=this.rules.block.nptable.exec(e);if(n){var t={type:"table",header:L(n[1].replace(/^ *| *\| *$/g,"")),align:n[2].replace(/^ *|\| *$/g,"").split(/ *\| */),cells:n[3]?n[3].replace(/\n$/,"").split("\n"):[],raw:n[0]};if(t.header.length===t.align.length){var a,i=t.align.length;for(a=0;a<i;a++)/^ *-+: *$/.test(t.align[a])?t.align[a]="right":/^ *:-+: *$/.test(t.align[a])?t.align[a]="center":/^ *:-+ *$/.test(t.align[a])?t.align[a]="left":t.align[a]=null;for(i=t.cells.length,a=0;a<i;a++)t.cells[a]=L(t.cells[a],t.header.length);return t}}},n.hr=function(e){var n=this.rules.block.hr.exec(e);if(n)return{type:"hr",raw:n[0]}},n.blockquote=function(e){var n=this.rules.block.blockquote.exec(e);if(n){var t=n[0].replace(/^ *> ?/gm,"");return{type:"blockquote",raw:n[0],text:t}}},n.list=function(e){var n=this.rules.block.list.exec(e);if(n){var t,a,i,o,r,s,l,c,u,h=n[0],d=n[2],p=d.length>1,m={type:"list",raw:h,ordered:p,start:p?+d.slice(0,-1):"",loose:!1,items:[]},g=n[0].match(this.rules.block.item),f=!1,w=g.length;i=this.rules.block.listItemStart.exec(g[0]);for(var b=0;b<w;b++){if(h=t=g[b],this.options.pedantic||(u=t.match(new RegExp("\\n\\s*\\n {0,"+(i[0].length-1)+"}\\S")))&&(r=t.length-u.index+g.slice(b+1).join("\n").length,m.raw=m.raw.substring(0,m.raw.length-r),h=t=t.substring(0,u.index),w=b+1),b!==w-1){if(o=this.rules.block.listItemStart.exec(g[b+1]),this.options.pedantic?o[1].length>i[1].length:o[1].length>=i[0].length||o[1].length>3){g.splice(b,2,g[b]+(!this.options.pedantic&&o[1].length<i[0].length&&!g[b].match(/\n$/)?"":"\n")+g[b+1]),b--,w--;continue}(!this.options.pedantic||this.options.smartLists?o[2][o[2].length-1]!==d[d.length-1]:p===(1===o[2].length))&&(r=g.slice(b+1).join("\n").length,m.raw=m.raw.substring(0,m.raw.length-r),b=w-1),i=o}a=t.length,~(t=t.replace(/^ *([*+-]|\d+[.)]) ?/,"")).indexOf("\n ")&&(a-=t.length,t=this.options.pedantic?t.replace(/^ {1,4}/gm,""):t.replace(new RegExp("^ {1,"+a+"}","gm"),"")),t=P(t,"\n"),b!==w-1&&(h+="\n"),s=f||/\n\n(?!\s*$)/.test(h),b!==w-1&&(f="\n\n"===h.slice(-2),s||(s=f)),s&&(m.loose=!0),this.options.gfm&&(c=void 0,(l=/^\[[ xX]\] /.test(t))&&(c=" "!==t[1],t=t.replace(/^\[[ xX]\] +/,""))),m.items.push({type:"list_item",raw:h,task:l,checked:c,loose:s,text:t})}return m}},n.html=function(e){var n=this.rules.block.html.exec(e);if(n)return{type:this.options.sanitize?"paragraph":"html",raw:n[0],pre:!this.options.sanitizer&&("pre"===n[1]||"script"===n[1]||"style"===n[1]),text:this.options.sanitize?this.options.sanitizer?this.options.sanitizer(n[0]):B(n[0]):n[0]}},n.def=function(e){var n=this.rules.block.def.exec(e);if(n)return n[3]&&(n[3]=n[3].substring(1,n[3].length-1)),{type:"def",tag:n[1].toLowerCase().replace(/\s+/g," "),raw:n[0],href:n[2],title:n[3]}},n.table=function(e){var n=this.rules.block.table.exec(e);if(n){var t={type:"table",header:L(n[1].replace(/^ *| *\| *$/g,"")),align:n[2].replace(/^ *|\| *$/g,"").split(/ *\| */),cells:n[3]?n[3].replace(/\n$/,"").split("\n"):[]};if(t.header.length===t.align.length){t.raw=n[0];var a,i=t.align.length;for(a=0;a<i;a++)/^ *-+: *$/.test(t.align[a])?t.align[a]="right":/^ *:-+: *$/.test(t.align[a])?t.align[a]="center":/^ *:-+ *$/.test(t.align[a])?t.align[a]="left":t.align[a]=null;for(i=t.cells.length,a=0;a<i;a++)t.cells[a]=L(t.cells[a].replace(/^ *\| *| *\| *$/g,""),t.header.length);return t}}},n.lheading=function(e){var n=this.rules.block.lheading.exec(e);if(n)return{type:"heading",raw:n[0],depth:"="===n[2].charAt(0)?1:2,text:n[1]}},n.paragraph=function(e){var n=this.rules.block.paragraph.exec(e);if(n)return{type:"paragraph",raw:n[0],text:"\n"===n[1].charAt(n[1].length-1)?n[1].slice(0,-1):n[1]}},n.text=function(e){var n=this.rules.block.text.exec(e);if(n)return{type:"text",raw:n[0],text:n[0]}},n.escape=function(e){var n=this.rules.inline.escape.exec(e);if(n)return{type:"escape",raw:n[0],text:B(n[1])}},n.tag=function(e,n,t){var a=this.rules.inline.tag.exec(e);if(a)return!n&&/^<a /i.test(a[0])?n=!0:n&&/^<\/a>/i.test(a[0])&&(n=!1),!t&&/^<(pre|code|kbd|script)(\s|>)/i.test(a[0])?t=!0:t&&/^<\/(pre|code|kbd|script)(\s|>)/i.test(a[0])&&(t=!1),{type:this.options.sanitize?"text":"html",raw:a[0],inLink:n,inRawBlock:t,text:this.options.sanitize?this.options.sanitizer?this.options.sanitizer(a[0]):B(a[0]):a[0]}},n.link=function(e){var n=this.rules.inline.link.exec(e);if(n){var t=n[2].trim();if(!this.options.pedantic&&/^</.test(t)){if(!/>$/.test(t))return;var a=P(t.slice(0,-1),"\\");if((t.length-a.length)%2===0)return}else{var i=z(n[2],"()");if(i>-1){var o=(0===n[0].indexOf("!")?5:4)+n[1].length+i;n[2]=n[2].substring(0,i),n[0]=n[0].substring(0,o).trim(),n[3]=""}}var r=n[2],s="";if(this.options.pedantic){var l=/^([^'"]*[^\s])\s+(['"])(.*)\2/.exec(r);l&&(r=l[1],s=l[3])}else s=n[3]?n[3].slice(1,-1):"";return r=r.trim(),/^</.test(r)&&(r=this.options.pedantic&&!/>$/.test(t)?r.slice(1):r.slice(1,-1)),O(n,{href:r?r.replace(this.rules.inline._escapes,"$1"):r,title:s?s.replace(this.rules.inline._escapes,"$1"):s},n[0])}},n.reflink=function(e,n){var t;if((t=this.rules.inline.reflink.exec(e))||(t=this.rules.inline.nolink.exec(e))){var a=(t[2]||t[1]).replace(/\s+/g," ");if(!(a=n[a.toLowerCase()])||!a.href){var i=t[0].charAt(0);return{type:"text",raw:i,text:i}}return O(t,a,t[0])}},n.emStrong=function(e,n,t){void 0===t&&(t="");var a=this.rules.inline.emStrong.lDelim.exec(e);if(a&&(!a[3]||!t.match(/(?:[0-9A-Za-z\xAA\xB2\xB3\xB5\xB9\xBA\xBC-\xBE\xC0-\xD6\xD8-\xF6\xF8-\u02C1\u02C6-\u02D1\u02E0-\u02E4\u02EC\u02EE\u0370-\u0374\u0376\u0377\u037A-\u037D\u037F\u0386\u0388-\u038A\u038C\u038E-\u03A1\u03A3-\u03F5\u03F7-\u0481\u048A-\u052F\u0531-\u0556\u0559\u0560-\u0588\u05D0-\u05EA\u05EF-\u05F2\u0620-\u064A\u0660-\u0669\u066E\u066F\u0671-\u06D3\u06D5\u06E5\u06E6\u06EE-\u06FC\u06FF\u0710\u0712-\u072F\u074D-\u07A5\u07B1\u07C0-\u07EA\u07F4\u07F5\u07FA\u0800-\u0815\u081A\u0824\u0828\u0840-\u0858\u0860-\u086A\u08A0-\u08B4\u08B6-\u08C7\u0904-\u0939\u093D\u0950\u0958-\u0961\u0966-\u096F\u0971-\u0980\u0985-\u098C\u098F\u0990\u0993-\u09A8\u09AA-\u09B0\u09B2\u09B6-\u09B9\u09BD\u09CE\u09DC\u09DD\u09DF-\u09E1\u09E6-\u09F1\u09F4-\u09F9\u09FC\u0A05-\u0A0A\u0A0F\u0A10\u0A13-\u0A28\u0A2A-\u0A30\u0A32\u0A33\u0A35\u0A36\u0A38\u0A39\u0A59-\u0A5C\u0A5E\u0A66-\u0A6F\u0A72-\u0A74\u0A85-\u0A8D\u0A8F-\u0A91\u0A93-\u0AA8\u0AAA-\u0AB0\u0AB2\u0AB3\u0AB5-\u0AB9\u0ABD\u0AD0\u0AE0\u0AE1\u0AE6-\u0AEF\u0AF9\u0B05-\u0B0C\u0B0F\u0B10\u0B13-\u0B28\u0B2A-\u0B30\u0B32\u0B33\u0B35-\u0B39\u0B3D\u0B5C\u0B5D\u0B5F-\u0B61\u0B66-\u0B6F\u0B71-\u0B77\u0B83\u0B85-\u0B8A\u0B8E-\u0B90\u0B92-\u0B95\u0B99\u0B9A\u0B9C\u0B9E\u0B9F\u0BA3\u0BA4\u0BA8-\u0BAA\u0BAE-\u0BB9\u0BD0\u0BE6-\u0BF2\u0C05-\u0C0C\u0C0E-\u0C10\u0C12-\u0C28\u0C2A-\u0C39\u0C3D\u0C58-\u0C5A\u0C60\u0C61\u0C66-\u0C6F\u0C78-\u0C7E\u0C80\u0C85-\u0C8C\u0C8E-\u0C90\u0C92-\u0CA8\u0CAA-\u0CB3\u0CB5-\u0CB9\u0CBD\u0CDE\u0CE0\u0CE1\u0CE6-\u0CEF\u0CF1\u0CF2\u0D04-\u0D0C\u0D0E-\u0D10\u0D12-\u0D3A\u0D3D\u0D4E\u0D54-\u0D56\u0D58-\u0D61\u0D66-\u0D78\u0D7A-\u0D7F\u0D85-\u0D96\u0D9A-\u0DB1\u0DB3-\u0DBB\u0DBD\u0DC0-\u0DC6\u0DE6-\u0DEF\u0E01-\u0E30\u0E32\u0E33\u0E40-\u0E46\u0E50-\u0E59\u0E81\u0E82\u0E84\u0E86-\u0E8A\u0E8C-\u0EA3\u0EA5\u0EA7-\u0EB0\u0EB2\u0EB3\u0EBD\u0EC0-\u0EC4\u0EC6\u0ED0-\u0ED9\u0EDC-\u0EDF\u0F00\u0F20-\u0F33\u0F40-\u0F47\u0F49-\u0F6C\u0F88-\u0F8C\u1000-\u102A\u103F-\u1049\u1050-\u1055\u105A-\u105D\u1061\u1065\u1066\u106E-\u1070\u1075-\u1081\u108E\u1090-\u1099\u10A0-\u10C5\u10C7\u10CD\u10D0-\u10FA\u10FC-\u1248\u124A-\u124D\u1250-\u1256\u1258\u125A-\u125D\u1260-\u1288\u128A-\u128D\u1290-\u12B0\u12B2-\u12B5\u12B8-\u12BE\u12C0\u12C2-\u12C5\u12C8-\u12D6\u12D8-\u1310\u1312-\u1315\u1318-\u135A\u1369-\u137C\u1380-\u138F\u13A0-\u13F5\u13F8-\u13FD\u1401-\u166C\u166F-\u167F\u1681-\u169A\u16A0-\u16EA\u16EE-\u16F8\u1700-\u170C\u170E-\u1711\u1720-\u1731\u1740-\u1751\u1760-\u176C\u176E-\u1770\u1780-\u17B3\u17D7\u17DC\u17E0-\u17E9\u17F0-\u17F9\u1810-\u1819\u1820-\u1878\u1880-\u1884\u1887-\u18A8\u18AA\u18B0-\u18F5\u1900-\u191E\u1946-\u196D\u1970-\u1974\u1980-\u19AB\u19B0-\u19C9\u19D0-\u19DA\u1A00-\u1A16\u1A20-\u1A54\u1A80-\u1A89\u1A90-\u1A99\u1AA7\u1B05-\u1B33\u1B45-\u1B4B\u1B50-\u1B59\u1B83-\u1BA0\u1BAE-\u1BE5\u1C00-\u1C23\u1C40-\u1C49\u1C4D-\u1C7D\u1C80-\u1C88\u1C90-\u1CBA\u1CBD-\u1CBF\u1CE9-\u1CEC\u1CEE-\u1CF3\u1CF5\u1CF6\u1CFA\u1D00-\u1DBF\u1E00-\u1F15\u1F18-\u1F1D\u1F20-\u1F45\u1F48-\u1F4D\u1F50-\u1F57\u1F59\u1F5B\u1F5D\u1F5F-\u1F7D\u1F80-\u1FB4\u1FB6-\u1FBC\u1FBE\u1FC2-\u1FC4\u1FC6-\u1FCC\u1FD0-\u1FD3\u1FD6-\u1FDB\u1FE0-\u1FEC\u1FF2-\u1FF4\u1FF6-\u1FFC\u2070\u2071\u2074-\u2079\u207F-\u2089\u2090-\u209C\u2102\u2107\u210A-\u2113\u2115\u2119-\u211D\u2124\u2126\u2128\u212A-\u212D\u212F-\u2139\u213C-\u213F\u2145-\u2149\u214E\u2150-\u2189\u2460-\u249B\u24EA-\u24FF\u2776-\u2793\u2C00-\u2C2E\u2C30-\u2C5E\u2C60-\u2CE4\u2CEB-\u2CEE\u2CF2\u2CF3\u2CFD\u2D00-\u2D25\u2D27\u2D2D\u2D30-\u2D67\u2D6F\u2D80-\u2D96\u2DA0-\u2DA6\u2DA8-\u2DAE\u2DB0-\u2DB6\u2DB8-\u2DBE\u2DC0-\u2DC6\u2DC8-\u2DCE\u2DD0-\u2DD6\u2DD8-\u2DDE\u2E2F\u3005-\u3007\u3021-\u3029\u3031-\u3035\u3038-\u303C\u3041-\u3096\u309D-\u309F\u30A1-\u30FA\u30FC-\u30FF\u3105-\u312F\u3131-\u318E\u3192-\u3195\u31A0-\u31BF\u31F0-\u31FF\u3220-\u3229\u3248-\u324F\u3251-\u325F\u3280-\u3289\u32B1-\u32BF\u3400-\u4DBF\u4E00-\u9FFC\uA000-\uA48C\uA4D0-\uA4FD\uA500-\uA60C\uA610-\uA62B\uA640-\uA66E\uA67F-\uA69D\uA6A0-\uA6EF\uA717-\uA71F\uA722-\uA788\uA78B-\uA7BF\uA7C2-\uA7CA\uA7F5-\uA801\uA803-\uA805\uA807-\uA80A\uA80C-\uA822\uA830-\uA835\uA840-\uA873\uA882-\uA8B3\uA8D0-\uA8D9\uA8F2-\uA8F7\uA8FB\uA8FD\uA8FE\uA900-\uA925\uA930-\uA946\uA960-\uA97C\uA984-\uA9B2\uA9CF-\uA9D9\uA9E0-\uA9E4\uA9E6-\uA9FE\uAA00-\uAA28\uAA40-\uAA42\uAA44-\uAA4B\uAA50-\uAA59\uAA60-\uAA76\uAA7A\uAA7E-\uAAAF\uAAB1\uAAB5\uAAB6\uAAB9-\uAABD\uAAC0\uAAC2\uAADB-\uAADD\uAAE0-\uAAEA\uAAF2-\uAAF4\uAB01-\uAB06\uAB09-\uAB0E\uAB11-\uAB16\uAB20-\uAB26\uAB28-\uAB2E\uAB30-\uAB5A\uAB5C-\uAB69\uAB70-\uABE2\uABF0-\uABF9\uAC00-\uD7A3\uD7B0-\uD7C6\uD7CB-\uD7FB\uF900-\uFA6D\uFA70-\uFAD9\uFB00-\uFB06\uFB13-\uFB17\uFB1D\uFB1F-\uFB28\uFB2A-\uFB36\uFB38-\uFB3C\uFB3E\uFB40\uFB41\uFB43\uFB44\uFB46-\uFBB1\uFBD3-\uFD3D\uFD50-\uFD8F\uFD92-\uFDC7\uFDF0-\uFDFB\uFE70-\uFE74\uFE76-\uFEFC\uFF10-\uFF19\uFF21-\uFF3A\uFF41-\uFF5A\uFF66-\uFFBE\uFFC2-\uFFC7\uFFCA-\uFFCF\uFFD2-\uFFD7\uFFDA-\uFFDC]|\uD800[\uDC00-\uDC0B\uDC0D-\uDC26\uDC28-\uDC3A\uDC3C\uDC3D\uDC3F-\uDC4D\uDC50-\uDC5D\uDC80-\uDCFA\uDD07-\uDD33\uDD40-\uDD78\uDD8A\uDD8B\uDE80-\uDE9C\uDEA0-\uDED0\uDEE1-\uDEFB\uDF00-\uDF23\uDF2D-\uDF4A\uDF50-\uDF75\uDF80-\uDF9D\uDFA0-\uDFC3\uDFC8-\uDFCF\uDFD1-\uDFD5]|\uD801[\uDC00-\uDC9D\uDCA0-\uDCA9\uDCB0-\uDCD3\uDCD8-\uDCFB\uDD00-\uDD27\uDD30-\uDD63\uDE00-\uDF36\uDF40-\uDF55\uDF60-\uDF67]|\uD802[\uDC00-\uDC05\uDC08\uDC0A-\uDC35\uDC37\uDC38\uDC3C\uDC3F-\uDC55\uDC58-\uDC76\uDC79-\uDC9E\uDCA7-\uDCAF\uDCE0-\uDCF2\uDCF4\uDCF5\uDCFB-\uDD1B\uDD20-\uDD39\uDD80-\uDDB7\uDDBC-\uDDCF\uDDD2-\uDE00\uDE10-\uDE13\uDE15-\uDE17\uDE19-\uDE35\uDE40-\uDE48\uDE60-\uDE7E\uDE80-\uDE9F\uDEC0-\uDEC7\uDEC9-\uDEE4\uDEEB-\uDEEF\uDF00-\uDF35\uDF40-\uDF55\uDF58-\uDF72\uDF78-\uDF91\uDFA9-\uDFAF]|\uD803[\uDC00-\uDC48\uDC80-\uDCB2\uDCC0-\uDCF2\uDCFA-\uDD23\uDD30-\uDD39\uDE60-\uDE7E\uDE80-\uDEA9\uDEB0\uDEB1\uDF00-\uDF27\uDF30-\uDF45\uDF51-\uDF54\uDFB0-\uDFCB\uDFE0-\uDFF6]|\uD804[\uDC03-\uDC37\uDC52-\uDC6F\uDC83-\uDCAF\uDCD0-\uDCE8\uDCF0-\uDCF9\uDD03-\uDD26\uDD36-\uDD3F\uDD44\uDD47\uDD50-\uDD72\uDD76\uDD83-\uDDB2\uDDC1-\uDDC4\uDDD0-\uDDDA\uDDDC\uDDE1-\uDDF4\uDE00-\uDE11\uDE13-\uDE2B\uDE80-\uDE86\uDE88\uDE8A-\uDE8D\uDE8F-\uDE9D\uDE9F-\uDEA8\uDEB0-\uDEDE\uDEF0-\uDEF9\uDF05-\uDF0C\uDF0F\uDF10\uDF13-\uDF28\uDF2A-\uDF30\uDF32\uDF33\uDF35-\uDF39\uDF3D\uDF50\uDF5D-\uDF61]|\uD805[\uDC00-\uDC34\uDC47-\uDC4A\uDC50-\uDC59\uDC5F-\uDC61\uDC80-\uDCAF\uDCC4\uDCC5\uDCC7\uDCD0-\uDCD9\uDD80-\uDDAE\uDDD8-\uDDDB\uDE00-\uDE2F\uDE44\uDE50-\uDE59\uDE80-\uDEAA\uDEB8\uDEC0-\uDEC9\uDF00-\uDF1A\uDF30-\uDF3B]|\uD806[\uDC00-\uDC2B\uDCA0-\uDCF2\uDCFF-\uDD06\uDD09\uDD0C-\uDD13\uDD15\uDD16\uDD18-\uDD2F\uDD3F\uDD41\uDD50-\uDD59\uDDA0-\uDDA7\uDDAA-\uDDD0\uDDE1\uDDE3\uDE00\uDE0B-\uDE32\uDE3A\uDE50\uDE5C-\uDE89\uDE9D\uDEC0-\uDEF8]|\uD807[\uDC00-\uDC08\uDC0A-\uDC2E\uDC40\uDC50-\uDC6C\uDC72-\uDC8F\uDD00-\uDD06\uDD08\uDD09\uDD0B-\uDD30\uDD46\uDD50-\uDD59\uDD60-\uDD65\uDD67\uDD68\uDD6A-\uDD89\uDD98\uDDA0-\uDDA9\uDEE0-\uDEF2\uDFB0\uDFC0-\uDFD4]|\uD808[\uDC00-\uDF99]|\uD809[\uDC00-\uDC6E\uDC80-\uDD43]|[\uD80C\uD81C-\uD820\uD822\uD840-\uD868\uD86A-\uD86C\uD86F-\uD872\uD874-\uD879\uD880-\uD883][\uDC00-\uDFFF]|\uD80D[\uDC00-\uDC2E]|\uD811[\uDC00-\uDE46]|\uD81A[\uDC00-\uDE38\uDE40-\uDE5E\uDE60-\uDE69\uDED0-\uDEED\uDF00-\uDF2F\uDF40-\uDF43\uDF50-\uDF59\uDF5B-\uDF61\uDF63-\uDF77\uDF7D-\uDF8F]|\uD81B[\uDE40-\uDE96\uDF00-\uDF4A\uDF50\uDF93-\uDF9F\uDFE0\uDFE1\uDFE3]|\uD821[\uDC00-\uDFF7]|\uD823[\uDC00-\uDCD5\uDD00-\uDD08]|\uD82C[\uDC00-\uDD1E\uDD50-\uDD52\uDD64-\uDD67\uDD70-\uDEFB]|\uD82F[\uDC00-\uDC6A\uDC70-\uDC7C\uDC80-\uDC88\uDC90-\uDC99]|\uD834[\uDEE0-\uDEF3\uDF60-\uDF78]|\uD835[\uDC00-\uDC54\uDC56-\uDC9C\uDC9E\uDC9F\uDCA2\uDCA5\uDCA6\uDCA9-\uDCAC\uDCAE-\uDCB9\uDCBB\uDCBD-\uDCC3\uDCC5-\uDD05\uDD07-\uDD0A\uDD0D-\uDD14\uDD16-\uDD1C\uDD1E-\uDD39\uDD3B-\uDD3E\uDD40-\uDD44\uDD46\uDD4A-\uDD50\uDD52-\uDEA5\uDEA8-\uDEC0\uDEC2-\uDEDA\uDEDC-\uDEFA\uDEFC-\uDF14\uDF16-\uDF34\uDF36-\uDF4E\uDF50-\uDF6E\uDF70-\uDF88\uDF8A-\uDFA8\uDFAA-\uDFC2\uDFC4-\uDFCB\uDFCE-\uDFFF]|\uD838[\uDD00-\uDD2C\uDD37-\uDD3D\uDD40-\uDD49\uDD4E\uDEC0-\uDEEB\uDEF0-\uDEF9]|\uD83A[\uDC00-\uDCC4\uDCC7-\uDCCF\uDD00-\uDD43\uDD4B\uDD50-\uDD59]|\uD83B[\uDC71-\uDCAB\uDCAD-\uDCAF\uDCB1-\uDCB4\uDD01-\uDD2D\uDD2F-\uDD3D\uDE00-\uDE03\uDE05-\uDE1F\uDE21\uDE22\uDE24\uDE27\uDE29-\uDE32\uDE34-\uDE37\uDE39\uDE3B\uDE42\uDE47\uDE49\uDE4B\uDE4D-\uDE4F\uDE51\uDE52\uDE54\uDE57\uDE59\uDE5B\uDE5D\uDE5F\uDE61\uDE62\uDE64\uDE67-\uDE6A\uDE6C-\uDE72\uDE74-\uDE77\uDE79-\uDE7C\uDE7E\uDE80-\uDE89\uDE8B-\uDE9B\uDEA1-\uDEA3\uDEA5-\uDEA9\uDEAB-\uDEBB]|\uD83C[\uDD00-\uDD0C]|\uD83E[\uDFF0-\uDFF9]|\uD869[\uDC00-\uDEDD\uDF00-\uDFFF]|\uD86D[\uDC00-\uDF34\uDF40-\uDFFF]|\uD86E[\uDC00-\uDC1D\uDC20-\uDFFF]|\uD873[\uDC00-\uDEA1\uDEB0-\uDFFF]|\uD87A[\uDC00-\uDFE0]|\uD87E[\uDC00-\uDE1D]|\uD884[\uDC00-\uDF4A])/))){var i=a[1]||a[2]||"";if(!i||i&&(""===t||this.rules.inline.punctuation.exec(t))){var o,r,s=a[0].length-1,l=s,c=0,u="*"===a[0][0]?this.rules.inline.emStrong.rDelimAst:this.rules.inline.emStrong.rDelimUnd;for(u.lastIndex=0,n=n.slice(-1*e.length+s);null!=(a=u.exec(n));)if(o=a[1]||a[2]||a[3]||a[4]||a[5]||a[6])if(r=o.length,a[3]||a[4])l+=r;else if(!((a[5]||a[6])&&s%3)||(s+r)%3){if(!((l-=r)>0)){if(l+c-r<=0&&!n.slice(u.lastIndex).match(u)&&(r=Math.min(r,r+l+c)),Math.min(s,r)%2)return{type:"em",raw:e.slice(0,s+a.index+r+1),text:e.slice(1,s+a.index+r)};if(Math.min(s,r)%2===0)return{type:"strong",raw:e.slice(0,s+a.index+r+1),text:e.slice(2,s+a.index+r-1)}}}else c+=r}}},n.codespan=function(e){var n=this.rules.inline.code.exec(e);if(n){var t=n[2].replace(/\n/g," "),a=/[^ ]/.test(t),i=/^ /.test(t)&&/ $/.test(t);return a&&i&&(t=t.substring(1,t.length-1)),t=B(t,!0),{type:"codespan",raw:n[0],text:t}}},n.br=function(e){var n=this.rules.inline.br.exec(e);if(n)return{type:"br",raw:n[0]}},n.del=function(e){var n=this.rules.inline.del.exec(e);if(n)return{type:"del",raw:n[0],text:n[2]}},n.autolink=function(e,n){var t,a,i=this.rules.inline.autolink.exec(e);if(i)return a="@"===i[2]?"mailto:"+(t=B(this.options.mangle?n(i[1]):i[1])):t=B(i[1]),{type:"link",raw:i[0],text:t,href:a,tokens:[{type:"text",raw:t,text:t}]}},n.url=function(e,n){var t;if(t=this.rules.inline.url.exec(e)){var a,i;if("@"===t[2])i="mailto:"+(a=B(this.options.mangle?n(t[0]):t[0]));else{var o;do{o=t[0],t[0]=this.rules.inline._backpedal.exec(t[0])[0]}while(o!==t[0]);a=B(t[0]),i="www."===t[1]?"http://"+a:a}return{type:"link",raw:t[0],text:a,href:i,tokens:[{type:"text",raw:a,text:a}]}}},n.inlineText=function(e,n,t){var a,i=this.rules.inline.text.exec(e);if(i)return a=n?this.options.sanitize?this.options.sanitizer?this.options.sanitizer(i[0]):B(i[0]):i[0]:B(this.options.smartypants?t(i[0]):i[0]),{type:"text",raw:i[0],text:a}},e}(),N=R.noopTest,W=R.edit,H=R.merge,J={newline:/^(?: *(?:\n|$))+/,code:/^( {4}[^\n]+(?:\n(?: *(?:\n|$))*)?)+/,fences:/^ {0,3}(`{3,}(?=[^`\n]*\n)|~{3,})([^\n]*)\n(?:|([\s\S]*?)\n)(?: {0,3}\1[~`]* *(?:\n+|$)|$)/,hr:/^ {0,3}((?:- *){3,}|(?:_ *){3,}|(?:\* *){3,})(?:\n+|$)/,heading:/^ {0,3}(#{1,6})(?=\s|$)(.*)(?:\n+|$)/,blockquote:/^( {0,3}> ?(paragraph|[^\n]*)(?:\n|$))+/,list:/^( {0,3})(bull) [\s\S]+?(?:hr|def|\n{2,}(?! )(?! {0,3}bull )\n*|\s*$)/,html:"^ {0,3}(?:<(script|pre|style)[\\s>][\\s\\S]*?(?:</\\1>[^\\n]*\\n+|$)|comment[^\\n]*(\\n+|$)|<\\?[\\s\\S]*?(?:\\?>\\n*|$)|<![A-Z][\\s\\S]*?(?:>\\n*|$)|<!\\[CDATA\\[[\\s\\S]*?(?:\\]\\]>\\n*|$)|</?(tag)(?: +|\\n|/?>)[\\s\\S]*?(?:(?:\\n *)+\\n|$)|<(?!script|pre|style)([a-z][\\w-]*)(?:attribute)*? */?>(?=[ \\t]*(?:\\n|$))[\\s\\S]*?(?:(?:\\n *)+\\n|$)|</(?!script|pre|style)[a-z][\\w-]*\\s*>(?=[ \\t]*(?:\\n|$))[\\s\\S]*?(?:(?:\\n *)+\\n|$))",def:/^ {0,3}\[(label)\]: *\n? *<?([^\s>]+)>?(?:(?: +\n? *| *\n *)(title))? *(?:\n+|$)/,nptable:N,table:N,lheading:/^([^\n]+)\n {0,3}(=+|-+) *(?:\n+|$)/,_paragraph:/^([^\n]+(?:\n(?!hr|heading|lheading|blockquote|fences|list|html| +\n)[^\n]+)*)/,text:/^[^\n]+/,_label:/(?!\s*\])(?:\\[\[\]]|[^\[\]])+/,_title:/(?:"(?:\\"?|[^"\\])*"|'[^'\n]*(?:\n[^'\n]+)*\n?'|\([^()]*\))/};J.def=W(J.def).replace("label",J._label).replace("title",J._title).getRegex(),J.bullet=/(?:[*+-]|\d{1,9}[.)])/,J.item=/^( *)(bull) ?[^\n]*(?:\n(?! *bull ?)[^\n]*)*/,J.item=W(J.item,"gm").replace(/bull/g,J.bullet).getRegex(),J.listItemStart=W(/^( *)(bull) */).replace("bull",J.bullet).getRegex(),J.list=W(J.list).replace(/bull/g,J.bullet).replace("hr","\\n+(?=\\1?(?:(?:- *){3,}|(?:_ *){3,}|(?:\\* *){3,})(?:\\n+|$))").replace("def","\\n+(?="+J.def.source+")").getRegex(),J._tag="address|article|aside|base|basefont|blockquote|body|caption|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option|p|param|section|source|summary|table|tbody|td|tfoot|th|thead|title|tr|track|ul",J._comment=/<!--(?!-?>)[\s\S]*?(?:-->|$)/,J.html=W(J.html,"i").replace("comment",J._comment).replace("tag",J._tag).replace("attribute",/ +[a-zA-Z:_][\w.:-]*(?: *= *"[^"\n]*"| *= *'[^'\n]*'| *= *[^\s"'=<>`]+)?/).getRegex(),J.paragraph=W(J._paragraph).replace("hr",J.hr).replace("heading"," {0,3}#{1,6} ").replace("|lheading","").replace("blockquote"," {0,3}>").replace("fences"," {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n").replace("list"," {0,3}(?:[*+-]|1[.)]) ").replace("html","</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|!--)").replace("tag",J._tag).getRegex(),J.blockquote=W(J.blockquote).replace("paragraph",J.paragraph).getRegex(),J.normal=H({},J),J.gfm=H({},J.normal,{nptable:"^ *([^|\\n ].*\\|.*)\\n {0,3}([-:]+ *\\|[-| :]*)(?:\\n((?:(?!\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\n|$))*)\\n*|$)",table:"^ *\\|(.+)\\n {0,3}\\|?( *[-:]+[-| :]*)(?:\\n *((?:(?!\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\n|$))*)\\n*|$)"}),J.gfm.nptable=W(J.gfm.nptable).replace("hr",J.hr).replace("heading"," {0,3}#{1,6} ").replace("blockquote"," {0,3}>").replace("code"," {4}[^\\n]").replace("fences"," {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n").replace("list"," {0,3}(?:[*+-]|1[.)]) ").replace("html","</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|!--)").replace("tag",J._tag).getRegex(),J.gfm.table=W(J.gfm.table).replace("hr",J.hr).replace("heading"," {0,3}#{1,6} ").replace("blockquote"," {0,3}>").replace("code"," {4}[^\\n]").replace("fences"," {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n").replace("list"," {0,3}(?:[*+-]|1[.)]) ").replace("html","</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|!--)").replace("tag",J._tag).getRegex(),J.pedantic=H({},J.normal,{html:W("^ *(?:comment *(?:\\n|\\s*$)|<(tag)[\\s\\S]+?</\\1> *(?:\\n{2,}|\\s*$)|<tag(?:\"[^\"]*\"|'[^']*'|\\s[^'\"/>\\s]*)*?/?> *(?:\\n{2,}|\\s*$))").replace("comment",J._comment).replace(/tag/g,"(?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\b)\\w+(?!:|[^\\w\\s@]*@)\\b").getRegex(),def:/^ *\[([^\]]+)\]: *<?([^\s>]+)>?(?: +(["(][^\n]+[")]))? *(?:\n+|$)/,heading:/^(#{1,6})(.*)(?:\n+|$)/,fences:N,paragraph:W(J.normal._paragraph).replace("hr",J.hr).replace("heading"," *#{1,6} *[^\n]").replace("lheading",J.lheading).replace("blockquote"," {0,3}>").replace("|fences","").replace("|list","").replace("|html","").getRegex()});var U={escape:/^\\([!"#$%&'()*+,\-./:;<=>?@\[\]\\^_`{|}~])/,autolink:/^<(scheme:[^\s\x00-\x1f<>]*|email)>/,url:N,tag:"^comment|^</[a-zA-Z][\\w:-]*\\s*>|^<[a-zA-Z][\\w-]*(?:attribute)*?\\s*/?>|^<\\?[\\s\\S]*?\\?>|^<![a-zA-Z]+\\s[\\s\\S]*?>|^<!\\[CDATA\\[[\\s\\S]*?\\]\\]>",link:/^!?\[(label)\]\(\s*(href)(?:\s+(title))?\s*\)/,reflink:/^!?\[(label)\]\[(?!\s*\])((?:\\[\[\]]?|[^\[\]\\])+)\]/,nolink:/^!?\[(?!\s*\])((?:\[[^\[\]]*\]|\\[\[\]]|[^\[\]])*)\](?:\[\])?/,reflinkSearch:"reflink|nolink(?!\\()",emStrong:{lDelim:/^(?:\*+(?:([punct_])|[^\s*]))|^_+(?:([punct*])|([^\s_]))/,rDelimAst:/\_\_[^_]*?\*[^_]*?\_\_|[punct_](\*+)(?=[\s]|$)|[^punct*_\s](\*+)(?=[punct_\s]|$)|[punct_\s](\*+)(?=[^punct*_\s])|[\s](\*+)(?=[punct_])|[punct_](\*+)(?=[punct_])|[^punct*_\s](\*+)(?=[^punct*_\s])/,rDelimUnd:/\*\*[^*]*?\_[^*]*?\*\*|[punct*](\_+)(?=[\s]|$)|[^punct*_\s](\_+)(?=[punct*\s]|$)|[punct*\s](\_+)(?=[^punct*_\s])|[\s](\_+)(?=[punct*])|[punct*](\_+)(?=[punct*])/},code:/^(`+)([^`]|[^`][\s\S]*?[^`])\1(?!`)/,br:/^( {2,}|\\)\n(?!\s*$)/,del:N,text:/^(`+|[^`])(?:(?= {2,}\n)|[\s\S]*?(?:(?=[\\<!\[`*_]|\b_|$)|[^ ](?= {2,}\n)))/,punctuation:/^([\spunctuation])/,_punctuation:"!\"#$%&'()+\\-.,/:;<=>?@\\[\\]`^{|}~"};U.punctuation=W(U.punctuation).replace(/punctuation/g,U._punctuation).getRegex(),U.blockSkip=/\[[^\]]*?\]\([^\)]*?\)|`[^`]*?`|<[^>]*?>/g,U.escapedEmSt=/\\\*|\\_/g,U._comment=W(J._comment).replace("(?:--\x3e|$)","--\x3e").getRegex(),U.emStrong.lDelim=W(U.emStrong.lDelim).replace(/punct/g,U._punctuation).getRegex(),U.emStrong.rDelimAst=W(U.emStrong.rDelimAst,"g").replace(/punct/g,U._punctuation).getRegex(),U.emStrong.rDelimUnd=W(U.emStrong.rDelimUnd,"g").replace(/punct/g,U._punctuation).getRegex(),U._escapes=/\\([!"#$%&'()*+,\-./:;<=>?@\[\]\\^_`{|}~])/g,U._scheme=/[a-zA-Z][a-zA-Z0-9+.-]{1,31}/,U._email=/[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/,U.autolink=W(U.autolink).replace("scheme",U._scheme).replace("email",U._email).getRegex(),U._attribute=/\s+[a-zA-Z:_][\w.:-]*(?:\s*=\s*"[^"]*"|\s*=\s*'[^']*'|\s*=\s*[^\s"'=<>`]+)?/,U.tag=W(U.tag).replace("comment",U._comment).replace("attribute",U._attribute).getRegex(),U._label=/(?:\[(?:\\.|[^\[\]\\])*\]|\\.|`[^`]*`|[^\[\]\\`])*?/,U._href=/<(?:\\.|[^\n<>\\])+>|[^\s\x00-\x1f]*/,U._title=/"(?:\\"?|[^"\\])*"|'(?:\\'?|[^'\\])*'|\((?:\\\)?|[^)\\])*\)/,U.link=W(U.link).replace("label",U._label).replace("href",U._href).replace("title",U._title).getRegex(),U.reflink=W(U.reflink).replace("label",U._label).getRegex(),U.reflinkSearch=W(U.reflinkSearch,"g").replace("reflink",U.reflink).replace("nolink",U.nolink).getRegex(),U.normal=H({},U),U.pedantic=H({},U.normal,{strong:{start:/^__|\*\*/,middle:/^__(?=\S)([\s\S]*?\S)__(?!_)|^\*\*(?=\S)([\s\S]*?\S)\*\*(?!\*)/,endAst:/\*\*(?!\*)/g,endUnd:/__(?!_)/g},em:{start:/^_|\*/,middle:/^()\*(?=\S)([\s\S]*?\S)\*(?!\*)|^_(?=\S)([\s\S]*?\S)_(?!_)/,endAst:/\*(?!\*)/g,endUnd:/_(?!_)/g},link:W(/^!?\[(label)\]\((.*?)\)/).replace("label",U._label).getRegex(),reflink:W(/^!?\[(label)\]\s*\[([^\]]*)\]/).replace("label",U._label).getRegex()}),U.gfm=H({},U.normal,{escape:W(U.escape).replace("])","~|])").getRegex(),_extended_email:/[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/,url:/^((?:ftp|https?):\/\/|www\.)(?:[a-zA-Z0-9\-]+\.?)+[^\s<]*|^email/,_backpedal:/(?:[^?!.,:;*_~()&]+|\([^)]*\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_~)]+(?!$))+/,del:/^(~~?)(?=[^\s~])([\s\S]*?[^\s~])\1(?=[^~]|$)/,text:/^([`~]+|[^`~])(?:(?= {2,}\n)|[\s\S]*?(?:(?=[\\<!\[`*~_]|\b_|https?:\/\/|ftp:\/\/|www\.|$)|[^ ](?= {2,}\n)|[^a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-](?=[a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-]+@))|(?=[a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-]+@))/}),U.gfm.url=W(U.gfm.url,"i").replace("email",U.gfm._extended_email).getRegex(),U.breaks=H({},U.gfm,{br:W(U.br).replace("{2,}","*").getRegex(),text:W(U.gfm.text).replace("\\b_","\\b_| {2,}\\n").replace(/\{2,\}/g,"*").getRegex()});var Y={block:J,inline:U},Q=q,V=o.exports.defaults,Z=Y.block,X=Y.inline,$=R.repeatString;function K(e){return e.replace(/---/g,"\u2014").replace(/--/g,"\u2013").replace(/(^|[-\u2014/(\[{"\s])'/g,"$1\u2018").replace(/'/g,"\u2019").replace(/(^|[-\u2014/(\[{\u2018\s])"/g,"$1\u201c").replace(/"/g,"\u201d").replace(/\.{3}/g,"\u2026")}function ee(e){var n,t,a="",i=e.length;for(n=0;n<i;n++)t=e.charCodeAt(n),Math.random()>.5&&(t="x"+t.toString(16)),a+="&#"+t+";";return a}var ne=function(){function e(e){this.tokens=[],this.tokens.links=Object.create(null),this.options=e||V,this.options.tokenizer=this.options.tokenizer||new Q,this.tokenizer=this.options.tokenizer,this.tokenizer.options=this.options;var n={block:Z.normal,inline:X.normal};this.options.pedantic?(n.block=Z.pedantic,n.inline=X.pedantic):this.options.gfm&&(n.block=Z.gfm,this.options.breaks?n.inline=X.breaks:n.inline=X.gfm),this.tokenizer.rules=n}e.lex=function(n,t){return new e(t).lex(n)},e.lexInline=function(n,t){return new e(t).inlineTokens(n)};var t=e.prototype;return t.lex=function(e){return e=e.replace(/\r\n|\r/g,"\n").replace(/\t/g,"    "),this.blockTokens(e,this.tokens,!0),this.inline(this.tokens),this.tokens},t.blockTokens=function(e,n,t){var a,i,o,r;for(void 0===n&&(n=[]),void 0===t&&(t=!0),this.options.pedantic&&(e=e.replace(/^ +$/gm,""));e;)if(a=this.tokenizer.space(e))e=e.substring(a.raw.length),a.type&&n.push(a);else if(a=this.tokenizer.code(e))e=e.substring(a.raw.length),(r=n[n.length-1])&&"paragraph"===r.type?(r.raw+="\n"+a.raw,r.text+="\n"+a.text):n.push(a);else if(a=this.tokenizer.fences(e))e=e.substring(a.raw.length),n.push(a);else if(a=this.tokenizer.heading(e))e=e.substring(a.raw.length),n.push(a);else if(a=this.tokenizer.nptable(e))e=e.substring(a.raw.length),n.push(a);else if(a=this.tokenizer.hr(e))e=e.substring(a.raw.length),n.push(a);else if(a=this.tokenizer.blockquote(e))e=e.substring(a.raw.length),a.tokens=this.blockTokens(a.text,[],t),n.push(a);else if(a=this.tokenizer.list(e)){for(e=e.substring(a.raw.length),o=a.items.length,i=0;i<o;i++)a.items[i].tokens=this.blockTokens(a.items[i].text,[],!1);n.push(a)}else if(a=this.tokenizer.html(e))e=e.substring(a.raw.length),n.push(a);else if(t&&(a=this.tokenizer.def(e)))e=e.substring(a.raw.length),this.tokens.links[a.tag]||(this.tokens.links[a.tag]={href:a.href,title:a.title});else if(a=this.tokenizer.table(e))e=e.substring(a.raw.length),n.push(a);else if(a=this.tokenizer.lheading(e))e=e.substring(a.raw.length),n.push(a);else if(t&&(a=this.tokenizer.paragraph(e)))e=e.substring(a.raw.length),n.push(a);else if(a=this.tokenizer.text(e))e=e.substring(a.raw.length),(r=n[n.length-1])&&"text"===r.type?(r.raw+="\n"+a.raw,r.text+="\n"+a.text):n.push(a);else if(e){var s="Infinite loop on byte: "+e.charCodeAt(0);if(this.options.silent){console.error(s);break}throw new Error(s)}return n},t.inline=function(e){var n,t,a,i,o,r,s=e.length;for(n=0;n<s;n++)switch((r=e[n]).type){case"paragraph":case"text":case"heading":r.tokens=[],this.inlineTokens(r.text,r.tokens);break;case"table":for(r.tokens={header:[],cells:[]},i=r.header.length,t=0;t<i;t++)r.tokens.header[t]=[],this.inlineTokens(r.header[t],r.tokens.header[t]);for(i=r.cells.length,t=0;t<i;t++)for(o=r.cells[t],r.tokens.cells[t]=[],a=0;a<o.length;a++)r.tokens.cells[t][a]=[],this.inlineTokens(o[a],r.tokens.cells[t][a]);break;case"blockquote":this.inline(r.tokens);break;case"list":for(i=r.items.length,t=0;t<i;t++)this.inline(r.items[t].tokens)}return e},t.inlineTokens=function(e,n,t,a){var i,o;void 0===n&&(n=[]),void 0===t&&(t=!1),void 0===a&&(a=!1);var r,s,l,c=e;if(this.tokens.links){var u=Object.keys(this.tokens.links);if(u.length>0)for(;null!=(r=this.tokenizer.rules.inline.reflinkSearch.exec(c));)u.includes(r[0].slice(r[0].lastIndexOf("[")+1,-1))&&(c=c.slice(0,r.index)+"["+$("a",r[0].length-2)+"]"+c.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex))}for(;null!=(r=this.tokenizer.rules.inline.blockSkip.exec(c));)c=c.slice(0,r.index)+"["+$("a",r[0].length-2)+"]"+c.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);for(;null!=(r=this.tokenizer.rules.inline.escapedEmSt.exec(c));)c=c.slice(0,r.index)+"++"+c.slice(this.tokenizer.rules.inline.escapedEmSt.lastIndex);for(;e;)if(s||(l=""),s=!1,i=this.tokenizer.escape(e))e=e.substring(i.raw.length),n.push(i);else if(i=this.tokenizer.tag(e,t,a)){e=e.substring(i.raw.length),t=i.inLink,a=i.inRawBlock;var h=n[n.length-1];h&&"text"===i.type&&"text"===h.type?(h.raw+=i.raw,h.text+=i.text):n.push(i)}else if(i=this.tokenizer.link(e))e=e.substring(i.raw.length),"link"===i.type&&(i.tokens=this.inlineTokens(i.text,[],!0,a)),n.push(i);else if(i=this.tokenizer.reflink(e,this.tokens.links)){e=e.substring(i.raw.length);var d=n[n.length-1];"link"===i.type?(i.tokens=this.inlineTokens(i.text,[],!0,a),n.push(i)):d&&"text"===i.type&&"text"===d.type?(d.raw+=i.raw,d.text+=i.text):n.push(i)}else if(i=this.tokenizer.emStrong(e,c,l))e=e.substring(i.raw.length),i.tokens=this.inlineTokens(i.text,[],t,a),n.push(i);else if(i=this.tokenizer.codespan(e))e=e.substring(i.raw.length),n.push(i);else if(i=this.tokenizer.br(e))e=e.substring(i.raw.length),n.push(i);else if(i=this.tokenizer.del(e))e=e.substring(i.raw.length),i.tokens=this.inlineTokens(i.text,[],t,a),n.push(i);else if(i=this.tokenizer.autolink(e,ee))e=e.substring(i.raw.length),n.push(i);else if(t||!(i=this.tokenizer.url(e,ee))){if(i=this.tokenizer.inlineText(e,a,K))e=e.substring(i.raw.length),"_"!==i.raw.slice(-1)&&(l=i.raw.slice(-1)),s=!0,(o=n[n.length-1])&&"text"===o.type?(o.raw+=i.raw,o.text+=i.text):n.push(i);else if(e){var p="Infinite loop on byte: "+e.charCodeAt(0);if(this.options.silent){console.error(p);break}throw new Error(p)}}else e=e.substring(i.raw.length),n.push(i);return n},n(e,null,[{key:"rules",get:function(){return{block:Z,inline:X}}}]),e}(),te=o.exports.defaults,ae=R.cleanUrl,ie=R.escape,oe=function(){function e(e){this.options=e||te}var n=e.prototype;return n.code=function(e,n,t){var a=(n||"").match(/\S*/)[0];if(this.options.highlight){var i=this.options.highlight(e,a);null!=i&&i!==e&&(t=!0,e=i)}return e=e.replace(/\n$/,"")+"\n",a?'<pre><code class="'+this.options.langPrefix+ie(a,!0)+'">'+(t?e:ie(e,!0))+"</code></pre>\n":"<pre><code>"+(t?e:ie(e,!0))+"</code></pre>\n"},n.blockquote=function(e){return"<blockquote>\n"+e+"</blockquote>\n"},n.html=function(e){return e},n.heading=function(e,n,t,a){return this.options.headerIds?"<h"+n+' id="'+this.options.headerPrefix+a.slug(t)+'">'+e+"</h"+n+">\n":"<h"+n+">"+e+"</h"+n+">\n"},n.hr=function(){return this.options.xhtml?"<hr/>\n":"<hr>\n"},n.list=function(e,n,t){var a=n?"ol":"ul";return"<"+a+(n&&1!==t?' start="'+t+'"':"")+">\n"+e+"</"+a+">\n"},n.listitem=function(e){return"<li>"+e+"</li>\n"},n.checkbox=function(e){return"<input "+(e?'checked="" ':"")+'disabled="" type="checkbox"'+(this.options.xhtml?" /":"")+"> "},n.paragraph=function(e){return"<p>"+e+"</p>\n"},n.table=function(e,n){return n&&(n="<tbody>"+n+"</tbody>"),"<table>\n<thead>\n"+e+"</thead>\n"+n+"</table>\n"},n.tablerow=function(e){return"<tr>\n"+e+"</tr>\n"},n.tablecell=function(e,n){var t=n.header?"th":"td";return(n.align?"<"+t+' align="'+n.align+'">':"<"+t+">")+e+"</"+t+">\n"},n.strong=function(e){return"<strong>"+e+"</strong>"},n.em=function(e){return"<em>"+e+"</em>"},n.codespan=function(e){return"<code>"+e+"</code>"},n.br=function(){return this.options.xhtml?"<br/>":"<br>"},n.del=function(e){return"<del>"+e+"</del>"},n.link=function(e,n,t){if(null===(e=ae(this.options.sanitize,this.options.baseUrl,e)))return t;var a='<a href="'+ie(e)+'"';return n&&(a+=' title="'+n+'"'),a+=">"+t+"</a>"},n.image=function(e,n,t){if(null===(e=ae(this.options.sanitize,this.options.baseUrl,e)))return t;var a='<img src="'+e+'" alt="'+t+'"';return n&&(a+=' title="'+n+'"'),a+=this.options.xhtml?"/>":">"},n.text=function(e){return e},e}(),re=function(){function e(){}var n=e.prototype;return n.strong=function(e){return e},n.em=function(e){return e},n.codespan=function(e){return e},n.del=function(e){return e},n.html=function(e){return e},n.text=function(e){return e},n.link=function(e,n,t){return""+t},n.image=function(e,n,t){return""+t},n.br=function(){return""},e}(),se=function(){function e(){this.seen={}}var n=e.prototype;return n.serialize=function(e){return e.toLowerCase().trim().replace(/<[!\/a-z].*?>/gi,"").replace(/[\u2000-\u206F\u2E00-\u2E7F\\'!"#$%&()*+,./:;<=>?@[\]^`{|}~]/g,"").replace(/\s/g,"-")},n.getNextSafeSlug=function(e,n){var t=e,a=0;if(this.seen.hasOwnProperty(t)){a=this.seen[e];do{t=e+"-"+ ++a}while(this.seen.hasOwnProperty(t))}return n||(this.seen[e]=a,this.seen[t]=0),t},n.slug=function(e,n){void 0===n&&(n={});var t=this.serialize(e);return this.getNextSafeSlug(t,n.dryrun)},e}(),le=oe,ce=re,ue=se,he=o.exports.defaults,de=R.unescape,pe=ne,me=function(){function e(e){this.options=e||he,this.options.renderer=this.options.renderer||new le,this.renderer=this.options.renderer,this.renderer.options=this.options,this.textRenderer=new ce,this.slugger=new ue}e.parse=function(n,t){return new e(t).parse(n)},e.parseInline=function(n,t){return new e(t).parseInline(n)};var n=e.prototype;return n.parse=function(e,n){void 0===n&&(n=!0);var t,a,i,o,r,s,l,c,u,h,d,p,m,g,f,w,b,y,v="",k=e.length;for(t=0;t<k;t++)switch((h=e[t]).type){case"space":continue;case"hr":v+=this.renderer.hr();continue;case"heading":v+=this.renderer.heading(this.parseInline(h.tokens),h.depth,de(this.parseInline(h.tokens,this.textRenderer)),this.slugger);continue;case"code":v+=this.renderer.code(h.text,h.lang,h.escaped);continue;case"table":for(c="",l="",o=h.header.length,a=0;a<o;a++)l+=this.renderer.tablecell(this.parseInline(h.tokens.header[a]),{header:!0,align:h.align[a]});for(c+=this.renderer.tablerow(l),u="",o=h.cells.length,a=0;a<o;a++){for(l="",r=(s=h.tokens.cells[a]).length,i=0;i<r;i++)l+=this.renderer.tablecell(this.parseInline(s[i]),{header:!1,align:h.align[i]});u+=this.renderer.tablerow(l)}v+=this.renderer.table(c,u);continue;case"blockquote":u=this.parse(h.tokens),v+=this.renderer.blockquote(u);continue;case"list":for(d=h.ordered,p=h.start,m=h.loose,o=h.items.length,u="",a=0;a<o;a++)w=(f=h.items[a]).checked,b=f.task,g="",f.task&&(y=this.renderer.checkbox(w),m?f.tokens.length>0&&"text"===f.tokens[0].type?(f.tokens[0].text=y+" "+f.tokens[0].text,f.tokens[0].tokens&&f.tokens[0].tokens.length>0&&"text"===f.tokens[0].tokens[0].type&&(f.tokens[0].tokens[0].text=y+" "+f.tokens[0].tokens[0].text)):f.tokens.unshift({type:"text",text:y}):g+=y),g+=this.parse(f.tokens,m),u+=this.renderer.listitem(g,b,w);v+=this.renderer.list(u,d,p);continue;case"html":v+=this.renderer.html(h.text);continue;case"paragraph":v+=this.renderer.paragraph(this.parseInline(h.tokens));continue;case"text":for(u=h.tokens?this.parseInline(h.tokens):h.text;t+1<k&&"text"===e[t+1].type;)u+="\n"+((h=e[++t]).tokens?this.parseInline(h.tokens):h.text);v+=n?this.renderer.paragraph(u):u;continue;default:var x='Token with "'+h.type+'" type was not found.';if(this.options.silent)return void console.error(x);throw new Error(x)}return v},n.parseInline=function(e,n){n=n||this.renderer;var t,a,i="",o=e.length;for(t=0;t<o;t++)switch((a=e[t]).type){case"escape":i+=n.text(a.text);break;case"html":i+=n.html(a.text);break;case"link":i+=n.link(a.href,a.title,this.parseInline(a.tokens,n));break;case"image":i+=n.image(a.href,a.title,a.text);break;case"strong":i+=n.strong(this.parseInline(a.tokens,n));break;case"em":i+=n.em(this.parseInline(a.tokens,n));break;case"codespan":i+=n.codespan(a.text);break;case"br":i+=n.br();break;case"del":i+=n.del(this.parseInline(a.tokens,n));break;case"text":i+=n.text(a.text);break;default:var r='Token with "'+a.type+'" type was not found.';if(this.options.silent)return void console.error(r);throw new Error(r)}return i},e}(),ge=q,fe=oe,we=re,be=se,ye=R.merge,ve=R.checkSanitizeDeprecation,ke=R.escape,xe=o.exports.getDefaults,Ae=o.exports.changeDefaults,De=o.exports.defaults;function Ee(e,n,t){if("undefined"===typeof e||null===e)throw new Error("marked(): input parameter is undefined or null");if("string"!==typeof e)throw new Error("marked(): input parameter is of type "+Object.prototype.toString.call(e)+", string expected");if("function"===typeof n&&(t=n,n=null),n=ye({},Ee.defaults,n||{}),ve(n),t){var a,i=n.highlight;try{a=pe.lex(e,n)}catch(l){return t(l)}var o=function(e){var o;if(!e)try{o=me.parse(a,n)}catch(l){e=l}return n.highlight=i,e?t(e):t(null,o)};if(!i||i.length<3)return o();if(delete n.highlight,!a.length)return o();var r=0;return Ee.walkTokens(a,(function(e){"code"===e.type&&(r++,setTimeout((function(){i(e.text,e.lang,(function(n,t){if(n)return o(n);null!=t&&t!==e.text&&(e.text=t,e.escaped=!0),0===--r&&o()}))}),0))})),void(0===r&&o())}try{var s=pe.lex(e,n);return n.walkTokens&&Ee.walkTokens(s,n.walkTokens),me.parse(s,n)}catch(l){if(l.message+="\nPlease report this to https://github.com/markedjs/marked.",n.silent)return"<p>An error occurred:</p><pre>"+ke(l.message+"",!0)+"</pre>";throw l}}return Ee.options=Ee.setOptions=function(e){return ye(Ee.defaults,e),Ae(Ee.defaults),Ee},Ee.getDefaults=xe,Ee.defaults=De,Ee.use=function(e){var n=ye({},e);if(e.renderer&&function(){var t=Ee.defaults.renderer||new fe,a=function(n){var a=t[n];t[n]=function(){for(var i=arguments.length,o=new Array(i),r=0;r<i;r++)o[r]=arguments[r];var s=e.renderer[n].apply(t,o);return!1===s&&(s=a.apply(t,o)),s}};for(var i in e.renderer)a(i);n.renderer=t}(),e.tokenizer&&function(){var t=Ee.defaults.tokenizer||new ge,a=function(n){var a=t[n];t[n]=function(){for(var i=arguments.length,o=new Array(i),r=0;r<i;r++)o[r]=arguments[r];var s=e.tokenizer[n].apply(t,o);return!1===s&&(s=a.apply(t,o)),s}};for(var i in e.tokenizer)a(i);n.tokenizer=t}(),e.walkTokens){var t=Ee.defaults.walkTokens;n.walkTokens=function(n){e.walkTokens(n),t&&t(n)}}Ee.setOptions(n)},Ee.walkTokens=function(e,n){for(var t,a=i(e);!(t=a()).done;){var o=t.value;switch(n(o),o.type){case"table":for(var r,s=i(o.tokens.header);!(r=s()).done;){var l=r.value;Ee.walkTokens(l,n)}for(var c,u=i(o.tokens.cells);!(c=u()).done;)for(var h,d=i(c.value);!(h=d()).done;){var p=h.value;Ee.walkTokens(p,n)}break;case"list":Ee.walkTokens(o.items,n);break;default:o.tokens&&Ee.walkTokens(o.tokens,n)}}},Ee.parseInline=function(e,n){if("undefined"===typeof e||null===e)throw new Error("marked.parseInline(): input parameter is undefined or null");if("string"!==typeof e)throw new Error("marked.parseInline(): input parameter is of type "+Object.prototype.toString.call(e)+", string expected");n=ye({},Ee.defaults,n||{}),ve(n);try{var t=pe.lexInline(e,n);return n.walkTokens&&Ee.walkTokens(t,n.walkTokens),me.parseInline(t,n)}catch(a){if(a.message+="\nPlease report this to https://github.com/markedjs/marked.",n.silent)return"<p>An error occurred:</p><pre>"+ke(a.message+"",!0)+"</pre>";throw a}},Ee.Parser=me,Ee.parser=me.parse,Ee.Renderer=fe,Ee.TextRenderer=we,Ee.Lexer=pe,Ee.lexer=pe.lex,Ee.Tokenizer=ge,Ee.Slugger=be,Ee.parse=Ee,Ee}()},DoYn:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Cellular Automata in IBEX\'\ndescription: \'IBEX is my game made for js13kgames. This article explains how the game has been implemented with GLSL and cellular automata.\'\nthumbnail: /images/2014/09/ibex-2.png\nauthor: Gaetan\nlayout: post\ntags:\n - gamedev\n - js13k\n - GLSL\n---\n\n [gamepost]: /2014/09/ibex\n [js13kgames]: http://js13kgames.com/\n [submission]: http://js13kgames.com/entries/ibex\n [github]: http://github.com/gre/js13k-2014\n [cellular]: http://en.wikipedia.org/wiki/Cellular_automaton\n [wolfram]: http://en.wikipedia.org/wiki/Stephen_Wolfram\n [ankos]: https://www.wolframscience.com/\n [gol]: http://en.wikipedia.org/wiki/Conway\'s_Game_of_Life\n [cavelikegen]: http://www.roguebasin.com/index.php?title=Cellular_Automata_Method_for_Generating_Random_Cave-Like_Levels\n [logicfrag]: https://github.com/gre/js13k-2014/blob/master/src/shaders/logic.frag\n\n\n<a href="/2014/09/ibex">\n  <img src="/images/2014/09/ibex-2.png" alt="" class="thumbnail-right" />\n</a>\n\nLast week I finished my [JS13K game called "IBEX"][gamepost],\nan apocalyptic game where you have to help some wild ibex to escape from the inferno.\n\n> IBEX received the 16th place (out of 129 games) from the [js13kgames][js13kgames] jury.\n\nThis article is a technical post-mortem about the development of this game in JavaScript / WebGL\nand how the world is just **ruled with [cellular automata][cellular]**\nand computed efficiently in a GLSL shader.\n\n<iframe width="50%" height="220" src="//www.youtube.com/embed/nqD2qIy4auU" frameborder="0" allowfullscreen></iframe>\n\n\x3c!--more--\x3e\n\n## Cellular automata ruled world\n\nA **Cellular Automaton** (plurial Cellular Automata) is an **automaton** *(in other words, a state machine)*\nbased on **a grid (an array) of cells**.\nIt has been discovered years ago and popularized by [Stephen Wolfram][wolfram]\nin his interesting book [A new Kind of Science][ankos].\n\n\n<figure class="thumbnail-right">\n  <img src="/images/2014/09/elementary-automaton.png" />\n  <figcaption>\n    <a href="http://mathworld.wolfram.com/ElementaryCellularAutomaton.html">\n      elementary automata.\n    </a>\n  </figcaption>\n</figure>\n\nThe simplest possible cellular automaton is the one where, at each generation,\nthe cell value is determined from the **previous and the 2 adjacent cells** (left and right)\nvalue and where the value can only be **0 or 1** (white or black / true or false).\nThe way the cell value is determined is through a set of rules.\n\n> In an elementary cellular automaton, there is a total of 8 rules, which means 256 possible cellular automata.\n\n### 2D cellular automaton\n\n<figure class="thumbnail-left">\n  <img src="/images/2014/09/Gospers_glider_gun.gif" />\n  <figcaption>\n    <a href="http://en.wikipedia.org/wiki/Conway\'s_Game_of_Life">Conway\'s Game of Life</a>,\n    a well known 2D cellular automaton.\n  </figcaption>\n</figure>\n\nThe kind of Cellular Automaton I focused on for my game is **2D cellular automaton**:\nAt each generation, the cell value is determined from **the previous value and the 8 adjacent cells**\nusing a finite set of rules.\n\nIt is important to understand that these rules are applied in parallel for __all__ cells of the world.\n\n<br />\n\n<figure class="thumbnail-right">\n  <img src="/images/2014/09/ibex-experiment2.png" />\n  <figcaption>\n    Early version with 4 elements and simple rules:\n    Water falls in Air, Fire grows in Air, Water extinguishes Fire, Earth drops Water + creates Fire\n  </figcaption>\n</figure>\n\n**A 2D cellular automaton rule:**\n\n![](/images/2014/09/ibex-rule-2d.png)\n\nWhat I\'ve found is that\n**the WebGL and the GLSL language works well to implement a cellular automaton**.\n\nThe GLSL paradigm is what I like to call [functional rendering](/2013/11/functional-rendering/):\nIt is, to simplify, a function **`(x,y) => (r,g,b,a)`**:\nYou fundamentally have to implement this function which **gives a color for a given viewport position**,\nand you implement it in a dedicated language which compiles to the GPU.\n\nSo we can implement a 2D cellular automaton where each cell is a real (x,y) position in the Texture\nand where the (r,g,b,a) color is used to encode your possible cell states, and that\'s a lot of possible encoding!\n\nIn my game, i\'ve chosen to only use the `"r"` component to implement the cell state.\nBut imagine all the possibilities of encoding more data per cell (like the velocity, the amount of particle in the cells,...).\n\n**Here is a boilerplate of making a Cellular Automaton in GLSL:**\n\n```glsl\nuniform sampler2D state; // the previous world state texture.\nuniform vec2 size; // The world size (state texture width and height)\n\n/*\n The decode / encode functions provide an example of encoding\n an integer state in the "r" component over possible 16 values.\n You can definitely implement your own. Also "int" could be something more complex\n */\nint decode (vec4 color) {\n  return int(floor(.5 + 16.0 * texture2D(state, uv).r));\n}\nvec4 encode (int value) {\n  return vec4(float(r) / 16.0,  0.0, 0.0, 1.0);\n}\n\n/*\n  get(x,y) is doing a lookup in the state texture to get the (previous) state value of a position.\n */\nint get (int x, int y) {\n  vec2 uv = (gl_FragCoord.xy + vec2(x, y)) / size;\n  return (uv.x < 0.0 || uv.x >= 1.0 || uv.y < 0.0 || uv.y >= 1.0) ? 0 :\n    decode(texture2D(state, uv).r);\n}\n\nvoid main () {\n  // We get all neighbors cell values from previous state\n  int NW = get(-1, 1);\n  int NN = get( 0, 1);\n  int NE = get( 1, 1);\n  int WW = get(-1, 0);\n  int CC = get( 0, 0);\n  int EE = get( 1, 0);\n  int SW = get(-1,-1);\n  int SS = get( 0,-1);\n  int SE = get( 1,-1);\n\n  int r; // r (for result) is the new cell value.\n\n  ////////////////////////////\n  // NOW HERE IS THE COOL PART\n  // where you implement all your rules (from the 9 state values)\n  // and give a value to r.\n  ////////////////////////////\n\n  gl_FragColor = encode(r);\n}\n```\n\n>**The complete game rules are all implemented in a GLSL fragment shader:\n[logic.frag][logicfrag]**.\nIt is important to understand that this fragment shader takes in input\nthe previous world state (as an uniform texture)\nand computes a new state by applying the rules.\n\nOn the JavaScript side, you need to **give an initial state to the texture**\n(so you need to also encode data the same way it is done in the shader).\nAlternatively you can also make a shader to do this job\n*(generating the terrain can be intense to do in JavaScript, like it is the case for my game...)*.\n\nAlso if you want to **query the world from JavaScript**,\n*(e.g. you want to do physics or collision detection like it is also the case for my game)*,\nyou need to use `gl.readPixels` and then decode data in JavaScript.\n\nI\'ll explain this a bit later in another article.\nLet\'s now go back to the Cellular Automaton used in IBEX.\n\n<figure>\n  <img src="/images/2014/09/ibex-screenshot1.png" />\n  <figcaption>\n    The different elements gameplay.\n  </figcaption>\n</figure>\n\n### The elements\n\nThe game theme was "Four Elements: **Water, Air, Earth, Fire**", so I\'ve used\nthese 4 elements as primary elements of the cellular automaton.\n\nEach elements also have secondary elements that can be created from each other interactions:\n**Source, Volcano, Grass, WindLeft, WindRight**.\n\n- The **Volcano** is lava growing in the Earth. It creates Fire (when there is Air).\n- The **Source** is water infiltrating in the Earth. It drops Water (when there is Air).\n- The **Grass** (or Forest) grows on Earth with Water. It is a speed bonus for ibex but it propagates fire very fast. It also stop the water from flowing.\n- The **Wind** (left or right wind) is created randomly in Air. It have effects on Water and Fire propagation and also on ibex speed.\n\n**Some constants...**\n\n```glsl\n// Elements\nint A  = 0; // Air\nint E  = 1; // Earth\nint F  = 2; // Fire\nint W  = 3; // Water\nint V  = 4; // Volcano\nint S  = 5; // Source\nint Al = 6; // Air Left (wind)\nint Ar = 7; // Air Right (wind)\nint G  = 8; // Grass (forest)\n```\n\n<figure class="thumbnail-right">\n  <img src="/images/2014/09/ibex-experiment1.png" />\n  <figcaption>\n    Fun and experimental result accidentally produced in an early development of the rules.\n  </figcaption>\n</figure>\n\nTo summary, there is 9 possible elements,\nand rules are determined from the 9 previous cells:\nThis makes a LOT of possible rules.\nHowever, the rules involved here remain simple and with just a few rules.\n\n> That is the big thing about cellular automata:\nvery simple rules produce an incredible variety of results.\n\nIn general, we can classify my game rules into 2 kind of rules:\n"interaction" rules and "propagation" rules.\nThe first kind describes how two (or more!) elements interact each other.\nThe second kind describes the way an element evolve.\nSome rules will also mix them both.\n\n### Some simple "propagation rule"\n\n**Earth stays:**\nan Earth is returned if there was an Earth before.\n\n![](/images/2014/09/ibex-rule-earth.png)\n\n**Water falls in Air:**\na Water is created if there was a Water on top.\n\n![](/images/2014/09/ibex-rule-water1.png)\n\n**Fire grows in Air:**\na Fire is created if there was a Fire on bottom.\n\n![](/images/2014/09/ibex-rule-fire1.png)\n\n\nThese rules produce very elementary result, we will now see how we can improve them.\n\n### Weights in rules\n\n**More powerful rules can also be reached by using weights**:\nyou can affect a weight for each neighbor cell to give more or less importance to them.\n\nLet\'s take a look at a simple example:\n\n![](/images/2014/09/ibex-rule-gencave-example.png)\n\n> N.B.: only the "sum" is considered in the rule:\nif an element matches, we sum the weight of the cell, otherwise "zero".\n\n**This example is actually a weighted version of [the cave rule you can find here][cavelikegen]:**\n\n<figure>\n  <figcaption>\n    Result of the rule, with (Air or Earth) random pick for each  initial cell value.\n  </figcaption>\n  <img src="/images/2014/09/ibex-gencaveresult.png" />\n</figure>\n\n### Randomness in rules\n\n**Combine Randomness and Weights and you get a very powerful simulation.**\n\nTo avoid seeing some (well known) patterns in the simulation I added some randomness in my rules.\n**With randomness, the results are incredibly powerful.**\n\nIn the following video, notice how cool the fire propagation can result\nby varying the propagation randomness factor.\n\n<iframe width="100%" height="420" src="//www.youtube.com/embed/mF-MNHk7u4s" frameborder="0" allowfullscreen="allowfullscreen"></iframe>\n\n**The code:**\n\n```glsl\n#define AnyADJ(e) (NW==e||SE==e||NE==e||SW==e||NN==e||SS==e||EE==e||WW==e)\n// ^^^^^^^^ MACRO !\nif (\n  CC == G &&\n  RAND < firePropagation &&\n  ( AnyADJ(F) || AnyADJ(V) )) {\n  r = F;\n}\n```\n\n#### Randomness in GLSL ???\nGLSL is fully stateless and there is **NO WAY** to have a `random()` function in the GPU.\nThe trick to do randomness in GLSL is by invoking some math black magic:\n\n```glsl\nfloat rand(vec2 co){\n  return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);\n}\n```\n\n**`rand`** is a [popular](http://stackoverflow.com/questions/4200224/random-noise-functions-for-glsl)\nfunction which returns a pseudo-random value (from 0.0 to 1.0) for a given position.\n\nMy personal **black magic** was to define a convenient macro to have a "RAND" word which would get me\na new random number.\n\n```glsl\n#define RAND (S_=vec2(rand(S_), rand(S_+9.))).x\n```\n\n`S_` is a seed which is accumulated when calling this `RAND`.\nBecause this macro will be inlined in the code, `S_` must be defined in a local variable\n(so in summary, `RAND` is doing local side-effect).\n\n```glsl\nvec2 p = gl_FragCoord.xy;\nvec2 S_ = p + 0.001 * time;\n```\n\nNote that **the current pixel position** itself AND **the time** are both used for initializing the seed.\nIt produces **variable randomness over time and for each pixel**.\n\nLet\'s now see other examples where randomness can be very powerful.\n\n### The Water and Fire interactions\n\n**Fire grows and diverges**:\n\n![](/images/2014/09/ibex-rule-fire2.png)\n\n- the "left" and the "right" columns in this rule allows **divergence** in the way fire grows:\nInstead of growing straight up, **the fire can also move a bit left or a bit right**.\nA lower weight for these side columns make the fire diverge a bit less than a "triangle" propagation.\n\nHere is the GLSL code:\n\n```glsl\n// Fire grow / Fire + Water\nif (\n  -0.05 * float(NW==W) + -0.40 * float(NN==W) + -0.05 * float(NE==W) + // If water drop...\n  -0.50 * float(WW==W) + -0.50 * float(CC==W) + -0.50 * float(EE==W) + // ...or water nearby.\n   0.35 * float(SW==F) +  0.90 * float(SS==F) +  0.35 * float(SE==F)   // Fire will move up and expand a bit.\n >= 0.9 - 0.6 * RAND // The sum of matched weights must be enough important, also with some randomness\n) {\n  r = F;\n}\n```\n\n**Water falls, diverges and creates holes**:\n\n![](/images/2014/09/ibex-rule-water2.png)\n\n<figure class="thumbnail-right">\n  <img src="/images/2014/09/ibex-rain.png"/>\n  <figcaption>The rain in IBEX. Notice how Water diverges a bit and creates holes.</figcaption>\n</figure>\n\n- Same as the fire rule, we also have **divergence** in the water.\n- However there is one more important thing in the rule:\nthanks to the **double inequality**,\nWater is created only if there is not already too much Water:\nit **results of creating Air between the Water particules**.\nThis make Water elements to be less compact than Fire elements,\nthe water does not visually "expand" contrary to the fire.\n- The **randomness** helps a lot here to give **no visible patterns** in this job.\n\n<br />\n\nHere are all rules which creates Water:\nin this rules you can also notice how **the Water flows on Earth** and how\nthe **occasional rain** is implemented.\n\n```glsl\nif (\n// Water drop / Water + Fire\n  between(\n    0.3 * float(NW==W) +  0.9 * float(NN==W) +  0.3 * float(NE==W) +\n    0.1 * float(WW==W) + -0.3 * float(CC==F) +  0.1 * float(EE==W) +\n                         -0.3 * float(SS==F)  \n    ,\n    0.9 - 0.6 * RAND,\n    1.4 + 0.3 * RAND\n  )\n\n  || // Water flow on earth rules\n\n  !prevIsSolid &&\n  RAND < 0.98 &&\n  ( (WW==W||NW==W) && SW==E || (EE==W||NE==W) && SE==E )\n\n  || // Occasional rain\n  !prevIsSolid &&\n  p.y >= SZ.y-1.0 &&\n  rainRelativeTime < 100.0 &&\n  between(\n    p.x -\n    (rand(vec2(SD*0.7 + TI - rainRelativeTime)) * SZ.x) // Rain Start\n    ,\n    0.0,\n    100.0 * rand(vec2(SD + TI - rainRelativeTime)) // Rain Length\n  )\n\n  || // Source creates water\n  !prevIsSolid && (\n    0.9 * float(NW==S) +  1.0 * float(NN==S) +  0.9 * float(NE==S) +\n    0.7 * float(WW==S) +                        0.7 * float(EE==S)\n    >= 1.0 - 0.3 * RAND\n  )\n) {\n  r = W;\n}\n```\n\n**Source rules**\n\nThe Source can be created in the Earth by two rules:\nEither there is enough water around,\nOr there is source on top.\n\nNote the important usage of randomness.\n\n![](/images/2014/09/ibex-rule-source.png)\n\n\n### The grass propagation, Limiting the forest height\n\nTo finish, the grass needed a special extension to the so-far-used 2D cellular automaton,\nthe grass cell value is not only being determined from the 8 adjacent cells:\n\nTo have more complex structure, **the grass is determined\nfrom the previous cell at position `(x, y-N)`**,\nwhere x and y is the cell position and N is a variable value (random but constant per cell position).\nIn other word, a forest can grow if the cell at N step under it is not a forest.\nThis extra rule just adds a constraint on the max height that a forest can have.\n\n<figure>\n  <figcaption>A Grass can be created if the (x,y-N) cell is not a Grass.</figcaption>\n  <img src="/images/2014/09/ibex-rule-forest-specific.png" />\n</figure>\n\n\nHere is a demo showing the forest propagation randomness:\n\n<iframe width="100%" height="480" src="//www.youtube.com/embed/V_enCKx8XHA" frameborder="0" allowfullscreen="allowfullscreen"></iframe>\n\n\n### Drawing into the world\n\n**Drawing into the world is also done in GLSL: through uniforms.**\nAnother alternative way to do that would have be to use `gl.readPixels` to extract it out in JavaScript,\nto write into the Array and inject it back to the shader...\nbut this solution is not optimal because `readPixels` is blocking and costy (CPU time).\n\n```glsl\nuniform bool draw; // if true, we must draw for this tick.\nuniform ivec2 drawPosition; // The position of the drawing brush\nuniform float drawRadius; // The radius of the drawing brush\nuniform int drawObject; // The element to draw\n\n\nvoid main (void) {\n  ...\n  bool prevIsSolid = CC==E||CC==G||CC==V||CC==S;\n\n  if (draw) {\n    vec2 pos = floor(p);\n    if (distance(pos, vec2(drawPosition)) <= drawRadius) {\n    // Inside the brush disc\n      if (drawObject == W) {\n        // Draw Water\n        if (prevIsSolid && CC!=G) {\n          // Source is drawn instead if there was a solid cell\n          r = S;\n        }\n        else if (!prevIsSolid && mod(pos.x + pos.y, 2.0)==0.0) {\n          // We draw Water half of the time because Water is destroyed when surrounded by Water\n          r = W;\n        }\n      }\n      else if (drawObject == F) {\n        // Draw fire or volcano if solid cell.\n        r = prevIsSolid ? V : F;\n      }\n      else {\n        // Draw any other element\n        r = drawObject;\n      }\n    }\n  }\n\n  ...\n}\n```\n\n## World generation is also a Cellular automaton!\n\nThe world is generated on the fly when the ibex progress to the right. This is done chunk by chunk.\n\n> More precisely, the world height is 256 pixels and a new part of the world is discovered each 128 pixels \u2013\nIn other words, the generation is divided into world chunks of `(128 x 256)` pixels.\n\nEach world chunk is generated using a cellular automaton (different from the simulation one).\n\nAs shown in a previous example,\nwe can easily generate "cave like maps" from [this technique][cavelikegen].\nI\'ve added to this a [few improvments](https://github.com/gre/js13k-2014/blob/master/src/index.js#L842):\n\n- The [initial random conditions](https://github.com/gre/js13k-2014/blob/master/src/index.js#L881) ensure\nthat **the bottom of the world is Earth** and that **the top of the world is Air**.\n*(that with gradients of randomness)*\n- [Randomness](https://github.com/gre/js13k-2014/blob/master/src/index.js#L896-L906)\nhas been added to the rules to make the terrain evolving a bit more\n*(otherwise it creates stable but small caves)*.\n- The number of generation step is set to 26. the randomness of the rules is decreasing through steps to produce stable results.\n- In an attempt to create **seamless maps**,\nthe initial random state for x=0 is set to the values of x=127 of the previous world chunk.\n[(code here)](https://github.com/gre/js13k-2014/blob/master/src/index.js#L878)\nIt isn\'t perfect because you can still notice some edges.\n- For **more diversity in generated chunks**, here are the parameters that can [randomly vary](https://github.com/gre/js13k-2014/blob/master/src/index.js#L845-L848):\n  - The **amount of Earth** (can create dense areas VS floating platform areas)\n  - The **chance of Water Source** in the Earth (will creates a lot of forest)\n  - The **chance of Volcano** in the Earth (dangerous world chunk)\n\n![](/images/2014/09/ibex-gen-variety.png)\n\n\n## More articles to come\n\nDid you like this article?\n\nI\'ll try to write more about these subjects:\n\n- The **"Pixels paradigm"**, Pixel as first class citizen: How to query and analyze the pixels world. How to do simple bitmap collision detection.\n- The **game rendering performed in a GLSL shader** and all the graphics details I\'ve spent hours on.\n- **things I\'ve learned from WebGL**, how to solve the bad approaches I\'ve taken,\nand how I could have made a much more efficient game.\n- **what could have made this game even more interesting**,\nand some ideas that was not reachable in a 2 weeks deadline.\n'},DpoN:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Work in <progress />"\ndescription: A progress tag will be displayed on recent browsers with a OS-native progress bar representing a loading.\nthumbnail: /images/2012/04/progress_mac.png\nauthor: Gaetan\nlayout: post\npermalink: /2012/04/work-in-progress/\ntags:\n  - html\n  - javascript\n---\n\n**Did you know browsers now have a built-in HTML tag for making progress bar?**\n\n<progress style="width: 50%">(progress is not supported)</progress>\n\nHow cool is that!\n\nIt is perfect for making web applications loading bar in just one line of HTML and a few Javascript code.\n\nA progress tag will be displayed on recent browsers with a OS-native progress bar representing a loading. Like many HTML tag, if it is not supported, it fallbacks nicely by displaying its inner content. This fallback content should either be your own designed progress bar or simply display a percentage.\n\nIt is today supported by Firefox 9 , Chrome, Opera and IE10.\n\n\x3c!--more--\x3e\n\n## Example\n\n```html\n<progress value="23" max="100">23 %</progress>\n```\n\n### On your browser:\n\n<progress value="23" max="100">23 %</progress>\n\n### On Linux / Firefox (with GNOME)\n\n![](/images/2012/04/progress.png)\n\n### On Mac OS / Chrome:\n\n![](/images/2012/04/progress_mac.png)\n\n### On IE 6:\n\n![](/images/2012/04/progress_ie.png)\n\n## Let\u2019s see some cases:\n\n### waiting\n\n<progress max="1000"></progress>\n\n```html\n<progress max="1000"></progress>\n```\n\n### starting\n\n<progress value="0" max="1000"></progress>\n\n```html\n<progress value="0" max="1000"></progress>\n```\n\n### in progress:\n\n<progress value="500" max="1000"></progress>\n\n```html\n<progress value="500" max="1000"></progress>\n```\n\n### finished:\n\n<progress value="1000" max="1000"></progress>\n\n```html\n<progress value="1000" max="1000"></progress>\n```\n\n## Making a download bar\n\nWhen you need to load big resource like images, videos, or 3D materials, you usually want to display the progress of the download.  \nYou could still do it using some divs and CSS Javascript, but this is now much simpler to use a :\n\n### One line of HTML:\n\n```html\n<progress id="download"></progress>\n```\n\n### And the Javascript:\n\n(for more convenience, we are using jQuery)\n\n```javascript\nvar totalBytes = 10000000; // CHANGE ME WITH THE SIZE OF THE RESOURCE\nvar req = new XMLHttpRequest();\nvar progress = $(\'#download\');\nprogress.attr("max", totalBytes);\nreq.addEventListener("progress", function (e) {\n\xa0 progress.attr("value", e.loaded).text(Math.floor(100*e.loaded/totalBytes) " %");\n}, false); \xa0\nreq.addEventListener("load", function (e) {\n\xa0 // THE RESOURCE IS LOADED\n\xa0 progress.replaceWith("Downloaded!");\n});\nreq.open("GET","resource.dat",true);\nreq.send();\n```\n\nIt is quite easy to extend my code to support multiple files to download.\n\nIt is also easy to use this progress bar for anything else, but remember it represents a progress. If you want to represent some kind of stats, refer to the dedicated tag.\n'},DsvB:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "CryptoAliens: Genesis, a technical look"\nthumbnail: "/images/posts/cryptoaliens/026_px.png"\ndescription: "Technical aspects of CryptoAliens digital creatures generated with Ethereum blockchain blocks. They can be minted on ethblock.at by anyone, which establishes a limited set of CryptoAliens species."\ntags:\n  - NFT\n  - shaders\n---\n\n[main]: /2021/04/cryptoaliens\n\n> See also [CryptoAliens: Genesis][main] main article.\n\nThis article explains how [CryptoAliens: Genesis (ethblock.art)][main] works in technical depth.\n\n<img src="/images/posts/cryptoaliens/032_px.png" width="50%" /><img src="/images/posts/cryptoaliens/036_px.png" width="50%" />\n\nFirst of all, I would like to point out the [source code is available here on Github](https://github.com/gre/gre/tree/master/blockarts/CryptoAliens).\n\nThis whole idea was kicked off on [Twitch](https://twitch.tv/greweb). A recording is [available on Youtube](https://www.youtube.com/watch?v=WUzOlLq0IAo). Apart from the many glitches this 3 hours session had remained to be solved, the main part of this was implemented that night. Indeed I had to work countlessly on polishing the shaders, lighting and post-processing. I also spent a lot of time using the block data in a meaningful way because it\'s what [EthBlock.art](https://ethblock.art) really is about.\n\n## EthBlock.art revolutionary idea\n\nBefore going further into the technical details of CryptoAliens, I would like to point out how revolutionary this EthBlock.art idea is.\n\nThe project aims to create a virtuous ecosystem of "deterministic art", code visualization of Ethereum blocks. Everything is data: from the ethereum block of transactions, to the code that visualize it, and to the NFTs minted/traded using Ethereum transactions (that themselves are into Ethereum blocks).\n\n**This is a virtuous ecosystem, similar to [Supply Chain Transformation concepts](https://en.wikipedia.org/wiki/Value_chain): each actor in this ecosystem add value and get retributed for it, as I tried to explain in this schema:**\n\n![](/images/posts/cryptoaliens/ethblockart.png)\n\n`CryptoAliens: Genesis` is one possible BlockStyle that I\'ve designed, as a creative coder. It tries to visualize what happened in the Ethereum Block and will take mods into account to try to be as good as possible to deliver interesting possibilities to BlockArt minters.\n\n## Ok, so how is it implemented technically?\n\nIndeed WebGL.\n\nMore precisely, it is implemented with [`gl-react`](https://github.com/gre/gl-react) which is convenient to write and compose [_GLSL Fragment Shaders_](https://www.khronos.org/opengl/wiki/Fragment_Shader).\n\n**here is the big picture of the pipeline:**\n\n![](/images/posts/cryptoaliens/graph.gif)\n\nThere are 2 main shaders: Mandelglitch (for skin texturing) and Scene (the main raymarching shader). Each of them take a bunch of parameters. `mod1..4` are values from the creator. The rest are inferred from the Block information, they are split into multiple parameters for convenience.\n\nThe parameters `s1..9` are coming directly from `mersenne-twister` library, a [PRNG](https://en.wikipedia.org/wiki/Pseudorandom_number_generator) used to get a wide and deterministic variety of shapes, initialized with the block hash. That said, as pointed in the previous section, the main features of the shape are determined by Ethereum block information itself (number of transactions, timestamp, transfers, gas used,...).\n\nOn top of these, some other parameters are controling key elements they come from more block information (heavy, head, bonesK, arms info,...).\n\nThe technique implemented on the main Scene shader is [raymarching distance functions](https://www.iquilezles.org/www/articles/raymarchingdf/raymarchingdf.htm). The shapes at stake are mostly segments that are merged with a smooth union. There are many loops involved which made it challenging to optimize.\nThere may be issues on some mobile phone even tho it works on mine thanks to a "pixelated" version. (downscaling the pixels helped)\n\nBecause of an heavy usage of this technique, the main scene was really challenging to optimize, it actually runs something like 5 FPS. My choice was to not animate it directly (you can see on the rendering graph that actually the buffer don\'t need to refresh, except when a "mod" is changed). However, thanks to intermediary framebuffers we can do 60 FPS animation at the postprocessing level. This is what the final user will get as the mods are static.\n\n### Canvas 2D to draw texts\n\nA Canvas 2D element is used to draw the text that will appear on top of everything.\n\n```js\n/// canvas used to draw in postprocessing ///\nfunction FrameText({ blockNumber, dateText, width, height, kg, bones }) {\n  const onCanvasRef = (canvas) => {\n    if (!canvas) return;\n    const ctx = canvas.getContext("2d");\n    const w = ctx.canvas.width;\n    const h = ctx.canvas.height;\n    const pad = Math.round(w * 0.01);\n    const padX = Math.round(w * 0.02);\n    const fontS = Math.floor(0.19 * w) / 10;\n    const fontSize = `${fontS}px`;\n    ctx.save();\n    ctx.fillStyle = "#000";\n    ctx.fillRect(0, 0, w, h);\n    ctx.font = "bold " + fontSize + " monospace";\n    ctx.textBaseline = "top";\n    ctx.fillStyle = "#fff";\n    ctx.fillText(`CryptoAliens specimen #${blockNumber}`, padX, pad);\n    ctx.textBaseline = "bottom";\n    ctx.textAlign = "right";\n    ctx.font = fontSize + " monospace";\n    ctx.fillText(\n      `born ${dateText}, ${kg} kg, ${bones} bones`,\n      w - padX,\n      h - pad\n    );\n    ctx.restore();\n  };\n  return (\n    <canvas\n      ref={onCanvasRef}\n      width={String(width * 2)}\n      height={String(height * 2)}\n    />\n  );\n}\nconst FrameTextCached = React.memo(FrameText);\n```\n\n### How is Mandelglitch used?\n\nAs said, [Mandelglitch BlockStyle](https://ethblock.art/create/17) is re-used in this CryptoAliens BlockStyle. This really is the power of gl-react: it makes such composability really easy to do, the same way you can compose React components.\n\nYou can see in the [Youtube recording](https://www.youtube.com/watch?v=WUzOlLq0IAo) the way I have implemented it initially: it is just a simple import of Mandelglitch.js (literally the BlockStyle as-is) that I can just send as a uniform sampler2D.\n\n```\n<Node\n  shader={sceneShaders.scene}\n  uniforms={{\n    t: <Mandelglitch block={block} mod1={mod1} mod2={mod2} mod3={mod3} />,\n  ...\n```\n\nafter that, it was simpler to embed Mandelglitch in the BlockStyle.\n\nThe way Mandelglitch texturing is used however is that I will only use the "red" component and remap it to CryptoAliens\' own palette, in order to have a better control of the coloring.\n\n### Code organisation\n\nReact and Gl-React allows to organize the code relatively easily. First of all each pass in the rendering scene is a component, then shaders are organized in the `Shaders.create` usage. I\'ve tried to collocate them (still in same one big file to simplify the upload to EthBlock.art).\n\nI find it pretty convenient to externalize piece of the logic into "hooks" function. Example:\n\n```js\nconst CustomStyle = (props) => {\n  // prettier-ignore\n  const { block, attributesRef, mod1, mod2, mod3, mod4, highQuality, width, height } = props;\n  // prettier-ignore\n  const { kg, bones, theme, background, s1, s2, s3, s4, s5, s6, s7, s8, heavy, head, bonesK, armsLen, armsSpread, armsCenter, armsEndW, dateText, blockNumber } =\n    useBlockDerivedData(block, mod1, mod2, mod3, mod4);\n\n  useAttributesSync(attributesRef, kg, bones, theme);\n\n  return (\n    <LiveTV\n      text={\n        <FrameTextCached ... />\n      }\n      ...\n    >\n      <NearestCopy width={w} height={h}>\n        <Scene\n          t={<MandelglitchCached ... />}\n          ...\n        />\n      </NearestCopy>\n    </LiveTV>\n  );\n};\n```\n\n`useBlockDerivedData` internally uses `useMemo` in order to cache the computation of block data interpretation.\n\nIn order to make **only** one part of the tree to actively re-render, i\'ve used a local `useTime` that would re-render only that part (the LiveTV final shader). It\'s implementation is trivial:\n\n```js\nfunction useTime() {\n  const [time, setTime] = useState(0);\n  useEffect(() => {\n    let startT;\n    let h;\n    function loop(t) {\n      h = requestAnimationFrame(loop);\n      if (!startT) startT = t;\n      setTime((t - startT) / 1000);\n    }\n    h = requestAnimationFrame(loop);\n    return () => cancelAnimationFrame(h);\n  }, []);\n  return time;\n}\n```\n\n## Arms joints rotation, GLSL random and determinism\n\nOk, this is a hard topic. But it\'s extremely important that every BlockArt reliably produce the same result with the same block data, regardless of the computer used.\n\nThat last "regardless of computer used" part has challenged me at the last minute! JavaScript doesn\'t have this problem because it\'s stable between implementations (computers, engines). However, **this is not the case with OpenGL / GLSL**: every computer, every hardware (GPU) or possibly the "backend" implementation for WebGL ([ANGLE](https://github.com/google/angle) have different backends) can differ when it comes to float precision and primitive results.\n\nIn my shader, I was using the classical `random` function that is documented at https://thebookofshaders.com/10/\n\n```cpp\nfloat random (vec2 st) {\n  return fract(sin(dot(st.xy, vec2(12.9898,78.233))) * 43758.5453123);\n}\n```\n\nIt works very well when you need a nice 2D distributed noise for basic effects **but it is very bad if you strongly rely on a stable & consistent noise to generate different shapes**.\n\nEmpirically, I can observe that `sin()` yields different results on different computers.\n\nThis was impacting me badly because I was able to see very various shapes:\n\n<img src="/images/posts/cryptoaliens/rand1.png" width="33%"/><img src="/images/posts/cryptoaliens/rand2.png" width="33%"/><img src="/images/posts/cryptoaliens/rand3.png" width="33%"/>\n\nWhat I need to varies a bit here is just the angle at each joint of the arms. This is very important for the uniqueness of the creature. The problem is that if each value changes a tiny bit, the whole thing diverge VERY QUICKLY, as the rotation angle will accumulate.\n\nWorse than that, I had a bad pattern to accumulate randomness like this:\n\n```cpp\nfloat ss1 = s1;\nfor (int i = 0; i < armsLen; i++) {\n  ss1 = random(ss1);\n  ...\n}\n```\n\nActually I don\'t need that, first of all it\'s probably not good for performance, secondly I can just afford taking the fractional part of a simple polynomial:\n\n```cpp\nfloat arm (inout vec3 p, float index, float w, float h) {\n  float s = sdSegment(p, h, w);\n  float base1 = 305.53 * s1 + 77.21 * index;\n  float base2 = 403.53 * s2 + 69.71 * index;\n  for (int i = 0; i < armsLen; i++) {\n    float fi = float(i);\n    float ss1 = fract(base1 + 9.412 * fi);\n    float ss2 = fract(base2 + 8.823 * fi);\n    pR(p.xy, 8. * s4 * (ss2-.5));\n    pR(p.xz, 6. * s5 * (ss1-.5));\n    s = fOpUnionSoft(bonesK, s, sdSegment(p, h, w));\n    h *= .9;\n    w *= .9;\n    p.y -= 1.2 * h;\n  }\n  s = fOpUnionSoft(bonesK + 0.2 * s5, s, length(p) - armsEndW);\n  return s;\n}\n```\n\nNote that here it\'s very arbitrary numbers, the point is to obtain variety and unpredictability in the results. `fract` is a very simple operation (take the fractional part of the number). Indeed i\'m still prone to approximation, but the risk is limited by the fact i don\'t go too high in values here. Worse case scenario is it varies a bit the rotation but it should be so tiny that it won\'t be visible.\n\nAs said before and as seen in this code, the number will be used to do rotations (that `pR` is transforming `p` with some rotations). I use `s4` and `s5` values to give the magnitude of rotations.\n\n**Let\'s look at a few cases:**\n\nIf both s4 and s5 are very near 0.0, it will be straight arms (it\'s a rare case therefore).\n\n<img src="/images/posts/cryptoaliens/042_px.png" width="50%"/><img src="/images/posts/cryptoaliens/033_px.png" width="50%"/>\n\nIf one of the s4 or s5 are 0.0, it will be only happening on one "plan", or slightly diverging spirals, which I assume also to be rare cases:\n\n<img src="/images/posts/cryptoaliens/017_px.png" width="50%"/><img src="/images/posts/cryptoaliens/020_px.png" width="50%"/>\n\nOtherwise, most of the times, it will be relatively random:\n\n<img src="/images/posts/cryptoaliens/029_px.png" width="50%"/><img src="/images/posts/cryptoaliens/032_px.png" width="50%"/>\n<img src="/images/posts/cryptoaliens/028_px.png" width="50%"/><img src="/images/posts/cryptoaliens/026_px.png" width="50%"/>\n\n## going 128px. Last minute decision, hard tradeoff\n\nDue to concerns on the "deterministic rendering" from Ethblock.art folks, I had to make a choice regarding the fact it was too slow on mobile... I\'ve decided to switch to 128x128 rendering for ALL platforms so it\'s consistent.\n\nAll the images on that article were done on 1024x1024 which is slow on computer and not even working on my mobile phone. (OnePlus)\n\nIt\'s hard to have efficient raymarching today when you have many items.\n\n**Ultimately, I like how it finally looks, there were some minimalism / cell shaded styles,.. now it embraces Pixel Art even more!**\n\n<img src="/images/posts/cryptoaliens/r02.png" width="50%" /><img src="/images/posts/cryptoaliens/r01.png" width="50%" />\n\nIt\'s also always possible to make higher quality version of these rendering and I\'m excited to experiment more of these in future.\n\n---\n\nMy name is Ga\xebtan Renaudeau, and I\'m a noise explorer. **feel free to ping me on Twitter [@greweb](https://twitter.com/greweb)**\n'},E3sc:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Hack-a-plot avatar hatching 2"\nthumbnail: "/images/plots/173.jpg"\ndescription: "Plots made during an internal Hackathon at Ledger using profile picture, hatching and contouring techniques."\ntags:\n  - contour\n  - hatching\n---\n\nPlots made during an internal Hackathon at Ledger using profile picture, hatching and contouring techniques.\n\nhttps://opensea.io/collection/ledger-hackathon-summer-2021/'},E7uD:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "rect waves"\nthumbnail: /images/plots/146.jpg\ndescription: "A simple idea applying sine waves to rectangular shapes. Keeping some glitches in!"\n---\n\nA simple idea applying sine waves to rectangular shapes. Keeping some glitches in!'},EF3T:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Growing 8\u03c0t"\nthumbnail: /images/plots/113.jpg\ndescription: "stacking multiple parametric functions. Sakura Gelly Roll on black A4, revealing artifacts of the paper."\ntags:\n  - parametric\n---\n\nAnother parametric functions. Inspired from [plot#111](/plots/111) idea: stacking multiple parametric functions. The formula is `(0.3+0.7p)f(2\u03c0t)+0.05f(8\u03c0t)` where p is the growing factor, t is the parametric value and f is a cos for x and sin for y. Sakura Gelly Roll on black A4, revealing artifacts of the paper.\n'},EGKs:function(e,n,t){"use strict";var a=t("NdRM");e.exports=new a("tag:yaml.org,2002:js/regexp",{kind:"scalar",resolve:function(e){if(null===e)return!1;if(0===e.length)return!1;var n=e,t=/\/([gim]*)$/.exec(e),a="";if("/"===n[0]){if(t&&(a=t[1]),a.length>3)return!1;if("/"!==n[n.length-a.length-1])return!1}return!0},construct:function(e){var n=e,t=/\/([gim]*)$/.exec(e),a="";return"/"===n[0]&&(t&&(a=t[1]),n=n.slice(1,n.length-a.length-1)),new RegExp(n,a)},predicate:function(e){return"[object RegExp]"===Object.prototype.toString.call(e)},represent:function(e){var n="/"+e.source+"/";return e.global&&(n+="g"),e.multiline&&(n+="m"),e.ignoreCase&&(n+="i"),n}})},EOT6:function(e,n,t){"use strict";var a=t("3rKx");e.exports=new a({include:[t("rMOK")],implicit:[t("H+oK"),t("iFIo")],explicit:[t("mv/Q"),t("55eu"),t("jOok"),t("Xq5V")]})},Ej7k:function(e,n,t){"use strict";var a=t("NdRM");e.exports=new a("tag:yaml.org,2002:null",{kind:"scalar",resolve:function(e){if(null===e)return!0;var n=e.length;return 1===n&&"~"===e||4===n&&("null"===e||"Null"===e||"NULL"===e)},construct:function(){return null},predicate:function(e){return null===e},represent:{canonical:function(){return"~"},lowercase:function(){return"null"},uppercase:function(){return"NULL"},camelcase:function(){return"Null"}},defaultStyle:"lowercase"})},Ekcc:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "parametric oddity"\nthumbnail: "/images/plots/138.jpg"\ndescription: "transition of two parametric spirals. I called it \'parametric oddity\' because one of the parametric frequency is literally an \'odd number\' which makes it having this mesh effect. Fountain pen with \'Red Dragon\' on white bristol A4."\ntags:\n  - parametric\n---\n\ntransition of two parametric spirals. I called it \'parametric oddity\' because one of the parametric frequency is literally an \'odd number\' which makes it having this mesh effect. Fountain pen with \'Red Dragon\' on white bristol A4.\n\nbasically it\'s a transition between `(10\u03c0t,41\u03c0t)` and `(8\u03c0t,8\u03c0t)` with radius that varies all along to make it a spiral. 41 is the oddity here!\n\nThe parametric is repeated twice with a slightly different perlin noise displacement to add some moir\xe9 effect on top of this.\n\n<img src="/images/plots/138zoom1.jpg" width="100%">\n\n<img src="/images/plots/138zoom2.jpg" width="100%">\n'},F4W1:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Elevation 01"\nthumbnail: /images/plots/156.jpg\ndescription: "First experiment of Molotow pen on Bristol paper."\n---\n\nFirst experiment of Molotow pen on Bristol paper.\n\nUsing perlin noise and domain warping, we can make very interesting shapes that we can pipe into marching squares contour algorithm.\n\nIn this code, i\'ve also made 2 lines close to each other instead of a linear distribution. This is relatively simple to implement:\n\n```rust\nlet pattern = (2., 3.); // 2 lines 3 blanks\nlet thresholds: Vec<f64> = // in [0..1] range\n    (0..samples)\n    .map(|i|\n        (i as f64 + pattern.1 * (i as f64 / pattern.0).floor())\n        / (samples as f64 * (pattern.0 + pattern.1) / pattern.0).floor())\n    .collect();\n\n```\n\nHere is the formula: (that i\'m not sure is correctly normalized by the way)\n\nhttps://www.desmos.com/calculator/mlngfvssv0\n\n(yeah I also use my fountain pen to do (simple) math =D)\n\n<img src="/images/plots/156math.jpg" width="100%">\n'},FO6U:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Gold disc"\nthumbnail: /images/plots/110.jpg\ntags:\n  - polar\n  - disc\n---\n\nThis is a continuation of [plot#107](/plots/107), but this time it projects it with polar coordinate, essentially making it a disc.\n\nStill using fountain pen, main ink is "Amber" by Diamine. It has interesting properties.\n'},"G+m4":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'[FR] webglparis talk: GLSL.io initiative and WebGL Transitions\'\ndescription: "A talk I did at webglparis to present GLSL.io and GLSL Transitions initiative."\nauthor: Gaetan\nlayout: post\ntags:\n  - webgl\n  - GLSL\n---\n\n<iframe width="640" height="360" src="http://www.youtube.com/embed/Cmr2RRETCXs?feature=player_embedded" frameborder="0" allowfullscreen></iframe>\n\n'},G0yk:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Apophenia"\nthumbnail: /images/plots/160.jpg\ndescription: "the tendency to perceive meaningful connections between unrelated things"\n---\n\nApophenia \u2013 the tendency to perceive meaningful connections between unrelated things.\n'},GL4Q:function(e,n,t){"use strict";t.d(n,"a",(function(){return u}));var a=t("nKUr"),i=t("cpVT");function o(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var r=t("q1tI"),s=t("e0Q9");function l(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}const c=e=>{let{Day:n}=e,t=o(e,["Day"]);const{0:s,1:c}=Object(r.useState)(0);return Object(r.useEffect)((()=>{let e,n;return n=requestAnimationFrame((function t(a){n=requestAnimationFrame(t),e||(e=a),c((a-e)/1e3)})),()=>cancelAnimationFrame(n)}),[]),Object(a.jsx)(n.Shader,function(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?l(Object(t),!0).forEach((function(n){Object(i.a)(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}({time:s},t))};function u({Day:e,width:n,height:t}){const{0:i,1:o}=Object(r.useState)(0);return Object(a.jsxs)(a.Fragment,{children:[Object(a.jsx)(s.Surface,{width:n||400,height:t||400,children:Object(a.jsx)(c,{Day:e,n:i},e.n)}),null]})}},GOMj:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Hack-a-plot avatar hatching 3"\nthumbnail: "/images/plots/174.jpg"\ndescription: "Plots made during an internal Hackathon at Ledger using profile picture, hatching and contouring techniques."\ntags:\n  - contour\n  - hatching\n---\n\nPlots made during an internal Hackathon at Ledger using profile picture, hatching and contouring techniques.\n\nhttps://opensea.io/collection/ledger-hackathon-summer-2021/'},GQDz:function(e,n,t){"use strict";t.r(n),n.default=""},Ga6R:function(e,n,t){"use strict";function a(e){return"undefined"===typeof e||null===e}e.exports.isNothing=a,e.exports.isObject=function(e){return"object"===typeof e&&null!==e},e.exports.toArray=function(e){return Array.isArray(e)?e:a(e)?[]:[e]},e.exports.repeat=function(e,n){var t,a="";for(t=0;t<n;t+=1)a+=e;return a},e.exports.isNegativeZero=function(e){return 0===e&&Number.NEGATIVE_INFINITY===1/e},e.exports.extend=function(e,n){var t,a,i,o;if(n)for(t=0,a=(o=Object.keys(n)).length;t<a;t+=1)e[i=o[t]]=n[i];return e}},GeD1:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Colored mountains 01"\nthumbnail: /images/plots/192.jpg\ndescription: "Continuation of noise elevation. Fountain pens with various inks on watercolour paper (300g/m)."\n---\n\nContinuation of noise elevation. Fountain pens with various inks on watercolour paper (300g/m).\n\nTwo other experiments done and much more will follow because it\'s a great concept:\n\n<img src="/images/plots/192b.jpg" width="100%" />\n<img src="/images/plots/192c.jpg" width="100%" />\n'},Gu2q:function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: \"Chaotic Inner\"\ndescription: \"A chaotic experiment of parametric function meeting perlin noise. Brush pen with 'Bloody Brexit' ink on Bristol paper.\"\nthumbnail: /images/plots/149.jpg\ntags:\n  - perlin\n  - parametric\n---\n\nA chaotic experiment of parametric function meeting perlin noise. Brush pen with 'Bloody Brexit' ink on Bristol paper."},"H+oK":function(e,n,t){"use strict";var a=t("NdRM"),i=new RegExp("^([0-9][0-9][0-9][0-9])-([0-9][0-9])-([0-9][0-9])$"),o=new RegExp("^([0-9][0-9][0-9][0-9])-([0-9][0-9]?)-([0-9][0-9]?)(?:[Tt]|[ \\t]+)([0-9][0-9]?):([0-9][0-9]):([0-9][0-9])(?:\\.([0-9]*))?(?:[ \\t]*(Z|([-+])([0-9][0-9]?)(?::([0-9][0-9]))?))?$");e.exports=new a("tag:yaml.org,2002:timestamp",{kind:"scalar",resolve:function(e){return null!==e&&(null!==i.exec(e)||null!==o.exec(e))},construct:function(e){var n,t,a,r,s,l,c,u,h=0,d=null;if(null===(n=i.exec(e))&&(n=o.exec(e)),null===n)throw new Error("Date resolve error");if(t=+n[1],a=+n[2]-1,r=+n[3],!n[4])return new Date(Date.UTC(t,a,r));if(s=+n[4],l=+n[5],c=+n[6],n[7]){for(h=n[7].slice(0,3);h.length<3;)h+="0";h=+h}return n[9]&&(d=6e4*(60*+n[10]+ +(n[11]||0)),"-"===n[9]&&(d=-d)),u=new Date(Date.UTC(t,a,r,s,l,c,h)),d&&u.setTime(u.getTime()-d),u},instanceOf:Date,represent:function(e){return e.toISOString()}})},H4Wf:function(e,n,t){"use strict";t.r(n),n.default=""},HGVa:function(e,n,t){"use strict";t.r(n),n.default=""},"HpC+":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "topographic warp"\nthumbnail: /images/plots/135.jpg\ndescription: "Domain warping meets marching squares algorithms"\ntags:\n  - marching-squares\n  - warp\n---\n\nDomain warping meets marching squares algorithms. Fountain pen on A4 canson.\n\nI have many other candidates. I also tried this one:\n\n<img width="100%" src="/images/plots/135bis.jpg"/>\n'},"I3+r":function(e,n,t){"use strict";t.r(n),n.default=""},IceM:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "hexa flower noise"\nthumbnail: "/images/plots/131.jpg"\ndescription: "Yet another spiral transitioning between two parametric functions. \'Bloody Brexit\' ink from Diamine with brush pens on A4 Bristol."\ntags:\n  - parametric\n---\n\nYet another spiral transitioning between two parametric functions. \'Bloody Brexit\' ink from Diamine with brush pens on A4 Bristol.\n\n<img width="100%" src="/images/plots/131.gif" />\n'},Icra:function(e,n,t){"use strict";t.r(n),n.default=""},J3bC:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Warp Glitch 01"\nthumbnail: /images/plots/152.jpg\ndescription: "This is a fresh experimentation of noise domain warping with glitches"\ntweet: https://twitter.com/greweb/status/1399823206215831556\ntags:\n  - noise\n---\n\nThis is a fresh experimentation of noise domain warping with glitches. As many of my previous plots, this is a 2-pass spiral parametric function, displaced with perlin noise warpped into each other (see "domain warping"). The spiral ends up being unstable and "breaks apart" with intentional glitches: the line is stopped as soon as two datapoints are to far from each other, as a spiral get bigger and bigger it inevitably ending up breaking apart completely in various places which combined with the parametric function makes some sort of humano\xefd shape!\n\nI sent some video while it was getting plotted. It started from the middle and the beginning is quite interesting and could itself be made a standalone. All of these are very exploratory and may be revisited later!\n'},J8yY:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Jumping man"\nthumbnail: /images/plots/60.jpg\ndescription: "Photo of a jumping man with TSP."\n---\n\nPhoto of a jumping man. Implemented with k-means clustering, tsp and parallelization. Plotted with with a brush pen. There is a slight gradient thanks to some slope on the plotting table!\n'},"JIL/":function(e,n,t){var a={"./001/README.md":["yCvz"],"./002/README.md":["bPaa"],"./003/README.md":["LBVh"],"./004/README.md":["t+o8"],"./005/README.md":["Icra"],"./006/README.md":["Otr/"],"./007/README.md":["vFoq"],"./008/README.md":["Y5WS"],"./009/README.md":["xgUO"],"./010/README.md":["3XcB"],"./011/README.md":["xNY0"],"./012/README.md":["11Sj"],"./013/README.md":["l4gz"],"./014/README.md":["eIIq"],"./015/README.md":["COZH"],"./016/README.md":["353+"],"./017/README.md":["Xhx1"],"./018/README.md":["RHpB"],"./019/README.md":["88+z"],"./020/README.md":["GQDz"],"./021/README.md":["ig9K"],"./022/README.md":["yF2V"],"./023/README.md":["ZYYP"],"./024/README.md":["rEsJ"],"./025/README.md":["2/YE"],"./026/README.md":["HGVa"],"./027/README.md":["uWLs"],"./028/README.md":["98/W"],"./029/README.md":["QmdR"],"./030/README.md":["naOd"],"./031/README.md":["BHC3"],"./032/README.md":["AccM"],"./033/README.md":["fUMH"],"./034/README.md":["8VEi"],"./035/README.md":["bJea"],"./036/README.md":["8pr5"],"./037/README.md":["TjV/"],"./038/README.md":["XA8f"],"./039/README.md":["ABVm"],"./040/README.md":["5/hP"],"./041/README.md":["ZMnA"],"./042/README.md":["zYy3"],"./043/README.md":["L4qi"],"./044/README.md":["qn1m"],"./045/README.md":["Pkmy"],"./046/README.md":["v2OP"],"./047/README.md":["QzXX"],"./048/README.md":["bYUS"],"./049/README.md":["xi4s"],"./050/README.md":["X8lm"],"./051/README.md":["tbEk"],"./052/README.md":["1Hz/"],"./053/README.md":["K+gO"],"./054/README.md":["Da1f"],"./055/README.md":["+bvG"],"./056/README.md":["I3+r"],"./057/README.md":["PdyT"],"./058/README.md":["Qru/"],"./059/README.md":["wBBG"],"./060/README.md":["J8yY"],"./061/README.md":["9nhf"],"./062/README.md":["kG1y"],"./063/README.md":["SqyK"],"./064/README.md":["WEXz"],"./065/README.md":["0wZB"],"./066/README.md":["nrZ5"],"./067/README.md":["yJmW"],"./068/README.md":["qVQq"],"./069/README.md":["CgTJ"],"./070/README.md":["9x/r"],"./071/README.md":["uCoZ"],"./072/README.md":["noTo"],"./073/README.md":["ADEy"],"./074/README.md":["See4"],"./075/README.md":["NSLj"],"./076/README.md":["T+M9"],"./077/README.md":["ugXF"],"./078/README.md":["U+Tf"],"./079/README.md":["i+J6"],"./080/README.md":["v9De"],"./081/README.md":["eqFi"],"./082/README.md":["7GSA"],"./083/README.md":["cCet"],"./084/README.md":["1cPK"],"./085/README.md":["2SOq"],"./086/README.md":["NtWT"],"./087/README.md":["B0EA"],"./088/README.md":["wLwo"],"./089/README.md":["H4Wf"],"./090/README.md":["zWTV"],"./091/README.md":["jBCP"],"./092/README.md":["Y3sZ"],"./093/README.md":["tOsZ"],"./094/README.md":["6d7H"],"./095/README.md":["eWTH"],"./096/README.md":["nQk3"],"./097/README.md":["6ykQ"],"./098/README.md":["RXE9"],"./099/README.md":["JmH0"],"./100/README.md":["QR/K"],"./101/README.md":["lZcA"],"./102/README.md":["yQP0"],"./103/README.md":["yVRA"],"./104/README.md":["rgdI"],"./105/README.md":["0hcx"],"./106/README.md":["krhY"],"./107/README.md":["X4ni"],"./108/README.md":["zaAt"],"./109/README.md":["z6oG"],"./110/README.md":["FO6U"],"./111/README.md":["XQEI"],"./112/README.md":["f6A/"],"./113/README.md":["EF3T"],"./114/README.md":["Bir5"],"./115/README.md":["vLLl"],"./116/README.md":["Ycaf"],"./117/README.md":["/41s"],"./118/README.md":["gqgv"],"./119/README.md":["mVQU"],"./120/README.md":["gTso"],"./121/README.md":["SsVj"],"./122/README.md":["Jy1k"],"./123/README.md":["3yhu"],"./124/README.md":["jmt2"],"./125/README.md":["nNS1"],"./126/README.md":["zEwe"],"./127/README.md":["WuK3"],"./128/README.md":["5Tfx"],"./129/README.md":["QMpp"],"./130/README.md":["lQeP"],"./131/README.md":["IceM"],"./132/README.md":["Y2Co"],"./133/README.md":["kru4"],"./134/README.md":["QhJx"],"./135/README.md":["HpC+"],"./136/README.md":["duRY"],"./137/README.md":["T3W9"],"./138/README.md":["Ekcc"],"./139/README.md":["0tIW"],"./140/README.md":["sRRH"],"./141/README.md":["nSud"],"./142/README.md":["0RtR"],"./143/README.md":["JxLd"],"./144/README.md":["qC5S"],"./145/README.md":["YkbE"],"./146/README.md":["E7uD"],"./147/README.md":["kyr6"],"./148/README.md":["0dpp"],"./149/README.md":["Gu2q"],"./150/README.md":["DQgZ"],"./151/README.md":["2Xg7"],"./152/README.md":["J3bC"],"./153/README.md":["skje"],"./154/README.md":["jgXF"],"./155/README.md":["KGBF"],"./156/README.md":["F4W1"],"./157/README.md":["mRba"],"./158/README.md":["1tWJ"],"./159/README.md":["fzot"],"./160/README.md":["G0yk"],"./161/README.md":["K6d5"],"./162/README.md":["3PTt"],"./163/README.md":["ceB2"],"./164/README.md":["u0RZ"],"./165/README.md":["1hZm"],"./166/README.md":["4/z1"],"./167/README.md":["9aUE"],"./168/README.md":["qPHC"],"./169/README.md":["Q8dS"],"./170/README.md":["6oDM"],"./171/README.md":["liTY"],"./172/README.md":["/HDy"],"./173/README.md":["E3sc"],"./174/README.md":["GOMj"],"./175/README.md":["RiMv"],"./176/README.md":["cm/u"],"./177/README.md":["ppE9"],"./178/README.md":["g+0Z"],"./179/README.md":["mFDB"],"./180/README.md":["9i9n"],"./181/README.md":["DKqw"],"./182/README.md":["Xwm2"],"./183/README.md":["f1D6"],"./184/README.md":["licy"],"./185/README.md":["ikex"],"./186/README.md":["214X"],"./187/README.md":["Nwz3"],"./188/README.md":["RuLc"],"./189/README.md":["sSon"],"./190/README.md":["rn5Z"],"./191/README.md":["C+rD"],"./192/README.md":["GeD1"],"./193/README.md":["hkxR"],"./194/README.md":["YZnb"],"./195/README.md":["6ubZ"],"./196/README.md":["pV1G"],"./template/README.md":["AQsK",26],"./unreleased_106_fibers/README.md":["tuBF",27],"./unreleased_113_parametric_flower_11/README.md":["cDE2",28],"./unreleased_113_parametric_flower_12/README.md":["Ax0m",29],"./unreleased_113_parametric_flower_8/README.md":["mJEg",30],"./unreleased_133_pattern_cross_over_pink_blue/README.md":["RyHL",31],"./unreleased_153/README.md":["tmiX",32],"./unreleased_153_04/README.md":["+tor",33],"./unreleased_163_01/README.md":["KwB/",34],"./unreleased_190_2/README.md":["gJ2u",35],"./unreleased_190_3/README.md":["Icin",36],"./unreleased_190_7/README.md":["GZd6",37],"./unreleased_190_8/README.md":["kDAR",38],"./unreleased_brush_lines/README.md":["yFrm",39],"./wip_105-04/README.md":["B8Mv",40]};function i(e){if(!t.o(a,e))return Promise.resolve().then((function(){var n=new Error("Cannot find module '"+e+"'");throw n.code="MODULE_NOT_FOUND",n}));var n=a[e],i=n[0];return Promise.all(n.slice(1).map(t.e)).then((function(){return t(i)}))}i.keys=function(){return Object.keys(a)},i.id="JIL/",e.exports=i},JmH0:function(e,n,t){"use strict";t.r(n),n.default="---\ntweet: https://twitter.com/greweb/status/1380454403589689351\ntags:\n  - collection\n  - perlin\n  - parametric\n---\n"},JxLd:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Rainbow Roots"\nthumbnail: /images/plots/143.gif\ndescription: "8 frames plotted making an animated loop. A 1920p video and A4 physical art is available as an NFT."\ntags:\n  - field\n  - perlin\n  - plotloop\nobjkts:\n  - 98062\n---\n\nHere is "Rainbow Roots", my 4th [**plot loop** (see article)](https://greweb.me/2021/05/plot-loops). **The main digital art is a 1920p video loop of 8 frames available as a [Tezos hicetnunc NFT](https://www.hicetnunc.xyz/objkt/98062)**. The physical art are the 8 frames, plotted with 2 fountain pens on Bristol A4 paper (250g), and offered when [buying the NFT](https://www.hicetnunc.xyz/objkt/98062).\n\nThere are 8 plots available for sale and there will be no other editions of these plot loop frames. You can chose which frame you buy as the NFT editions are segmented into different prices. 20.1 tez for the first frame, 20.2 for the second and so on up to 20.8.\n\n<img src="/images/plots/143-plots.jpg" width="100%">\n\nThis is a reboot of [plot#091](/plots/091) with more lines and better noise technique using domain warping.\n\n### Coloring\n\nEach plotted frame is made with 2 fountain pens, one primary and one secondary ink. The primary color is interleaved with the second with a ratio of 2/3 for primary and 1/3 for secondary.\n\nI used 8 different inks, all by "Diamine" brand: Turquoise, Aurora Borealis, Bloody Brexit, Imperial Purple, Writer\'s Blood, Red Dragon, Pumpkin, Sepia.\n\n<img src="/images/plots/143-inks.jpg" width="100%">\n\nI had a last minute changes after the photo was taken: I replaced Spring Green by another color because it would have been too "light" for a plot. I actually tried to do one with Sepia and it was also too "light", I decided to go black! I definitely have betterplans for \'Spring Green\'.\n\n### Paper\n\nI use a Canson Bristol 250g paper which works great with fountain pen. Format A4.\n\n<img src="/images/plots/143-zoom1.jpg" width="50%"><img src="/images/plots/143-zoom2.jpg" width="50%">\n\n## Creation process\n\nThe creation process is made of many steps, which are entirely created by me and all these steps are fully published and open sourced.\n\n- art generator: I write a Rustlang program that generate SVG files. (see _main.rs_)\n- GIF preview: I use a script to make a digital and theorical video of the animation. Very important for me to have an idea of the animation (even tho only plotting time will have the final surprise).\n- plot first prototypes: I do some prototype plots to make sure the plot is good, specifically that the density chosen (number of lines) is well adjusted (too much and your paper starts to be comprised, not enough and you have too much gaps).\n- I polish a lot the generator. Specifically on the different noise harmonies, frequencies and amplitudes.\n- Once it\'s ready, i\'ll run a super script that loops over the "video preview" generation. It\'s time consuming as I will often stop and polish again the generator. This time it took me probably ten times to iterate like this. Literally the whole day.\n- When I\'m confident, I\'ll generate a lot of video previews. **This time I have generated 500 GIFs.** It was very tricky to decide and to actually elect the final plot, I developed my own tool (see section below)\n- Finally, I can plot them all, it takes a lot of caution on manipulating paper and fountain pens and a lot of manual actions. It is very time consuming but very rewarding. **Each frame took more than an hour to plot with an AxiDraw robot.**\n\n### Preview\n\nThis is what the theorical art was going to be, this is a digital preview before doing the plot so indeed it only simulate what the actual ink was going to do. The physical art is better looking with the imperfections of the medium.\n\n<img src="/images/plots/143-theorical.gif" width="100%">\n\n### Process to find the final plot\n\nAs I\'m working with a generator, it can generate infinite variants of plot loops. I have generated 500 GIFs (virtual plot loops)\n\nIt ended up being very tedious to try to find a good animation by manually going through the files so I literally developped an app to solve my problem and provide a voting system so I can compare in parallel different results and chose among them. It could be reused and improved in future, it\'s not yet "generic" but if there is a need for it, I would make it generic and open source it as a standalone tool.\n\n<img src="/images/plots/143-elector.jpg" width="100%">\n\n### Early prototype and Special Editions\n\nThis prototype was done to adjust some plotting parameters, specifically the number of lines.\n\n<img src="/images/plots/143-prototype.jpg" width="100%">\n\nI\'ve also made these 2 special editions one to offer a friend and one gift to buyer of one of my previous plot loop. Each of them have very specific variations of parameters (they are written on the back of the plot and i don\'t keep them in memory, basically they are technically not easy to reproduce identically!)\n\n<img src="/images/plots/143-special1.jpg" width="100%">\n<img src="/images/plots/143-special2.jpg" width="100%">\n'},Jy1k:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Growing parametric splitted"\nthumbnail: /images/plots/122.jpg\ndescription: "stacking multiple parametric functions with 3 stops. playing with moir\xe9 effects. STA pigment liner on A4 bristol."\ntags:\n  - parametric\n---\n\nstacking multiple parametric functions with 3 stops. playing with moir\xe9 effects. STA pigment liner on A4 bristol.\n\n```rust\nlet size = 90.;\nlet f1 = (8., 8.);\nlet f2 = (5., 40.);\nlet amp1 = 1.0;\nlet amp2 = 0.05;\nlet samples = 100000;\nlet spins = 200.0;\nlet splits = 4.0;\n\nlet parametric = |p: f64| {\n  let p1 = (splits * p).floor();\n  let p2 = splits * p - p1;\n  let t = (p1 + 0.8 * p2) / splits;\n  let scale = 1.0 - t;\n  let mut p = (\n    scale\n    * amp1\n    * ((spins * 2. * PI * t).cos()\n      + amp2\n      * mix(\n        (spins * f1.0 * PI * t).cos(),\n        (spins * f2.0 * PI * t).cos(),\n        t,\n      )),\n    scale\n    * amp1\n    * ((spins * 2. * PI * t).sin()\n      + amp2\n      * mix(\n        (spins * f1.1 * PI * t).sin(),\n        (spins * f2.1 * PI * t).sin(),\n        t,\n      )),\n  );\n  let noise_angle = 2.\n    * PI\n    * perlin.get([\n      0.02 * p.0,\n      0.02 * p.1,\n      100.0 + opts.seed,\n    ]);\n  let noise_amp = 0.1\n    * perlin.get([\n      0.01 * p.0,\n      0.01 * p.1,\n      opts.seed,\n    ]);\n  p.0 += noise_amp * noise_angle.cos();\n  p.1 += noise_amp * noise_angle.sin();\n  p\n};\n```\n'},"K+gO":function(e,n,t){"use strict";t.r(n),n.default=""},K6d5:function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: \"Elevation 02\"\nthumbnail: /images/plots/161.jpg\ndescription: \"Perlin noise and domain warping. Fountain pen 'Aurora Borealis' ink from Diamine on Bristol card.\"\n---\n\nPerlin noise and domain warping. Fountain pen 'Aurora Borealis' ink from Diamine on Bristol card.\n"},KFpJ:function(e,n,t){"use strict";var a=t("NdRM");e.exports=new a("tag:yaml.org,2002:map",{kind:"mapping",construct:function(e){return null!==e?e:{}}})},KGBF:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Corridor planet"\nthumbnail: /images/plots/155.jpg\ndescription: "Using distance functions primitives with marching squares and noise displacement to produce another planet hole."\ntags:\n  - planethole\n---\n\nUsing distance functions primitives with marching squares and noise displacement to produce another planet hole.\n'},KHjv:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Beez, WebRTC + Audio API\'\ndescription: \'Here is Beez, a web real-time audio experiment using smartphones as synthesizer effect controllers. This is our second Web Audio API experiment made in one Hackday at Zenexity.\'\nthumbnail: /images/2013/09/beez.png\nauthor: Gaetan\nlayout: post\ntags:\n - WebRTC\n - audio\n - hackday\n---\n\n[webaudioapi]: https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html\n[zenexity]: http://zenexity.com\n[github]: http://github.com/gre/beez\n[app]: http://beez.greweb.fr/\n[webrtc]: http://www.webrtc.org/\n[webrtcapi]: http://www.w3.org/TR/webrtc/\n[websocketapi]: http://www.w3.org/TR/websockets/\n[fm_article]: /2013/08/FM-audio-api\n[playframework]: http://playframework.com/\n\n<img src="/images/2013/09/beez.png" alt="" class="thumbnail-left" />\n\nHere is **Beez**, a web real-time audio experiment \nusing smartphones as synthesizer effect controllers.\n\nThis is our second [Web Audio API][webaudioapi] experiment made in one Hackday at [Zenexity][zenexity] (now Zengularity).\n\nThis time, we were much more focused on having the best **latency performance**:\nwe used the bleeding-edge [WebRTC][webrtcapi] technology,\nwhich allows you to link clients in Peer-to-Peer instead of a classical Client-Server architecture.\n\n* [The project on Github][github]\n* [Test it now!][app] (Chrome)\n\n\n### Live demo of the Hackday application\n\n<iframe width="640" height="480" src="//www.youtube.com/embed/QwU6IMNLF0o" frameborder="0" allowfullscreen></iframe>\n\n*Bonus for the one who recognizes the melody :-)*\n\n\x3c!--more--\x3e\n\n## The Experiment\n\nThe experiment consists in controlling an audio stream running on a desktop web page with \nsome audio effect pads running on phones via a mobile web interface.\n**Our main goal was to make the best real-time experience.**\n\n### Hive and Bees\n\nAn **Hive** is controlled by different **Bees**, eventhing connected in Peer-to-Peer (via WebRTC).\n\n#### The Hive\n\nThe **Hive** is a web page where the sound is generated and visualized *(Web Audio API)*.\nIt also shows you in real-time the different effects XY pads and allows you to control them.\n\n![](/images/2013/09/hive.png)\n\n#### A Bee\n\nThe **Bee** is a mobile web page which allows you to control the different sound effects with XY pads.\nIt only works on Android Chrome now *(WebRTC required)*.\n\n![](/images/2013/09/bee.png)\n\n### Audio tech\n\nWe used [Web Audio API][webaudioapi] for generating the sound client-side on the Hive:\n\nWe have a note sequencer which plays a ***famous melody*** through a [Frequency Modulator][fm_article] and different other effects.\nSome controls allow you to change the **BPM**, **gain** of the carrier and the modulator, **finetune**, \nfrequency **multiplicator** (0.25, 0.5, 1, 1.5, 2) of the carrier and the modulator,\n**reverbation**, **filter** (frequency and resonance).\nThere is also a delay effect made on both left and right channels to produce a cool stereo effect.\n\nThat\'s quite basic audio stuff so far, I can\'t wait to experiment deeper and try to generate more complex sounds with that awesome Audio API.\nAgain, our main goal was to make a P2P connection between the hive and its bees.\n\n### Network architecture\n\n<img src="/images/2013/09/beez_arch.png" alt="" class="thumbnail-left" />\n**Every bee are connected to the hive with a bi-directionnal Peer-to-Peer connection thanks to [WebRTC][webrtc].**\n\nEverytime a (bee) user moves an effect controller with his phone, a position event is sent to the hive.\n\nBasically:\n\n```javascript\nxyAxis.on("change:x change:y", function () {\n  hive.send(["tabxy", this.get("tab"), this.get("x"), this.get("y")]);\n});\n```\n\n*As you can see, we used Backbone.js models for events.*\n\nHowever, A lot of Touch events per second can be triggered by an Android device, and it may depends on the device speed. We shouldn\'t send to the network all of these events because it can saturate it and cause some lags. To avoid that we need to **throttle the touch events before sending the event to the network**.\n\nThis is done transparently with the [`_.throttle`](http://underscorejs.org/#throttle) function and we choose to **throttle by 50 milliseconds** which is **about 20 events per second** which is ok for human eye.\n\n```javascript\nxyAxis.on("change:x change:y", _.throttle(function () {\n  hive.send(["tabxy", this.get("tab"), this.get("x"), this.get("y")]);\n}, 50));\n```\n\nWe use different other events:\n\n- A bee can send `"tabxychanging"` and `"tabopen"` respectively to informs the cursor has been pressed/released and to inform a new tab has been opened.\n- When a Hive receive a `"tabopen"`, it will send back to the bee a `"tabxy"` event in order to inform what is the current value of that tab so we can init the cursor to the current xy axis position on the bee interface.\n\n## WebSockets vs WebRTC\n\n<img src="/images/2013/09/websocket.png" class="thumbnail-left" />\n\nMost "real-time" web experiments you see on the Internet today use [WebSockets][websocketapi].\nWebSockets are good, it\'s a significant evolution from the Ajax years.\n\nWebSocket is a protocol on top of TCP, which **links a browser with a server in a bidirectional text communication**.\nGetting 2 clients to communicate generally consists in broadcasting messages from the server to all clients \n(see the schema).\n\n**This architecture has some advantages:**\n\n* Simple to understand, Easy to use.\n* We can easily implement some server validation.\n\n**But also has some drawbacks:**\n\n* Not always easy to traverse **proxies**. *(e.g. through an nginx front server)*\n* Only text communication.\n* **bandwith** intensive. *(all the bandwidth goes back and forth with your server)*\n* **CPU** intensive. *(e.g. receiving 20 messages per second from 10 clients can be a lot for a small server, especially if you are doing some message processing)*\n\n(The last two "cons" are scalability issues)\n\n<hr style="clear:both" />\n\n<img src="https://upload.wikimedia.org/wikipedia/commons/a/ac/Logo-webrtc.png" class="thumbnail-left" />\n\n[WebRTC][webrtc] (*Web Real Time Communication*), \nis a new web technology which helps to connect browsers in a **Peer to Peer** way.\n\nWebRTC has been designed for transfering binary data like files, audio, video (e.g. a webcam stream).\nOf-course, we can still use it for text.\n\n<br style="clear:both" />\n\n<img src="/images/2013/09/webrtc.png" class="thumbnail-right" />\n\nUnlike WebSockets, multiple steps are required to **establish a P2P connection between two web clients**.\nIt is due to the fact that the two clients must resolve the closest network path to communicate with each other.\nThat resolving phase requires a communication between the clients, and for that we can use WebSockets as a *"Control Channel"*.\n\nBut once the two web clients are connected, they basically don\'t need the web server anymore and can **communicate directly together**.\nIf the two clients are in the same local network, they should directly communicate through that local network.\nThat **reduces the server load** and should significantly **decrease the latency**.\n\n### Playframework / Akka Actors\n\n[Playframework][playframework] has been used on the server side for making that WebSocket Control Channel,\nand akka was convenient for handling peer communication and rooms management.\n\n## About the melody\n\nYou still didn\'t guess where does the melody came from?\n\nWell, here is the answer:\n\n<iframe width="640" height="480" src="//www.youtube.com/embed/3rU_ei_x0Ag" frameborder="0" allowfullscreen></iframe>\n\n## Awesome team!\n\nFinally I want to thanks my team-mates: [@mrspeaker](http://twitter.com/mrspeaker), [@etaty](http://twitter.com/etaty), [@NicuPrinFum](http://twitter.com/NicuPrinFum), [@drfars](http://twitter.com/drfars), [@srenaultcontact](http://twitter.com/srenaultcontact)\nwith who we were able to make that demo from scratch in one day!\n'},KKCg:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'48 hours to prototype an Ant Sim Game\'\ndescription: \'I gamejam-ed last weekend to the Ludum Dare 29 theming "Beneath the Surface" to develop "Anthill", a minimalist anthill simulation game.\'\nthumbnail: /images/2014/05/anthill.png\nauthor: Gaetan\nlayout: post\ntags:\n - gamedev\n - ludumdare\n - javascript\n - phaser\n---\n\n[ludumdare]: http://ludumdare.com/compo/\n[play]: http://greweb.me/ld29/\n[source]: //github.com/gre/ld29/\n[entry]: http://www.ludumdare.com/compo/ludum-dare-29/?action=preview&uid=18803\n[sunvox]: http://www.warmplace.ru/soft/sunvox/\n[wrong]: /2014/05/ld29/#wrong\n[right]: /2014/05/ld29/#right\n\n<img class="thumbnail-left" src="/images/2014/05/computer_preset.jpg" alt="">\n\nI **gamejam-ed** last weekend to the [Ludum Dare][ludumdare] \ntheming *"Beneath the Surface"* (29th edition).\n\nI enjoyed that time a lot.\nWhat changed from the previous Ludum Dare for me is that \n**I\'m now** \u2014and happy to be\u2014 **a father**,\nand I\'m enough trained to wake up at 3am so I could be there attending the beginning!\n\nThis article is my diary of this incredible 48 hours past to\ndevelop **"Anthill", a minimalist anthill simulation game**.\nThis postmortem will explain what [went right][right] and what [went wrong][wrong]\nfor this compo.\n\n\nThe Game\n===\n\nI haven\'t played any Ant Simulation Game \nbut I recently played a lot ["Banished"](http://www.shiningrocksoftware.com/),\nan awesome city-building strategy game,\nand I was inspired by the "assign jobs to people" gameplay of this game.\n\n- **[Play the Game][play]**\n- [Ludum Dare entry][entry]\n- [Source code][source]\n\n<iframe width="640" height="360" src="http://www.youtube.com/embed/DBt-5Qmzu1k?feature=player_embedded" frameborder="0" allowfullscreen></iframe>\n\nTimelapse\n===\n\nDeveloping a complete game in 48 hours (including sleeping) is tough,\nespecially that it is also about making the graphics and the music!\n\nThe game resulting of these 2 days is more a **prototype** than a finished game:\nthe simulation remains minimalist and fastly boring,\nthe food is the only resource you have to care about.\n\n\nHere is a **300x accelerated screencast of the developement of "Anthill"**:\n<iframe width="640" height="360" src="http://www.youtube.com/embed/VhH7of4gAHk?feature=player_embedded" frameborder="0" allowfullscreen></iframe>\n\n\x3c!--more--\x3e\n\n<a name=right></a> What went right\n---\n\n### Music\n\nBest achievement of my LD entry was \u2013to me\u2013 **making the music**.\n\n<img class="thumbnail-left" src="/images/2014/05/music_preset.jpg" alt="">\n\nI\'m not a musician, neither a pianist, but I played a lot with [Audio](/tags/audio/) the past year and I\'ve managed to make a music for this game \u2014and had a lot of fun making it.\nI\'ve used my *Yamaha P105* as a MIDI controller for making the game music and connecting it \nto [SunVox][sunvox], a modular tracker software.\n\n#### Play the music - feedback appreciated\n\n<iframe width="100%" height="450" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/playlists/32426683&amp;auto_play=false&amp;hide_related=false&amp;visual=true"></iframe>\n\n<img class="thumbnail-right" src="/images/2014/05/playing_midi.png" alt="">\n\nMost of the notes you heard have been **recorded live from my hand**, and I was quite proud of that, because I\'m quite a noob on a piano.\nDoing that way, you keep some imperfection in the music (little delay on the notes, especially in the intro music) and I think that sometimes makes the music better.\n\nI\'ve talked a few times about SunVox, also [I still want to make my own web version](/2013/07/zound-live/) \nof a **modular audio tracker** that anyone (first myself!) could use \nand also could embed live in the game (and, for instance, having game variable impacting the audio experience).\n\n### Graphics\n\nAlso, I\'m more a developer than a graphist so I would say this was a success^^\n\n<blockquote class="twitter-tweet" lang="fr"><p>My best <a href="https://twitter.com/search?q=%23gamedev&amp;src=hash">#gamedev</a> graphics ever! <a href="http://t.co/FksRoq1r9x">pic.twitter.com/FksRoq1r9x</a></p>&mdash; Ga\xebtan Renaudeau (@greweb) <a href="https://twitter.com/greweb/statuses/460558902812086272">27 Avril 2014</a></blockquote>\n<script async src="//platform.twitter.com/widgets.js" charset="utf-8"><\/script>\n\n### Using a library\n\nI\'ve entirely **focused on making my game** rather than making the technical stack.\nUsually, I tend to develop my own framework with the game.\nIt is good to learn and discover some [cool ways of programming a game](/2014/01/promisify-your-games/)\nbut this time I really wanted to get things done...\n\n### Phaser.io\n\n...so I\'ve used **[Phaser](http://www.phaser.io/)** which is a trendy and awesome framework.\nIt is also built on top of the **Pixi.js** rendering library (I used in [LD27](http://www.ludumdare.com/compo/ludum-dare-27/?action=preview&uid=18803)) and **p2.js** physics engine,\nwhich are two brillant and performant JavaScript libraries.\n\nHopefully I started my project with a "Phaser template" I bootstraped during the previous warmup weekend.\nI\'ve still lost some time playing with the Phaser API but I could have relied on Phaser features and performance so I think it worth it the second day.\n\n### Google Hangout with Ludum Dare friends\n\nI used Google Hangout during the whole Ludum Dare, as a way to put my webcam in the timelapse, \nbut more importantly to have other Ludum Dare friends coming in it!\n\nThis was a cool first experiment as an alternative to the "stream my dev" approach.\nIt was quite fun and social to have [@mrspeaker](http://twitter.com/mrspeaker)\nshowing me his crazy Metal Meter game advancement.\n\n![](/images/2014/05/hangout.png)\n\n<a name=wrong></a> What went wrong\n---\n\n### Achievability \n**My [initial plan](https://github.com/gre/ld29/blob/master/TODO.md) was too ambitious.**\nIt seems to always happen with me: I get the first day a lot of ideas and motivation, and I tend to underestimate the work to be done. Then at the end of the first day, I\'m frustrated to find out I won\'t have enough time to do all my plans.\nIndeed it is good to have a lot of ideas but, next Ludum Dare, I\'ll try to be sure to have achievable goals.\n\n> Next time, let\'s **remove half the features** I establish!\n\nSo, the second day morning, I\'ve been replanning from scratch and reprioritize my features to basically have something finished and working as a game.\nBecause of this decision, the result you can see is a game, but far from the one I originally wanted. \n**This version is only about digging, collecting mushrooms and avoiding stravation**.\n\nAlso I originally scheduled to work that way **Day 1: developing-only, Day 2: music and graphics + new features**. I\'m not sure this approach can really works, especially it doesn\'t scale, we better work by adding complete features one after the other. That theorically works, but it is however difficult to apply in practice with the stress of the Ludum Dare countdown!\n\n### Path finding performance\n\n**Implementing my own path finding algorithm was fast but not optimal** at all because of performances!\nI recently released a bugfixed version which just use an existing [path finding library](http://qiao.github.io/PathFinding.js/visual/) to fix my bad implementation \nand also to avoid an ant to request path finding each frame when looking for a task to be affected on.\n\n### Finding the good simulation parameters\n\nI underestimated a bit the amount of work needed to find the good parameters of the simulation.\nThose are very important to **make the game well-balanced** (e.g. not impossible but also not super-easy), I don\'t think I found the optimal parameter in the released version.\n\nI think I need two important things to make this parameter search easier:\n\n- a framework to maintain parameters presets and change them live.\n- make the simulation running at any speed to ease the development. (faster simulation)\n\n### [bug] A task is not always completed by the closest ant\n\nThere is a inconvenient **proximity bug** in my game that you may have noticed:\nwhen a new job is created, it may happen that, even if a ant was here nearby, a very far ant is assigned to this job.\n\nI\'m using a `foreach ant in noJobAnts { findAntTask(ant,availableTasks) }` loop.\nIn this first approach, even if a ant will take the closest task in `findAntTask`, the first assigned ant will occupy the task even if a closer ant was after in the noJobAnts list.\n\nAnother approach to solve this issue would be to do `foreach task in availableTasks { findTaskAnts(task,noJobAnts) }`.\nIn this second approach, the `findTaskAnts` should sort the noJobAnts list for the given task proximity.\n\nHowever it is not that trivial because tasks also have different priorities for a given ant, and `findAntTask` solved that.\nIn my original plan, there is some basic tasks like "clean the dirt" or "clean the corpse" which can be done by any ant. However, a specialized ant (let\'s say an Harvester) may have some more important tasks to be done first, so this is why we need this priority.\n\nIn other word, fixing this bug is not trivial and I need to find the optimal loop for that!\n\nTo be continued...\n---\n\nI really wish to continue this game because I enjoyed making it and I would enjoy playing the one I have in mind! \nTime will tell if I can accomplish that wish!\n\n![](/images/2014/05/anthill.png)\n\nYou can make games!\n---\n\nI strongly think anyone a bit motivated and inspired can participate [Ludum Dare][ludumdare].\n\nWhoever you are, you can make games!\n\n- If you are a developer, you can develop games easily! But that\'s not enough, you will require graphics and music!\n- If you are a graphist, you can make crazy beautiful games! There is tools to help you making the game without coding.\n- If you are a game designer or story teller, you can make awesome games too! You could also just make a cool text adventure game?\n\n<iframe width="640" height="480" src="//www.youtube.com/embed/PVbCECjxFds" frameborder="0" allowfullscreen></iframe>\n'},L4qi:function(e,n,t){"use strict";t.r(n),n.default=""},LBVh:function(e,n,t){"use strict";t.r(n),n.default=""},Lgts:function(e,n,t){"use strict";var a=t("NdRM");e.exports=new a("tag:yaml.org,2002:bool",{kind:"scalar",resolve:function(e){if(null===e)return!1;var n=e.length;return 4===n&&("true"===e||"True"===e||"TRUE"===e)||5===n&&("false"===e||"False"===e||"FALSE"===e)},construct:function(e){return"true"===e||"True"===e||"TRUE"===e},predicate:function(e){return"[object Boolean]"===Object.prototype.toString.call(e)},represent:{lowercase:function(e){return e?"true":"false"},uppercase:function(e){return e?"TRUE":"FALSE"},camelcase:function(e){return e?"True":"False"}},defaultStyle:"lowercase"})},Myxv:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Making performant React applications\'\ndescription: \'I would like to express here my opinion and feedback on using React and performance optimization you can do.\'\nthumbnail: \'/images/2015/07/diaporama_3.jpg\'\nauthor: Gaetan\nlayout: post\ntags:\n - react\n - vdom\n---\n\n*^ Sorry guys, you may have notice the blog post date is wrong. I won\'t change the URL, but thanks to how time works, this will be fixed in one month anyway :-D*\n\n[ReactEurope](https://twitter.com/chantastic/status/616608931037646850) conference\nwas to me incredibly [inspiring](https://twitter.com/chantastic/status/616670658911715328) and [promising](https://twitter.com/chantastic/status/616995607043903488).\nYersterday got tons of news and tweets from JavaScript community.\n\nOne tweet and blog post by the great [@aerotwist](https://twitter.com/aerotwist) got my attention.\n\n<blockquote class="twitter-tweet" data-cards="hidden" lang="fr"><p lang="en" dir="ltr">I often hear claims that \u201cthe DOM is slow!\u201d and \u201cReact is fast!\u201d, so I decided to put that to the test:&#10;&#10;<a href="https://t.co/M1RZZiyVT2">https://t.co/M1RZZiyVT2</a>&#10;&#10;\ud83d\udc22vs\ud83d\udc07</p>&mdash; Paul Lewis (@aerotwist) <a href="https://twitter.com/aerotwist/status/616934953679458304">3 Juillet 2015</a></blockquote>\n\nI would like to express here my opinion and feedback on using React.\n\nI\'ve been using React for almost 2 years now, and always in performance intensive use-cases, from Games to WebGL.\n\n<a href="http://diaporama.glsl.io/" target="_blank">\n<img src="/images/2015/07/diaporama_3.jpg" alt="" class="thumbnail-left" />\n</a>\n\nI\'ve created [glsl.io](http://glsl.io/) and I\'m working on [Diaporama Maker](https://github.com/gre/diaporama-maker).\nBoth applications are built with React and combined use of HTML, SVG, WebGL.\n\nDiaporama Maker is probably the most ambitious piece of software I\'ve ever personally done.\n\n<br style="clear: left" />\n\n> In short, [Diaporama Maker](https://github.com/gre/diaporama-maker) it is a WYSIWYG editor for web slideshow (mainly photo slideshows). It is a bit like iMovie with the web as first target. [The project is entirely open-sourced.](https://github.com/gre/diaporama-maker)\n\nCurrently, I am able to render the whole application at 60 FPS and this is still unexpected and surprising to me\n(press Space to run the diaporama on [diaporama.glsl.io demo](http://diaporama.glsl.io/)).\nWell, more exactly, this would not have been possible without some optimizations\nthat I\'m going to detail a bit at the end of this article.\n\n\x3c!--more--\x3e\n\n## The point is productivity\n\nI don\'t think Virtual DOM claims to be faster than doing Vanilla DOM, and that\'s not really the point. **The point is productivity.**\nYou can write very well optimized code in Vanilla DOM but this might require **a lot of expertise**\nand a lot of time even for an experienced team *(time that should be spent focusing on making your product)*.\n\nWhen it comes to adding new features and refactoring old ones, this goes worse.\nWithout a well constrained framework or paradigm, things does not scale far, are time consuming and introduce bugs,...\nEspecially in a team where multiple developers have to work with each other.\n\n> **See Also:** [Why does React scale?](https://www.youtube.com/watch?v=D-ioDiacTm8) by [@vjeux](https://twitter.com/Vjeux).\n\n## What matters to me\n\nThere is a lot of advantages of using Virtual DOM approach before talking about React performances.\n\nOf course, this always depends on what you are building, but I would claim that\n**there is a long way to go using React before experiencing performance issues**,\nand in the worse cases: **you can almost always find easy solutions to optimize these performance issues**.\n\n### DX\n\nReact has an incredible Developer eXperience (that people seem to call DX nowadays!) that can [help you improving UX](https://twitter.com/greweb/status/617258379183005696) and the ability to [measure Performances](https://facebook.github.io/react/docs/perf.html) and [optimize them](https://facebook.github.io/react/docs/component-specs.html#updating-shouldcomponentupdate) when you reach bottlenecks.\n\nYou can easily figure out which component is a bottleneck in the Component tree as shown in following screenshot.\n\n> ![](/images/2015/07/diaporama-perfs.png)\nWith printWasted() you can see how much time React has wasted to `render()` something that didn\'t change and how much instances has been created. (there is also printInclusive and printExclusive)\n\nThis is a bit equivalent of the Web Console Profiler except it emphasis on your application components which is a very relevant approach.\n\n### React data flow\n\n> I can\'t imagine re-writing Diaporama Maker in Vanilla DOM.\n\nIn Diaporama Maker, I have a lot of cross dependencies between components,\nfor instance the current `time` is shared and used everywhere in the application.\nAs a matter of fact, dependencies grow when adding more and more features.\n\n> ![](/images/2015/07/diaporama_configure_kenburns.gif)\nusages of time in 3 independent components.\n\n**The descriptive Virtual DOM approach very simply solves this problem**.\nYou just have to pass props in to share data between components:\nthere is one source of trust that climb down your component tree via "props".\n\n![](/images/2015/07/diaporama-maker-time-props.jpg)\n\nWith Virtual DOM approach, the cost to add one new dependency to a shared data is small and **does not become more complex as the application grows**.\n\n> ![](/images/2015/07/diaporama_slide_content.gif)\nanother more complex showcase of shared states.\n\nUsing an Event System like you would do in standard Backbone approach tends to lead to imperative style and spaghetti codes (and when using global events, components are not really reusable).\n\nMoreover, I think that `Views<->Models` Event System approach, if not carefully used, tends to converge to an unmaintainable and laggy applications.\n\n### React is a Component library\n\nReact truly offers **component as first-class citizen**.\nThis means it allows component reusability. I\'ve tried alternative like virtual-dom and I don\'t think it emphasizes enough on this benefit.\n\nThere are [important good practices](https://twitter.com/chantastic/status/616997918155759616) when using React like minimizing states and props and I\'m not going to expand more on this subject. Most of these best practices are not exclusive to React but come from common sense and software architecture in general.\nOne of the important point for performance is to **choose a good granularity of your component tree**.\nIt is generally a good idea to split up a component into pieces as small as possible\nbecause it allows to separate concerns, minimize props and consequently optimize rendering diff.\n\n#### Diaporama Maker architecture\n\nYou would be surprised to know that Diaporama Maker does not even use **Flux** (that might be reconsidered soon for collaborative features). I\'ve just taken the old "callback as props" approach all the way down the component tree. That easily makes all components purely modular and re-usable (no dependencies on some Stores).\nI\'ve also taken the [inline style approach]() without actually using any framework (this is just about props-passing `style` objects).\n\nAs a consequence, I\'ve been able to externalize a lot of tiny components that are part of my application\nso I can share them across apps and also in order to people to re-use them.\n\nWhat is important about externalizing components is also the ability to test and optimize them independently (the whole idea of modularity).\n\nHere are all the standalone UI components used by Diaporama Maker:\n\n- [bezier-easing-editor](https://github.com/gre/bezier-easing-editor)\n- [bezier-easing-picker](https://github.com/gre/bezier-easing-picker)\n- [diaporama-react](https://github.com/glslio/diaporama-react)\n- [glsl-transition-vignette](https://github.com/glslio/glsl-transition-vignette)\n- [glsl-transition-vignette-grid](https://github.com/glslio/glsl-transition-vignette-grid)\n- [glsl-uniforms-editor](https://github.com/gre/glsl-uniforms-editor)\n- [kenburns-editor](https://github.com/gre/kenburns-editor)\n\n(each one have standalone demos)\n\n\n## Optimizing performances\n\n<blockquote class="twitter-tweet" lang="fr"><p lang="en" dir="ltr">I&#39;ve been working on crazy projects using React (like <a href="http://t.co/U2oETh5lhZ">http://t.co/U2oETh5lhZ</a> ). most performance issues i&#39;ve met was not because of React</p>&mdash; Ga\xebtan Renaudeau (@greweb) <a href="https://twitter.com/greweb/status/617210444839809024">4 Juillet 2015</a></blockquote>\n<script async src="//platform.twitter.com/widgets.js" charset="utf-8"><\/script>\n\nHere are 2 examples of optimizations I had to do in Diaporama Maker that are not because of React:\n\n- It is easy to write not very optimized WebGL, so I work a lot to optimize the pipeline of [Diaporama engine](https://github.com/gre/diaporama)\n- CSS transforms defined on Library images was for a time very intensive for the browser to render so I am now using server-resized "thumbnails" instead of the full-size images. Asking the browser to recompute the `transform: scale(...)` of 50 high resolution images can be super costy. (without this optimization, the resize of the application was running at like 2-3 FPS because the library thumbnails need to recompute their scale and crop).\n\nBut what if you still have performance issue due by React? Yes this can happens.\n\n### Timeline Grid example\n\nIn Diaporama Maker, I have a Component that generates a lot of elements (like 1300 elements for a 2 minutes slideshow) and my first naive implementation was very slow. This component is [TimelineGrid](https://github.com/gre/diaporama-maker/blob/b0c6447b127785bea3c2487b0c77037418298b8c/client/ui/TimelineGrid/index.js) which renders the timescale in the timeline. It is implemented with SVG and a lot of `<text>` and `<line>`.\n\nThe performance issue was noticeable when drag and dropping items across the application. React was forced to render() and compare the whole timescale grid every time. But the timescale does not change! it just have 3 props:\n\n```xml\n<TimelineGrid timeScale={timeScale} width={gridWidth} height={gridHeight} />\n```\n\n**So it was very easy to optimize it just by using the `PureRenderMixin` to say to react that all my props are immutable.**\n(I could have implemented `shouldComponentUpdate` too).\n\nAfter this step, and for this precise example, I don\'t think a Vanilla DOM implementation can reach better performance:\n\n- when one of the grid parameter change, **EVERYTHING** need to be recomputed because all scales are changing.\n- React is doing even smarter thing that I would not manually do? Like reusing elements instead of destroying/creating them.\n\nThere might still be ways to go more far in optimizing this example. For instance I could chunk my grid into pieces\nand only render the pieces that are visible, like in an infinite scroll system *(I could use something like [sliding-window](https://github.com/gre/sliding-window) for this)*.\nThat would probably be premature optimization for this example.\n\n## Wrap Up\n\nTo my mind, generic benchmarks always tends to be biased and does not represent use-cases reality unless you are really covering your application itself.\n\nThe TimelineGrid component optimization explained in this article is a very specific and well chosen example,\nbut it is one counter-example for such a benchmark.\n\nEach application has its own needs and constraints and we can\'t really generalize one way to go.\nAlso Performance should not be the main concern to choose a technology.\n\n\nIt is easy to make Virtual DOM library benchmarks,\ncomparing the performance of rendering and Array diffing,\nbut does that covers 80% of use-cases?\nIs performance really the point?\nWhat tradeoff do you accept to make between Performance and Productivity?\n\nTell me what you think.\n\nIn the meantime, I think we can all continue getting applications done\nand [developing amazing DX](https://github.com/gaearon/react-hot-loader).\n'},NGCR:function(e,n,t){"use strict";var a=t("3rKx");e.exports=new a({include:[t("gWvi")],implicit:[t("Ej7k"),t("Lgts"),t("gCGJ"),t("eW+f")]})},NSLj:function(e,n,t){"use strict";t.r(n),n.default=""},NdRM:function(e,n,t){"use strict";var a=t("XCGq"),i=["kind","resolve","construct","instanceOf","predicate","represent","defaultStyle","styleAliases"],o=["scalar","sequence","mapping"];e.exports=function(e,n){if(n=n||{},Object.keys(n).forEach((function(n){if(-1===i.indexOf(n))throw new a('Unknown option "'+n+'" is met in definition of "'+e+'" YAML type.')})),this.tag=e,this.kind=n.kind||null,this.resolve=n.resolve||function(){return!0},this.construct=n.construct||function(e){return e},this.instanceOf=n.instanceOf||null,this.predicate=n.predicate||null,this.represent=n.represent||null,this.defaultStyle=n.defaultStyle||null,this.styleAliases=function(e){var n={};return null!==e&&Object.keys(e).forEach((function(t){e[t].forEach((function(e){n[String(e)]=t}))})),n}(n.styleAliases||null),-1===o.indexOf(this.kind))throw new a('Unknown kind "'+this.kind+'" is specified for "'+e+'" YAML type.')}},NtWT:function(e,n,t){"use strict";t.r(n),n.default=""},NvIL:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Slides: Web Audio API, Overview\'\ndescription: "A presentation overview of the Web Audio API"\nauthor: Gaetan\nlayout: post\ntags:\n - audio\n---\n\n<a href="http://greweb.me/webaudioapi-introduction">\n<img src="/images/2013/09/webaudioapiprez.png" alt="" class="thumbnail-left" />\n</a>\n\n<a href="http://greweb.me/webaudioapi-introduction">Open the presentation</a>\n/\n<a href="http://greweb.me/webaudioapi-introduction?azerty=1">AZERTY version</a>\n'},Nwz3:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "circles inside circles inside circles in a circle"\nthumbnail: /images/plots/187.jpg\ndescription: "3-level recursion of packing circles"\ntags:\n  - shape-packing\n---\n\n3-level recursion of packing circles'},Ogqt:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "SASS : l\'\xe9volution du CSS pour Play, Rails ou autres"\nauthor: Gaetan\nlayout: post\npermalink: /2010/03/sass-levolution-du-css/\ntags:\n  - css\n  - sass\n---\n\n[1]: http://sass-lang.com/\n[2]: http://www.playframework.org/\n[3]: http://compass-style.org/\n[4]: http://sass-lang.com/docs/yardoc/file.SASS_REFERENCE.html\n\n**SASS, Syntactically Awesome Stylesheets**, est un langage de feuille de style \xe9volu\xe9 qui permet de factoriser beaucoup de code css et de rendre son \xe9criture et sa maintenance **rapide et moins contraignante**. Il est compil\xe9 en css.\n\n\x3c!--more--\x3e\n\n## Pourquoi utiliser SASS ?\n\nSon utilisation a de nombreux avantages par rapport au CSS :\n\n- sa **simplicit\xe9** (pas de crochets, pas de point virgule mais juste de l\u2019indentation)\n- l\u2019**imbrication** des s\xe9lecteurs css (appliquant l\u2019id\xe9e DRY : don\u2019t repeat yourself)\n- l\u2019utilisation de **variables**\n- l\u2019utilisation d\u2019**op\xe9rations \xe9l\xe9mentaires** (sur les pixels, les couleurs, \u2026)\n- la **factorisation** du code (au lieu de faire des copier-coller, on peux factoriser le code \xe0 travers les \u201cmixins\u201d).\n- La **r\xe9duction** css et la **clart\xe9** du code\n- La **compression du code** compil\xe9 avec la possibilit\xe9 de tout mettre dans un fichier (via l\u2019h\xe9ritage) et de minimifier le code css.\n\nCe langage n\u2019est pas difficile \xe0 apprendre, cela ressemble au css, avec de nombreuses fonctionnalit\xe9s int\xe9ressantes en plus.\n\n## La syntaxe du langage\n\nLa syntaxe du sass est **compatible avec celle du css \xe0 quelques exceptions pr\xe8s** :\n\n- Ne plus mettre de point virgule **;**\n- Ne plus mettre de crochets **{ }**\n- Respecter les conventions traditionnelles (**attribut: valeur** un espace apr\xe8s le deux points mais pas avant)\n- Respecter l\u2019indentation : Il faut choisir une indentation et s\u2019y tenir dans un m\xeame fichier. Au choix : une tabulation, 2 espaces, 4 espaces, \u2026 Les lignes _propri\xe9t\xe9s: valeurs_ d\u2019un s\xe9lecteur css doivent d\xe9passer d\u2019une indentation ce s\xe9lecteur.\n\nEn respectant ces points, vous pouvez d\xe9j\xe0 **coder en SASS comme en CSS**.\n\nMais cela ne serait pas int\xe9ressant sans les nouveaut\xe9s suivantes :\n\n### La factorisation des s\xe9lecteurs en plusieurs niveaux\n\nAu lieu d\u2019avoir ce type d\u2019arborescence \xe0 un niveau :\n\n```sass\n.main .head\n\xa0 color: red\n.main .body\n\xa0 color: blue\n```\n\nNous pouvons factoriser le s\xe9lecteur \u201c_.main_\u201d et se ramener \xe0 deux niveaux :\n\n```sass\n.main\n\xa0 .head\n\xa0 \xa0 color: red\n\xa0 .body\n\xa0 \xa0 color: blue\n```\n\nCe proc\xe9d\xe9 de factorisation bas\xe9 sur l\u2019esprit **DRY** (Don\u2019t Repeat Yourself) est aussi applicable sur les attributs eux-m\xeames :\n\n```sass\na\n\xa0 font:\n\xa0 \xa0 family: serif\n\xa0 \xa0 weight: bold\n\xa0 \xa0 size: 1.2em\n```\n\nsera compil\xe9 en css par :\n\n```css\na {\n\xa0 font-family: serif;\n\xa0 font-weight: bold;\n\xa0 font-size: 1.2em;\n}\n```\n\n### Les variables\n\nLa possibilit\xe9 d\u2019utiliser des variables est un gros apport au css. Elle permet **une meilleure maintenance du code et une meilleure scalabilit\xe9 d\u2019une application** (en utilisant par exemple des fichiers sass de th\xe8mes d\xe9finissant toutes les couleurs, images, polices, \u2026).  \nIl existe plusieurs **types de variables** (nombre r\xe9el, pixels, couleurs, chaines de caract\xe8res \u2026) et il est possible d\u2019utiliser des **op\xe9rations \xe9l\xe9mentaires**.\n\nLorsqu\u2019on \xe9crit une ligne **attribut / value** avec l\u2019utilisation de variables (dynamique),  \non utilise le caract\xe8re \u2018**=**\u2018 au lieu de \u2018**:**\u2018 pour l\u2019affectation.\n\n#### Les couleurs\n\n```sass\n!link_color = red\na\n\xa0 color = !link_color\n\xa0 &:hover\n\xa0 \xa0 color = !link_color #222\n```\n\nA noter que le symbole **&** remplace le s\xe9lecteur parent.\n\nCe qui donne le code compil\xe9 suivant :\n\n```css\na {\n\xa0 color: red;\n}\na:hover {\n\xa0 color: #ff2222;\n}\n```\n\n#### Les pixels\n\n```sass\n!margin = 16px\n.border\n\xa0 padding = !margin / 2\n\xa0 margin = !margin / 2\n```\n\ndonne le code compil\xe9 :\n\n```css\n.border {\n\xa0 padding: 8px;\n\xa0 margin: 8px;\n}\n```\n\n### Les \u201cmixins\u201d\n\nLes mixins sont des proc\xe9dures qui contiennent plusieurs lignes de sass.  \nIl est possible d\u2019utiliser des arguments sur ces mixins.\n\n```sass\n=border-radius(!radius = 5px)\n\xa0 border-radius= !radius\n\xa0 -moz-border-radius= !radius\n\xa0 -webkit-border-radius= !radius\n```\n\n```sass\n#wrapper\n\xa0  border-radius(10px)\n\xa0 > footer\n\xa0 \xa0  border-radius()\n```\n\nCet exemple est typiquement int\xe9ressant car il permet d\u2019utiliser **border-radius** de fa\xe7on **cross-browser** et avec une ligne de code.\n\nA noter qu\u2019il est possible d\u2019affecter des valeurs par d\xe9faut aux mixins.\n\nLe r\xe9sultat css compil\xe9 est le suivant :\n\n```css\n#wrapper {\n\xa0 border-radius: 10px;\n\xa0 -moz-border-radius: 10px;\n\xa0 -webkit-border-radius: 10px;\n}\n#wrapper > footer {\n\xa0 border-radius: 5px;\n\xa0 -moz-border-radius: 5px;\n\xa0 -webkit-border-radius: 5px;\n}\n```\n\n### Exemple complet\n\nVoici un exemple complet de l\u2019utilisation du SASS\n\n```sass\n/* This is just an example */\n\n/* variables */\n!main_width = 900px\n!aside_width = 300px\n!section_width = 520px\n\n!link_color = red\n\n!font_title = "Liberation","Georgia","serif"\n\n/* mixins */\n=border-radius(!radius = 5px)\n\xa0 border-radius= !radius\n\xa0 -moz-border-radius= !radius\n\xa0 -webkit-border-radius= !radius\n\n=block()\n\xa0 display: block\n\xa0 overflow: auto\n\n/* colors */\na\n\xa0 color = !link_color\n\xa0 &:hover\n\xa0 \xa0 color = !link_color #222\n\n\n/* layout */\n\n#wrapper\n\xa0 margin:  auto\n\xa0 position: relative\n\xa0 width = !main_width\n\xa0  border-radius(10px)\n\xa0 >nav\n\xa0 \xa0  block()\n\xa0 \xa0 padding: 2px\n\xa0 \xa0 \xa0 top: 5px\n\xa0 \xa0 font-size: 1.2em\n\xa0 \xa0 font-family = !font_title\n\xa0 \xa0 a\n\xa0 \xa0 \xa0 font-weight: bold\n\xa0 \xa0 \xa0 &:hover\n\xa0 \xa0 \xa0 \xa0 color: white\n\n\xa0 >header\n\xa0 \xa0  block()\n\xa0 \xa0 clear: both\n\xa0 \xa0 height: 48px\n\xa0 \xa0 font-family = !font_title\n\n\xa0 >footer\n\xa0 \xa0  block()\n\xa0 \xa0 padding: 5px\n\xa0 \xa0 text-align: center\n\xa0 \xa0 clear: both\n\n\xa0 #main\n\xa0 \xa0 position: relative\n\xa0 \xa0 >section\n\xa0 \xa0 \xa0  block()\n\xa0 \xa0 \xa0 width = !section_width\n\xa0 \xa0 \xa0 padding: 20px\n\n\xa0 \xa0 >aside\n\xa0 \xa0 \xa0  block()\n\xa0 \xa0 \xa0 float: right\n\xa0 \xa0 \xa0 width = !aside_width\n\xa0 \xa0 \xa0 padding: 20px\n```\n\net le r\xe9sultat du fichier CSS compil\xe9\n\n```css\n/* This is just an example */\n/* variables */\n/* mixins */\n/* colors */\na {\n\xa0 color: red;\n}\n\xa0 a:hover {\n\xa0 \xa0 color: #ff2222;\n}\n\n/* layout */\n#wrapper {\n\xa0 margin:  auto;\n\xa0 position: relative;\n\xa0 width: 900px;\n\xa0 border-radius: 10px;\n\xa0 -moz-border-radius: 10px;\n\xa0 -webkit-border-radius: 10px;\n}\n\xa0 #wrapper >nav {\n\xa0 \xa0 display: block;\n\xa0 \xa0 overflow: auto;\n\xa0 \xa0 padding: 2px;\n\xa0 \xa0 padding-top: 5px;\n\xa0 \xa0 font-size: 1.2em;\n\xa0 \xa0 font-family: Liberation, Georgia, serif;\n}\n\xa0 \xa0 #wrapper >nav a {\n\xa0 \xa0 \xa0 font-weight: bold;\n}\n\xa0 \xa0 \xa0 #wrapper >nav a:hover {\n\xa0 \xa0 \xa0 \xa0 color: white;\n}\n\xa0 #wrapper >header {\n\xa0 \xa0 display: block;\n\xa0 \xa0 overflow: auto;\n\xa0 \xa0 clear: both;\n\xa0 \xa0 height: 48px;\n\xa0 \xa0 font-family: Liberation, Georgia, serif;\n}\n\xa0 #wrapper >footer {\n\xa0 \xa0 display: block;\n\xa0 \xa0 overflow: auto;\n\xa0 \xa0 padding: 5px;\n\xa0 \xa0 text-align: center;\n\xa0 \xa0 clear: both;\n}\n\xa0 #wrapper #main {\n\xa0 \xa0 position: relative;\n}\n\xa0 \xa0 #wrapper #main >section {\n\xa0 \xa0 \xa0 display: block;\n\xa0 \xa0 \xa0 overflow: auto;\n\xa0 \xa0 \xa0 width: 520px;\n\xa0 \xa0 \xa0 padding: 20px;\n}\n\xa0 \xa0 #wrapper #main >aside {\n\xa0 \xa0 \xa0 display: block;\n\xa0 \xa0 \xa0 overflow: auto;\n\xa0 \xa0 \xa0 float: right;\n\xa0 \xa0 \xa0 width: 300px;\n\xa0 \xa0 \xa0 padding: 20px;\n}\n```\n\nLe SASS offre **encore plus de possibilit\xe9s**, notamment l\u2019interpolation, les conditions, les boucles, \u2026  \nVous trouverez plus d\u2019informations sur la _documentation SASS_.\n\n## Utilisation\n\n### Pr\xe9-requis\n\n**Note**: Ce qui suit ne s\u2019applique pas pour le plugin sass du framework Play! .\n\nPour utiliser SASS, sous linux, installez les packets **ruby** et **rubygems** puis installez **haml** avec la commande :\n\n```bash\ngem install haml\n```\n\n### Avec le framework java Play!\n\nGr\xe2ce au module sass de play framework, le SASS est **compil\xe9 \xe0 la vol\xe9e** au moment du chargement d\u2019une page (en mode d\xe9veloppement) ou au chargement de l\u2019application (en mode production).\n\n#### Installation\n\nDepuis play 1.1, il suffit de lancer la commande\n\n```bash\nplay install sass\n```\n\nEnsuite il faut activer le module dans la configuration de l\u2019application (fichier _conf/application.conf_).\n\n### Avec le framework Ruby on Rails\n\n#### Installation\n\nPour activer le plugin SASS sur une application Rails, lancez :\n\n```bash\nhaml --rails path/to/rails/app\n```\n\n### Autrement\n\nVous pouvez toujours utiliser SASS en compilant vos fichier sass en css \xe0 chaque modification (voir _Commandes pratiques_).  \nVous inclurez ensuite le fichier css compil\xe9 dans votre html.\n\n## Convertir ses anciens CSS en SASS\n\nSi vous ne voulez pas repartir de z\xe9ro dans le design d\u2019un projet, vous pouvez tout \xe0 fait repartir avec les anciens CSS en les exportant en SASS.\n\n## Commandes pratiques\n\n- Pour convertir vos fichier CSS en SASS il vous suffit d\u2019utiliser : `css2sass`\n\n- Pour compiler vos fichier SASS en CSS, utilisez: `sass`\n\n## Liens\n\n- [Site du langage SASS][1]\n- [Site du framework Play!][2]\n\n### Aller plus loin\n\n- [Compass : framework SASS][3]\n- [Documentation SASS][4]\n'},"Otr/":function(e,n,t){"use strict";t.r(n),n.default=""},PMAo:function(e,n,t){"use strict";var a=t("Ga6R"),i=t("XCGq"),o=t("uOdg"),r=t("EOT6"),s=t("YJCK"),l=Object.prototype.hasOwnProperty,c=/[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x84\x86-\x9F\uFFFE\uFFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])|(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF]/,u=/[\x85\u2028\u2029]/,h=/[,\[\]\{\}]/,d=/^(?:!|!!|![a-z\-]+!)$/i,p=/^(?:!|[^,\[\]\{\}])(?:%[0-9a-f]{2}|[0-9a-z\-#;\/\?:@&=\+\$,_\.!~\*'\(\)\[\]])*$/i;function m(e){return Object.prototype.toString.call(e)}function g(e){return 10===e||13===e}function f(e){return 9===e||32===e}function w(e){return 9===e||32===e||10===e||13===e}function b(e){return 44===e||91===e||93===e||123===e||125===e}function y(e){var n;return 48<=e&&e<=57?e-48:97<=(n=32|e)&&n<=102?n-97+10:-1}function v(e){return 48===e?"\0":97===e?"\x07":98===e?"\b":116===e||9===e?"\t":110===e?"\n":118===e?"\v":102===e?"\f":114===e?"\r":101===e?"\x1b":32===e?" ":34===e?'"':47===e?"/":92===e?"\\":78===e?"\x85":95===e?"\xa0":76===e?"\u2028":80===e?"\u2029":""}function k(e){return e<=65535?String.fromCharCode(e):String.fromCharCode(55296+(e-65536>>10),56320+(e-65536&1023))}for(var x=new Array(256),A=new Array(256),D=0;D<256;D++)x[D]=v(D)?1:0,A[D]=v(D);function E(e,n){this.input=e,this.filename=n.filename||null,this.schema=n.schema||s,this.onWarning=n.onWarning||null,this.legacy=n.legacy||!1,this.json=n.json||!1,this.listener=n.listener||null,this.implicitTypes=this.schema.compiledImplicit,this.typeMap=this.schema.compiledTypeMap,this.length=e.length,this.position=0,this.line=0,this.lineStart=0,this.lineIndent=0,this.documents=[]}function I(e,n){return new i(n,new o(e.filename,e.input,e.position,e.line,e.position-e.lineStart))}function S(e,n){throw I(e,n)}function j(e,n){e.onWarning&&e.onWarning.call(null,I(e,n))}var T={YAML:function(e,n,t){var a,i,o;null!==e.version&&S(e,"duplication of %YAML directive"),1!==t.length&&S(e,"YAML directive accepts exactly one argument"),null===(a=/^([0-9]+)\.([0-9]+)$/.exec(t[0]))&&S(e,"ill-formed argument of the YAML directive"),i=parseInt(a[1],10),o=parseInt(a[2],10),1!==i&&S(e,"unacceptable YAML version of the document"),e.version=t[0],e.checkLineBreaks=o<2,1!==o&&2!==o&&j(e,"unsupported YAML version of the document")},TAG:function(e,n,t){var a,i;2!==t.length&&S(e,"TAG directive accepts exactly two arguments"),a=t[0],i=t[1],d.test(a)||S(e,"ill-formed tag handle (first argument) of the TAG directive"),l.call(e.tagMap,a)&&S(e,'there is a previously declared suffix for "'+a+'" tag handle'),p.test(i)||S(e,"ill-formed tag prefix (second argument) of the TAG directive"),e.tagMap[a]=i}};function C(e,n,t,a){var i,o,r,s;if(n<t){if(s=e.input.slice(n,t),a)for(i=0,o=s.length;i<o;i+=1)9===(r=s.charCodeAt(i))||32<=r&&r<=1114111||S(e,"expected valid JSON character");else c.test(s)&&S(e,"the stream contains non-printable characters");e.result+=s}}function F(e,n,t,i){var o,r,s,c;for(a.isObject(t)||S(e,"cannot merge mappings; the provided source object is unacceptable"),s=0,c=(o=Object.keys(t)).length;s<c;s+=1)r=o[s],l.call(n,r)||(n[r]=t[r],i[r]=!0)}function M(e,n,t,a,i,o,r,s){var c,u;if(Array.isArray(i))for(c=0,u=(i=Array.prototype.slice.call(i)).length;c<u;c+=1)Array.isArray(i[c])&&S(e,"nested arrays are not supported inside keys"),"object"===typeof i&&"[object Object]"===m(i[c])&&(i[c]="[object Object]");if("object"===typeof i&&"[object Object]"===m(i)&&(i="[object Object]"),i=String(i),null===n&&(n={}),"tag:yaml.org,2002:merge"===a)if(Array.isArray(o))for(c=0,u=o.length;c<u;c+=1)F(e,n,o[c],t);else F(e,n,o,t);else e.json||l.call(t,i)||!l.call(n,i)||(e.line=r||e.line,e.position=s||e.position,S(e,"duplicated mapping key")),n[i]=o,delete t[i];return n}function R(e){var n;10===(n=e.input.charCodeAt(e.position))?e.position++:13===n?(e.position++,10===e.input.charCodeAt(e.position)&&e.position++):S(e,"a line break is expected"),e.line+=1,e.lineStart=e.position}function _(e,n,t){for(var a=0,i=e.input.charCodeAt(e.position);0!==i;){for(;f(i);)i=e.input.charCodeAt(++e.position);if(n&&35===i)do{i=e.input.charCodeAt(++e.position)}while(10!==i&&13!==i&&0!==i);if(!g(i))break;for(R(e),i=e.input.charCodeAt(e.position),a++,e.lineIndent=0;32===i;)e.lineIndent++,i=e.input.charCodeAt(++e.position)}return-1!==t&&0!==a&&e.lineIndent<t&&j(e,"deficient indentation"),a}function P(e){var n,t=e.position;return!(45!==(n=e.input.charCodeAt(t))&&46!==n||n!==e.input.charCodeAt(t+1)||n!==e.input.charCodeAt(t+2)||(t+=3,0!==(n=e.input.charCodeAt(t))&&!w(n)))}function L(e,n){1===n?e.result+=" ":n>1&&(e.result+=a.repeat("\n",n-1))}function B(e,n){var t,a,i=e.tag,o=e.anchor,r=[],s=!1;for(null!==e.anchor&&(e.anchorMap[e.anchor]=r),a=e.input.charCodeAt(e.position);0!==a&&45===a&&w(e.input.charCodeAt(e.position+1));)if(s=!0,e.position++,_(e,!0,-1)&&e.lineIndent<=n)r.push(null),a=e.input.charCodeAt(e.position);else if(t=e.line,G(e,n,3,!1,!0),r.push(e.result),_(e,!0,-1),a=e.input.charCodeAt(e.position),(e.line===t||e.lineIndent>n)&&0!==a)S(e,"bad indentation of a sequence entry");else if(e.lineIndent<n)break;return!!s&&(e.tag=i,e.anchor=o,e.kind="sequence",e.result=r,!0)}function z(e){var n,t,a,i,o=!1,r=!1;if(33!==(i=e.input.charCodeAt(e.position)))return!1;if(null!==e.tag&&S(e,"duplication of a tag property"),60===(i=e.input.charCodeAt(++e.position))?(o=!0,i=e.input.charCodeAt(++e.position)):33===i?(r=!0,t="!!",i=e.input.charCodeAt(++e.position)):t="!",n=e.position,o){do{i=e.input.charCodeAt(++e.position)}while(0!==i&&62!==i);e.position<e.length?(a=e.input.slice(n,e.position),i=e.input.charCodeAt(++e.position)):S(e,"unexpected end of the stream within a verbatim tag")}else{for(;0!==i&&!w(i);)33===i&&(r?S(e,"tag suffix cannot contain exclamation marks"):(t=e.input.slice(n-1,e.position+1),d.test(t)||S(e,"named tag handle cannot contain such characters"),r=!0,n=e.position+1)),i=e.input.charCodeAt(++e.position);a=e.input.slice(n,e.position),h.test(a)&&S(e,"tag suffix cannot contain flow indicator characters")}return a&&!p.test(a)&&S(e,"tag name cannot contain such characters: "+a),o?e.tag=a:l.call(e.tagMap,t)?e.tag=e.tagMap[t]+a:"!"===t?e.tag="!"+a:"!!"===t?e.tag="tag:yaml.org,2002:"+a:S(e,'undeclared tag handle "'+t+'"'),!0}function O(e){var n,t;if(38!==(t=e.input.charCodeAt(e.position)))return!1;for(null!==e.anchor&&S(e,"duplication of an anchor property"),t=e.input.charCodeAt(++e.position),n=e.position;0!==t&&!w(t)&&!b(t);)t=e.input.charCodeAt(++e.position);return e.position===n&&S(e,"name of an anchor node must contain at least one character"),e.anchor=e.input.slice(n,e.position),!0}function G(e,n,t,i,o){var r,s,c,u,h,d,p,m,v=1,D=!1,E=!1;if(null!==e.listener&&e.listener("open",e),e.tag=null,e.anchor=null,e.kind=null,e.result=null,r=s=c=4===t||3===t,i&&_(e,!0,-1)&&(D=!0,e.lineIndent>n?v=1:e.lineIndent===n?v=0:e.lineIndent<n&&(v=-1)),1===v)for(;z(e)||O(e);)_(e,!0,-1)?(D=!0,c=r,e.lineIndent>n?v=1:e.lineIndent===n?v=0:e.lineIndent<n&&(v=-1)):c=!1;if(c&&(c=D||o),1!==v&&4!==t||(p=1===t||2===t?n:n+1,m=e.position-e.lineStart,1===v?c&&(B(e,m)||function(e,n,t){var a,i,o,r,s,l=e.tag,c=e.anchor,u={},h={},d=null,p=null,m=null,g=!1,b=!1;for(null!==e.anchor&&(e.anchorMap[e.anchor]=u),s=e.input.charCodeAt(e.position);0!==s;){if(a=e.input.charCodeAt(e.position+1),o=e.line,r=e.position,63!==s&&58!==s||!w(a)){if(!G(e,t,2,!1,!0))break;if(e.line===o){for(s=e.input.charCodeAt(e.position);f(s);)s=e.input.charCodeAt(++e.position);if(58===s)w(s=e.input.charCodeAt(++e.position))||S(e,"a whitespace character is expected after the key-value separator within a block mapping"),g&&(M(e,u,h,d,p,null),d=p=m=null),b=!0,g=!1,i=!1,d=e.tag,p=e.result;else{if(!b)return e.tag=l,e.anchor=c,!0;S(e,"can not read an implicit mapping pair; a colon is missed")}}else{if(!b)return e.tag=l,e.anchor=c,!0;S(e,"can not read a block mapping entry; a multiline key may not be an implicit key")}}else 63===s?(g&&(M(e,u,h,d,p,null),d=p=m=null),b=!0,g=!0,i=!0):g?(g=!1,i=!0):S(e,"incomplete explicit mapping pair; a key node is missed; or followed by a non-tabulated empty line"),e.position+=1,s=a;if((e.line===o||e.lineIndent>n)&&(G(e,n,4,!0,i)&&(g?p=e.result:m=e.result),g||(M(e,u,h,d,p,m,o,r),d=p=m=null),_(e,!0,-1),s=e.input.charCodeAt(e.position)),e.lineIndent>n&&0!==s)S(e,"bad indentation of a mapping entry");else if(e.lineIndent<n)break}return g&&M(e,u,h,d,p,null),b&&(e.tag=l,e.anchor=c,e.kind="mapping",e.result=u),b}(e,m,p))||function(e,n){var t,a,i,o,r,s,l,c,u,h,d=!0,p=e.tag,m=e.anchor,g={};if(91===(h=e.input.charCodeAt(e.position)))i=93,s=!1,a=[];else{if(123!==h)return!1;i=125,s=!0,a={}}for(null!==e.anchor&&(e.anchorMap[e.anchor]=a),h=e.input.charCodeAt(++e.position);0!==h;){if(_(e,!0,n),(h=e.input.charCodeAt(e.position))===i)return e.position++,e.tag=p,e.anchor=m,e.kind=s?"mapping":"sequence",e.result=a,!0;d||S(e,"missed comma between flow collection entries"),u=null,o=r=!1,63===h&&w(e.input.charCodeAt(e.position+1))&&(o=r=!0,e.position++,_(e,!0,n)),t=e.line,G(e,n,1,!1,!0),c=e.tag,l=e.result,_(e,!0,n),h=e.input.charCodeAt(e.position),!r&&e.line!==t||58!==h||(o=!0,h=e.input.charCodeAt(++e.position),_(e,!0,n),G(e,n,1,!1,!0),u=e.result),s?M(e,a,g,c,l,u):o?a.push(M(e,null,g,c,l,u)):a.push(l),_(e,!0,n),44===(h=e.input.charCodeAt(e.position))?(d=!0,h=e.input.charCodeAt(++e.position)):d=!1}S(e,"unexpected end of the stream within a flow collection")}(e,p)?E=!0:(s&&function(e,n){var t,i,o,r,s,l=1,c=!1,u=!1,h=n,d=0,p=!1;if(124===(r=e.input.charCodeAt(e.position)))i=!1;else{if(62!==r)return!1;i=!0}for(e.kind="scalar",e.result="";0!==r;)if(43===(r=e.input.charCodeAt(++e.position))||45===r)1===l?l=43===r?3:2:S(e,"repeat of a chomping mode identifier");else{if(!((o=48<=(s=r)&&s<=57?s-48:-1)>=0))break;0===o?S(e,"bad explicit indentation width of a block scalar; it cannot be less than one"):u?S(e,"repeat of an indentation width identifier"):(h=n+o-1,u=!0)}if(f(r)){do{r=e.input.charCodeAt(++e.position)}while(f(r));if(35===r)do{r=e.input.charCodeAt(++e.position)}while(!g(r)&&0!==r)}for(;0!==r;){for(R(e),e.lineIndent=0,r=e.input.charCodeAt(e.position);(!u||e.lineIndent<h)&&32===r;)e.lineIndent++,r=e.input.charCodeAt(++e.position);if(!u&&e.lineIndent>h&&(h=e.lineIndent),g(r))d++;else{if(e.lineIndent<h){3===l?e.result+=a.repeat("\n",c?1+d:d):1===l&&c&&(e.result+="\n");break}for(i?f(r)?(p=!0,e.result+=a.repeat("\n",c?1+d:d)):p?(p=!1,e.result+=a.repeat("\n",d+1)):0===d?c&&(e.result+=" "):e.result+=a.repeat("\n",d):e.result+=a.repeat("\n",c?1+d:d),c=!0,u=!0,d=0,t=e.position;!g(r)&&0!==r;)r=e.input.charCodeAt(++e.position);C(e,t,e.position,!1)}}return!0}(e,p)||function(e,n){var t,a,i;if(39!==(t=e.input.charCodeAt(e.position)))return!1;for(e.kind="scalar",e.result="",e.position++,a=i=e.position;0!==(t=e.input.charCodeAt(e.position));)if(39===t){if(C(e,a,e.position,!0),39!==(t=e.input.charCodeAt(++e.position)))return!0;a=e.position,e.position++,i=e.position}else g(t)?(C(e,a,i,!0),L(e,_(e,!1,n)),a=i=e.position):e.position===e.lineStart&&P(e)?S(e,"unexpected end of the document within a single quoted scalar"):(e.position++,i=e.position);S(e,"unexpected end of the stream within a single quoted scalar")}(e,p)||function(e,n){var t,a,i,o,r,s,l;if(34!==(s=e.input.charCodeAt(e.position)))return!1;for(e.kind="scalar",e.result="",e.position++,t=a=e.position;0!==(s=e.input.charCodeAt(e.position));){if(34===s)return C(e,t,e.position,!0),e.position++,!0;if(92===s){if(C(e,t,e.position,!0),g(s=e.input.charCodeAt(++e.position)))_(e,!1,n);else if(s<256&&x[s])e.result+=A[s],e.position++;else if((r=120===(l=s)?2:117===l?4:85===l?8:0)>0){for(i=r,o=0;i>0;i--)(r=y(s=e.input.charCodeAt(++e.position)))>=0?o=(o<<4)+r:S(e,"expected hexadecimal character");e.result+=k(o),e.position++}else S(e,"unknown escape sequence");t=a=e.position}else g(s)?(C(e,t,a,!0),L(e,_(e,!1,n)),t=a=e.position):e.position===e.lineStart&&P(e)?S(e,"unexpected end of the document within a double quoted scalar"):(e.position++,a=e.position)}S(e,"unexpected end of the stream within a double quoted scalar")}(e,p)?E=!0:!function(e){var n,t,a;if(42!==(a=e.input.charCodeAt(e.position)))return!1;for(a=e.input.charCodeAt(++e.position),n=e.position;0!==a&&!w(a)&&!b(a);)a=e.input.charCodeAt(++e.position);return e.position===n&&S(e,"name of an alias node must contain at least one character"),t=e.input.slice(n,e.position),l.call(e.anchorMap,t)||S(e,'unidentified alias "'+t+'"'),e.result=e.anchorMap[t],_(e,!0,-1),!0}(e)?function(e,n,t){var a,i,o,r,s,l,c,u,h=e.kind,d=e.result;if(w(u=e.input.charCodeAt(e.position))||b(u)||35===u||38===u||42===u||33===u||124===u||62===u||39===u||34===u||37===u||64===u||96===u)return!1;if((63===u||45===u)&&(w(a=e.input.charCodeAt(e.position+1))||t&&b(a)))return!1;for(e.kind="scalar",e.result="",i=o=e.position,r=!1;0!==u;){if(58===u){if(w(a=e.input.charCodeAt(e.position+1))||t&&b(a))break}else if(35===u){if(w(e.input.charCodeAt(e.position-1)))break}else{if(e.position===e.lineStart&&P(e)||t&&b(u))break;if(g(u)){if(s=e.line,l=e.lineStart,c=e.lineIndent,_(e,!1,-1),e.lineIndent>=n){r=!0,u=e.input.charCodeAt(e.position);continue}e.position=o,e.line=s,e.lineStart=l,e.lineIndent=c;break}}r&&(C(e,i,o,!1),L(e,e.line-s),i=o=e.position,r=!1),f(u)||(o=e.position+1),u=e.input.charCodeAt(++e.position)}return C(e,i,o,!1),!!e.result||(e.kind=h,e.result=d,!1)}(e,p,1===t)&&(E=!0,null===e.tag&&(e.tag="?")):(E=!0,null===e.tag&&null===e.anchor||S(e,"alias node should not have any properties")),null!==e.anchor&&(e.anchorMap[e.anchor]=e.result)):0===v&&(E=c&&B(e,m))),null!==e.tag&&"!"!==e.tag)if("?"===e.tag){for(null!==e.result&&"scalar"!==e.kind&&S(e,'unacceptable node kind for !<?> tag; it should be "scalar", not "'+e.kind+'"'),u=0,h=e.implicitTypes.length;u<h;u+=1)if((d=e.implicitTypes[u]).resolve(e.result)){e.result=d.construct(e.result),e.tag=d.tag,null!==e.anchor&&(e.anchorMap[e.anchor]=e.result);break}}else l.call(e.typeMap[e.kind||"fallback"],e.tag)?(d=e.typeMap[e.kind||"fallback"][e.tag],null!==e.result&&d.kind!==e.kind&&S(e,"unacceptable node kind for !<"+e.tag+'> tag; it should be "'+d.kind+'", not "'+e.kind+'"'),d.resolve(e.result)?(e.result=d.construct(e.result),null!==e.anchor&&(e.anchorMap[e.anchor]=e.result)):S(e,"cannot resolve a node with !<"+e.tag+"> explicit tag")):S(e,"unknown tag !<"+e.tag+">");return null!==e.listener&&e.listener("close",e),null!==e.tag||null!==e.anchor||E}function q(e){var n,t,a,i,o=e.position,r=!1;for(e.version=null,e.checkLineBreaks=e.legacy,e.tagMap={},e.anchorMap={};0!==(i=e.input.charCodeAt(e.position))&&(_(e,!0,-1),i=e.input.charCodeAt(e.position),!(e.lineIndent>0||37!==i));){for(r=!0,i=e.input.charCodeAt(++e.position),n=e.position;0!==i&&!w(i);)i=e.input.charCodeAt(++e.position);for(a=[],(t=e.input.slice(n,e.position)).length<1&&S(e,"directive name must not be less than one character in length");0!==i;){for(;f(i);)i=e.input.charCodeAt(++e.position);if(35===i){do{i=e.input.charCodeAt(++e.position)}while(0!==i&&!g(i));break}if(g(i))break;for(n=e.position;0!==i&&!w(i);)i=e.input.charCodeAt(++e.position);a.push(e.input.slice(n,e.position))}0!==i&&R(e),l.call(T,t)?T[t](e,t,a):j(e,'unknown document directive "'+t+'"')}_(e,!0,-1),0===e.lineIndent&&45===e.input.charCodeAt(e.position)&&45===e.input.charCodeAt(e.position+1)&&45===e.input.charCodeAt(e.position+2)?(e.position+=3,_(e,!0,-1)):r&&S(e,"directives end mark is expected"),G(e,e.lineIndent-1,4,!1,!0),_(e,!0,-1),e.checkLineBreaks&&u.test(e.input.slice(o,e.position))&&j(e,"non-ASCII line breaks are interpreted as content"),e.documents.push(e.result),e.position===e.lineStart&&P(e)?46===e.input.charCodeAt(e.position)&&(e.position+=3,_(e,!0,-1)):e.position<e.length-1&&S(e,"end of the stream or a document separator is expected")}function N(e,n){n=n||{},0!==(e=String(e)).length&&(10!==e.charCodeAt(e.length-1)&&13!==e.charCodeAt(e.length-1)&&(e+="\n"),65279===e.charCodeAt(0)&&(e=e.slice(1)));var t=new E(e,n),a=e.indexOf("\0");for(-1!==a&&(t.position=a,S(t,"null byte is not allowed in input")),t.input+="\0";32===t.input.charCodeAt(t.position);)t.lineIndent+=1,t.position+=1;for(;t.position<t.length-1;)q(t);return t.documents}function W(e,n,t){null!==n&&"object"===typeof n&&"undefined"===typeof t&&(t=n,n=null);var a=N(e,t);if("function"!==typeof n)return a;for(var i=0,o=a.length;i<o;i+=1)n(a[i])}function H(e,n){var t=N(e,n);if(0!==t.length){if(1===t.length)return t[0];throw new i("expected a single document in the stream, but found more")}}e.exports.loadAll=W,e.exports.load=H,e.exports.safeLoadAll=function(e,n,t){return"object"===typeof n&&null!==n&&"undefined"===typeof t&&(t=n,n=null),W(e,n,a.extend({schema:r},t))},e.exports.safeLoad=function(e,n){return H(e,a.extend({schema:r},n))}},Pcej:function(e,n,t){"use strict";var a=t("7104"),i=t("z08I");function o(e,n){return e.slice(0,n.length)===n&&e.charAt(n.length+1)!==n.slice(-1)}function r(e){return e}e.exports=function(e,n){"function"===typeof n&&(n={parse:n});var t=function(e){"object"!==a(e)&&(e={content:e});if("string"!==typeof e.content&&!function(e){if(e&&e.constructor&&"function"===typeof e.constructor.isBuffer)return e.constructor.isBuffer(e);return!1}(e.content))throw new TypeError("expected a buffer or string");return e.content=e.content.toString(),e.sections=[],e}(e),s=i({},{section_delimiter:"---",parse:r},n),l=s.section_delimiter,c=t.content.split(/\r?\n/),u=null,h={key:"",data:"",content:""},d=[],p=[];function m(e){t.content=e,u=[],d=[]}function g(e){p.length&&(h.key=function(e,n){return e?e.slice(n.length).trim():""}(p[0],l),h.content=e,s.parse(h,u),u.push(h),h={key:"",data:"",content:""},d=[],p=[])}for(var f=0;f<c.length;f++){var w=c[f],b=p.length,y=w.trim();if(o(y,l)){if(3===y.length&&0!==f){if(0===b||2===b){d.push(w);continue}p.push(y),h.data=d.join("\n"),d=[];continue}null===u&&m(d.join("\n")),2===b&&g(d.join("\n")),p.push(y)}else d.push(w)}return null===u?m(d.join("\n")):g(d.join("\n")),t.sections=u,t}},PdyT:function(e,n,t){"use strict";t.r(n),n.default=""},Pfac:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Making a rhythm game with bleeding-edge web\'\ndescription: "While continuing to experiment with Web Audio API and GLSL, I\'ve made a game called Timelapse for js13kgames (an HTML5 game competition where entries must be less than 13 kb zipped)."\nthumbnail: /images/2013/09/timelapse.png\nauthor: Gaetan\nlayout: post\ntags:\n - js13k\n - GLSL\n - audio\n - gamedev\n---\n\n[webaudioapi]: https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html\n[glslheroku]: http://glsl.heroku.com/\n[glsl.js]: /2013/02/glsl-js-a-javascript-glsl-library-dry-efficient/\n[js13kgames]: http://js13kgames.com/\n[beez]: /2013/09/beez\n[fm]: /2013/08/FM-audio-api\n[zound]: /2013/08/zound-wip-v1/\n[entry]: http://js13kgames.com/entries/timelapse\n[github]: https://github.com/gre/js13k\n\n<img src="/images/2013/09/timelapse.png" alt="" class="thumbnail-left" />\n\nWhile continuing to experiment with [Web Audio API][webaudioapi] and [GLSL][glsl.js],\nI\'ve made **[a game called Timelapse][entry]** for [js13kgames][js13kgames]\n(an HTML5 game competition where entries must be less than 13 kb zipped).\n\nThis article is a **postmortem overview of my game development** which will try to explain\nwhat was my game mecanism ideas and show you some interesting parts with **screenshots, audios and source code snippets**.\n\n## The Game\n\n[Open the game on js13kgames][entry] / [github][github].\n\n**The game intends to work on Desktop and Mobile**.\nHowever, *Chrome* is recommended \n(*Firefox Aurora* also supports it but audio is a bit wrong, but Mozilla devs should improve this [soon](https://twitter.com/padenot/status/375924494537195520)).\nToday, it works on *Android Chrome Beta* on a Nexus 4, unfortunately with some clicks in the audio (Web Audio API is bleeding-edge).\n\n\x3c!--more--\x3e\n\n## Experimenting with stuff\n\nLast months, I\'ve been playing with Web Audio API and released a few experiments like \n[Beez][beez], [FM Synthesis][fm] and [Zound][zound].\n\nMy game development started last weekend as an experiment, I tried to make some **dubstep-like sound**, \nstarting with a **["Wob Wob Wob" sound](http://jsfiddle.net/greweb/CrXYw/4/)**.\n\nI also started to dig into [glsl.heroku.com][glslheroku], \nI definitely wanted to make some **cool and unusual graphics with glitchy style** to fit with dubstep audio part, \nI unfortunately hadn\'t enough deepen this glitchy part as I would have liked.\n\nGLSL quite fits this need: it mays look strange and hard code language as a start \nbut **it\'s very easy and free to do anything with it**. \nI used my [glsl.js][glsl.js] wrapper to easily have a shader rendering the whole Canvas.\n\n> GLSL is a totally different way of thinking the rendering: \nthe main principle is to define **a function which returns a Color for a given Position**. \nI use to call it "Functional Rendering" in opposite to "Procedural Rendering". I\'ll talk again about those concepts soon.\n\nI started my graphics by forking [this very interesting glow effect](http://glsl.heroku.com/e#10795.2).\n\n## Prototyping the game ideas\n\nThen I started to really think about the game I could do, \nI sketched some game mecanisms and thought about the gameplay.\n\nMy game was designed to be a **one-button** [DDR](https://en.wikipedia.org/wiki/Dance_Dance_Revolution)-like **rhythm game**\nwith the main idea that **the user controls the speed** *(the BPM, beats per minute)* of the song.\nI wanted an **inertia system**: tap a bit early and your song will speed up, tap a bit late and the song will slow down.\nThis speed freedom isn\'t without constraints: You can reach a gameover if your speed isn\'t enough fast, or contrariwise if it is too fast (like a overheat).\n\n> The game listen to your inputs to adapt the song BPM.\n\nThe game is basically about SPACE-typing on each beat, but also introduce some **freestyle "dubstep" phase**\n*(It\'s not really dubstep though!)*: the gameplay is either typing on the key like hell or holding and releasing some "riff". \n\nThe score mecanisms give good scores for very precise beats and will be negative for very bad/loss rhythms.\nDuring the freestyle section, each action gives a score, also each riff (holding the button for more than 1 tick) gives a score. Making small riffs has been designed to give more points that a very long riff so you have to find the good balance.\n(The score also increases at the end of each freestyle phase).\n\n<img src="/images/2013/09/highscores.png" style="max-width: 300px; width: 50%" />\n\nI also had to find a game end, I first thought about trying to make the game harder and harder but it wasn\'t trivial to make\nbecause I wanted to keep my *"player is free to take any speed he wants"* idea.\n\nInstead, I chose to **limit the game time by one minute**, \nwhich makes my game a psychedelic rush game if you want a good score: \nA good strategy to make a good score is to first speed up the song inertia as fast as possible, and then keep the rhythm on an high BPM.\n\n> That mecanism is interesting because it is also harder to make precise scores on higher speed, it can even be risky (reaching the BPM limit, failing some beats), the player has to find the speed it fits the most!\n\n## The game experience\n\nI wanted my game experience to be both on the **graphics** and on the **audio** aspects:\nyou have both a feedback on your actions with the graphics using a color (\n<span style="color:#0F0">green=good</span>,\n<span style="color:#CC0">yellow=meh</span>,\n<span style="color:#F00">red=bad</span>\n) and with the audio (different sound depending on the rate of the action).\n\n<img src="/images/2013/09/good.png" style="width: 30%" />\n<img src="/images/2013/09/timelapse.png" style="width: 30%" />\n<img src="/images/2013/09/toofast.png" style="width: 30%" />\n\nThe audio BPM is also graphically visualized using a circle with a rotating pulse\nwhich also helps you on the rhythm.\n\nDuring the freestyle phase, the circle turns fully highlighted and the audio "wob wob wob" part is playing.\nEach user freestyle "riff" (hold a note) will randomly change the delay of a "repeater", an important part on the audio of that section I will discuss in the *Audio Section*.\n\n<img src="/images/2013/09/killer-riff.png" style="max-width: 300px; width: 100%" />\n\nIf the player runs the song too fast, an overheat happens and the circle turns very light:\n\n<img src="/images/2013/09/lighted.png" style="max-width: 300px; width: 100%" />\n\nOn the contrary, it turns very dark and glitchy when the BPM is very slow:\n\n<img src="/images/2013/09/slow.png" style="max-width: 300px; width: 100%" />\n\n## More about the audio\n\nAs described in the [specification][webaudioapi], the *Web Audio API* is an audio routing graph composed of low level audio nodes.\nUsing it raw can be quite verbose, I\'ve made my own reusable component using those nodes.\nMy convention is to use Javascript constructor for those components and to have a "inp" and an "out" *AudioNode* field.\n\nFirst I create a `ctx` *AudioContext* (works for Chrome & Firefox Aurora):\n\n```javascript\nvar ctx = new (window.AudioContext || window.webkitAudioContext)();\n```\n\nThis `ctx` variable now offers all methods to work with sound.\n\n### Global effects: Reverbation, Compressor\n\nWeb Audio API have a **Convolver** node which allows to make diverse audio effects like **reverbation**, which is basically emulating your song played in a room. You can find more information [here](http://creativejs.com/resources/web-audio-api-a-bit-more-advanced/).\n\nI\'ve used a simple Reverb effect to pass the whole sound. This simple reverb implementation can be found on [https://github.com/web-audio-components/simple-reverb](https://github.com/web-audio-components/simple-reverb).\n\nAnother **very** important brick of the Audio graph is the **Compressor**.\nThe [Web Audio API][webaudioapi] have a built-in Compressor with some parameters.\n\nA compressor dynamically adapts the input sound to a normalized output. It ensures the output is not distorted (saturated because amplitude is too high) or inaudible because too low.\nIn other words, it consists of dynamically raise the volume if the input is lower, and decrease the volume if the input is higher, that a given rate.\n\nHere is the global audio setup I\'ve used as an output for all different sounds of the song:\n\n```javascript\n  var out = ctx.createGain(); // My global output\n  var outCompressor = ctx.createDynamicsCompressor();\n  var reverb = new Reverb(0.5);\n  out.gain.value = 0; // We will increase the main volume when the song starts\n  out.connect(reverb.inp);\n  reverb.out.connect(outCompressor);\n  outCompressor.connect(ctx.destination);\n```\n\n### Ambiant sounds\n\nI\'ve used a soft **sine Oscillator** and some **Noise generator** (protected by a bandpass Filter) for the **ambiant sound**.\nThat gives more depth to the song.\n\nIt was also used to give more audio feedback on the gameplay:\n\n* The **Oscillator frequency follows the BPM** (goes higher in frequency with the song speed).\n* The BPM also affects the **frequency of a LFO** which oscillate the **volume of the Noise** to make an **helicopter-like sound**.\n* The Oscillator is fastly **detuned on each user action**, and especially if the user tap too early it will produce a "bip" like you can hear in the following Soundcloud.\n* Finally, a second noise passed into a highpass filter will be louder if the player is in danger (BPM is too slow or too fast). *(we won\'t show the code for this one)*\n\nI have muted all other sounds to make you hear only the ambiant sound when speeding up the song up to a gameover:\n\n<iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F110774935"></iframe>\n\nThe Noise component:\n\n```javascript\n  function Noise () {\n    // Here we loop on a 2s noise buffer, it is more efficient that generating on the fly\n    var bufferSize = 2 * ctx.sampleRate,\n    noiseBuffer = ctx.createBuffer(1, bufferSize, ctx.sampleRate),\n    output = noiseBuffer.getChannelData(0);\n    for (var i = 0; i < bufferSize; i++) {\n      output[i] = Math.random() * 2 - 1;\n    }\n    var whiteNoise = ctx.createBufferSource();\n    whiteNoise.buffer = noiseBuffer;\n    whiteNoise.loop = true;\n\n    var gain = createGain();\n    whiteNoise.connect(gain);\n\n    var filter = ctx.createBiquadFilter();\n    gain.connect(filter);\n    filter.type = "lowpass"; // Generally lowpass, but can be overrided\n\n    this.white = whiteNoise;\n    this.gain = gain;\n    this.out = this.filter = filter;\n  }\n\n  Noise.prototype = {\n    start: function (time, duration) {\n      this.white.start(time, 0, duration);\n    }\n  };\n```\n\nHere is some code I used for making the ambiant sound:\n\n```javascript\n  var bpmOsc2mult = 3;\n  var bpmNoiseMult = 10;\n  var noiseBpmGain = ctx.createGain();\n  noiseBpmGain.connect(out);\n  var noiseBpm = new Noise();\n  noiseBpm.out.connect(noiseBpmGain);\n  noiseBpm.start(0);\n  noiseBpm.gain.gain.value = 0.2;\n  noiseBpm.filter.type = "bandpass";\n  noiseBpm.filter.Q.value = 20;\n  noiseBpm.filter.frequency.value = 0;\n\n  var bpmNoiseLfoMult = 0.05;\n  var bpmNoiseLfoPow = 1.3;\n  var lfoBpm = ctx.createOscillator();\n  lfoBpm.start(0);\n  var lfoBpmGain = ctx.createGain();\n  lfoBpmGain.gain.value = 0.8;\n  lfoBpm.connect(lfoBpmGain);\n  lfoBpmGain.connect(noiseBpmGain.gain);\n\n  var osc2 = new OscGain();\n  osc2.type = "sawtooth";\n  osc2.osc.frequency.value = vars.bpm * bpmOsc2mult;\n  osc2.osc.detune.value = 5;\n  osc2.gain.gain.value = 0.1;\n  osc2.out.connect(out);\n  osc2.start(0);\n```\n\n### NOTES\n\nTo easily define melodies, I first define "NOTES", a map of `note -> frequency`. \nFor instance `NOTES.A4` is `440` Hz:\n\n```javascript\nvar NOTES = (function () {\n  var notes = {};\n  var toneSymbols = "CcDdEFfGgAaB";\n  function noteToFrequency (note) {\n    return Math.pow(2, (note-69)/12)*440; // Beauty of audio math!\n  };\n  for (var octave = 0; octave < 8; ++octave) {\n    for (var t = 0; t < 12; ++t) {\n      notes[toneSymbols[t]+octave] = noteToFrequency(octave * 12 + t);\n    }\n  }\n  return notes;\n}());\n```\n\nMy convention here is to use a cap for major notes like `D` and no cap for minor notes like `d` (the black keys on a Piano).\nThe following number is the octave. Notes are defined with two characters: Like A1, C2, B3, a4, ...\nYou will see that\'s quite convenient to use the `with(NOTES){ ... }` syntax.\n\nSee Also [Frequencies of notes](https://en.wikipedia.org/wiki/Frequencies_of_notes).\n\n### FM Synth "bass" melody\n\nI used some [FM synth][fm] for making the main "bass" melody:\n\n<iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F110622269"></iframe>\n\n\nFirst, I made a "OscGain" and a "FM" components.\n\n```javascript\n  function OscGain (t) {\n    this.osc = ctx.createOscillator();\n    if (t) this.osc.type = t;\n    this.out = this.gain = ctx.createGain();\n    this.osc.connect(this.gain);\n  }\n  OscGain.prototype = {\n    start: function (time, duration) {\n      this.osc.start(time, 0, duration);\n    }\n  };\n\n  function FM () {\n    OscGain.call(this);\n    this.mod = new OscGain();\n    this.mod.out.connect(this.osc.frequency);\n  }\n  FM.prototype = {\n    start: function (time, duration) {\n      this.osc.start(time, 0, duration);\n      this.mod.start(time, duration);\n    }\n  };\n```\n\nAnd used this melody:\n\n```javascript\nwith (NOTES) {\n  bassMelo = [G4,D4,F4,C4];\n}\n```\n\n```javascript\n  // Usage for the bass:\n  var bass = new FM();\n  bass.out.connect(out);\n  function tick (i, time) {\n    // ...\n    // Change the note each 4 tick\n    var oscFreq = bassMelo[Math.floor(i/4) % bassMelo.length];\n    bass.osc.frequency.value = oscFreq * 2.0;\n    bass.mod.osc.frequency.value = oscFreq * 0.5;\n    bass.mod.gain.gain.value = oscFreq * 0.5;\n    // ...\n  }\n```\n\n> **N.B.**:\n> The modulator frequency is 1/4 of the oscillator frequency which gives a cool bass sound. <br/>\n> Also, That tick function is called at a (variable) frequency of `60 / BPM` Hz (BPM means Beat Per Minute, here it\'s more a Tick Per Minute) with the tick number `"i"` and the tick time `"time"`.\n\n### FM Synth "main" melody\n\n<iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F110620277"></iframe>\n\nThis "main" synth is also a Frequency Modulation, but using a 3/4 ratio on the modulator frequency,\nand with an envelope on each notes.\n\n```javascript\nwith (NOTES) {\n  melo1 = [E3,G3,D3,G3,E3,A3,C3,G3];\n  melo2 = [E3,B3,D3,G3,E3,C4,C3,D3];\n}\n```\n\nMaking an envelope consists of scheduling the amplitude through time with a *Gain*. See my [FM Article][fm].\n\n```javascript\n  function envelope (gainNode, time, volume, duration, a, d, s, r) {\n    var gain = gainNode.gain;\n    gain.cancelScheduledValues(0);\n    gain.setValueAtTime(gain, 0, time);\n    gain.linearRampToValueAtTime(volume, time + a);\n    gain.linearRampToValueAtTime(volume * s, time + a + d);\n    gain.setValueAtTime(volume * s, time + a + d + duration);\n    gain.linearRampToValueAtTime(0, time + a + d + duration + r);\n  }\n```\n\nAlso, the melody periodically switch into "arpeggio note" with this function:\n\n```javascript\n  var DELTAS = [\n    Math.pow(2, 0),\n    Math.pow(2, 1),\n    Math.pow(2, 2)\n  ];\n\n  function applyArpeggio (freqParam, baseFreq, time, duration, arpDuration, deltas) {\n    if (!deltas) deltas = DELTAS;\n    var length = deltas.length;\n    var ranges = [];\n    cancelScheduledValues(freqParam, 0);\n    for (var t = 0, i = 0; t <= duration; t += arpDuration, i = (i+1) % length) {\n      setValueAtTime(freqParam, baseFreq * deltas[i], time + t);\n    }\n  }\n```\n\nThe Arpeggio effect is about fastly changing some octaves higher (like C3,C4,C5,C3,C4,C5,... very fastly).\nI\'ve keeped that "deltas" a parameter to try other arpeggios, I\'ve only used `[1,2,4]` multiplicators in the game.\n\nIndeed, thanks to the magic of audio math, \nincrementing the octave means multipling the frequency by 2,\nmore generally increment by N octaves means multiplying by `2 ^ N`.\n\nFinally, here is "meloNote", the function which triggers one melody note.\n\n```javascript\n  function meloNote (noteFreq, time, arpeggio, metallic) {\n    var fm = new FM();\n    var duration = 0.3;\n    var release = 0.1;\n    fm.osc.type = "triangle";\n    fm.osc.frequency.value = 4 * noteFreq;\n    fm.mod.osc.frequency.value = 3 * noteFreq;\n    fm.mod.osc.type = "sine";\n    fm.out.connect(meloOut.inp);\n    setTimeout(function () {\n      fm.out.disconnect(meloOut.inp);\n    }, 1000);\n    startNode(fm, time, 0, 1);\n    arpeggio && applyArpeggio(fm.osc.frequency, 4 * noteFreq, time, duration+release, 0.025);\n    envelope(fm.gain, time, 0.5, duration, \n        0.01, 0.02, 0.6, 0.2);\n    envelope(fm.mod.gain, time, 4 * noteFreq * metallic, duration, \n        0.05, 0.1, 0.6, 0.2);\n  }\n```\n\n> **N.B.** The metallic parameter is a parameter from 0 to 1 to give a more metallic sound. \nIt changes the modulator intensity. In fact, that 3/4 ratio on the FM is the reason metallic sound.\n\nThis function is called each tick with a new note:\n\n```javascript\nfunction tick (i, time) {\n  // ...\n  var r = risk(); // How the player is in danger\n  var metallic = 0.4 * r + 0.3 * smoothstep(-1, 1, Math.cos(Math.PI * i / 16));\n  var melo = i % 16 < 8 ? melo1 : melo2;\n  var octave = i % 32 < 16 ? 0 : 1;\n  var m = melo[i % 8] * (1 << octave);\n  meloNote(m, time, meloIsArpeggio, metallic);\n  // ...\n}\n```\n\n\n### Repeater of freestyle part\n\nA **"repeater" with random delay add crazyness in the freestyle section**. The delay time is randomly changed each time you hold the key so it gives cool feedback.\n\n<iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F110612559"></iframe>\n\nThe *Repeater* is made of a *Delay* piped in a *Gain* and piped back in the delay input to produce feedback (echo).\nA particularity of this component is the input *Gain* is also the output *Gain*.\n\n![](/images/2013/09/repeater_schema.png)\n\nImplementation of a Repeater:\n\n```javascript\n  function Repeater (delayValue, repeatGainValue) {\n    var out = ctx.createGain();\n    var delay = ctx.createDelay(1); // The Max Delay\n    delay.delayTime.value = delayValue;\n    out.connect(delay);\n    var repeatGain = ctx.createGain();\n    repeatGain.gain.value = repeatGainValue;\n    delay.connect(repeatGain);\n    repeatGain.connect(out);\n    this.delay = delay;\n    this.repeater = repeatGain;\n    this.gain = this.inp = this.out = out;\n  }\n```\n\n### Playing with Stereo\n\nDoing stereo with Web Audio API can be a bit verbose without wrapping it,\nhere is the Stereo component:\n\n```javascript\n  function Stereo (left, right) {\n    var merger = ctx.createChannelMerger();\n    var inp = ctx.createGain();\n    inp.connect(left.inp);\n    inp.connect(right.inp);\n    this.inp = inp;\n    left.out.connect(merger, 0, 0);\n    right.out.connect(merger, 0, 1);\n    this.left = left;\n    this.right = right;\n    this.out = merger;\n  }\n```\n\n### Drumbox\n\n**The Drumbox is simply made of a Kick, a Snare and a Hihat.**\n\n<iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F110781486"></iframe>\n\nA **Snare** is implemented with a Noise and a Filter:\n\n```javascript\n  function Snare (volume, freqFrom, freqTo) {\n    var noise = new Noise();\n    noise.filter.type = "lowpass";\n    noise.filter.Q.value = 5;\n    noise.gain.gain.value = 0;\n    this.noise = noise;\n    this.out = noise.out;\n    this.volume = volume || 1;\n    this.freqFrom = freqFrom || 800;\n    this.freqTo = freqTo || 1000;\n    this.release = 0.3;\n  }\n\n  Snare.prototype = {\n    trigger: function (time) {\n      this.noise.start(time, 1);\n      envelope(this.noise.gain, time, this.volume, 0.05, \n          0.01, 0.03, 0.25, this.release);\n      var f = this.noise.filter.frequency;\n      f.setValueAtTime(this.freqFrom, time);\n      f.linearRampToValueAtTime(this.freqTo, time+0.1);\n    }\n  };\n```\n\nThe **HiHat** is also made with a Noise and a Filter, \nexcept the Filter is a highpass filter (only high frequency are audible).\n\nFinally, The **Kick** is made with a `Kicker` and a `Snare`.\n\nHere is the Kicker implementation:\n\n```javascript\n  function Kicker (freq, attack, duration, fall) {\n    OscGain.call(this);\n    this.gain.gain.value = 0;\n    this.osc.frequency.value = freq;\n    this.freq = freq || 50;\n    this.fall = fall || 0;\n    this.attack = attack || 0;\n    this.duration = duration || 0;\n    this.volume = 1;\n  }\n\n  Kicker.prototype = {\n    start: function (time, duration) {\n      startNode(this.osc, time, 0, duration);\n    },\n    trigger: function (time) {\n      var a = this.attack, d = this.attack + 0.06, s = 0.8, r = 0.1;\n      this.start(time, this.duration + 1);\n      envelope(this.gain, time, this.volume, this.duration, a, d, s, r);\n      setValueAtTime(this.osc.frequency, this.freq, time);\n      linearRampToValueAtTime(this.osc.frequency, 0, time + this.fall);\n    }\n  };\n```\n\nAnd finally, here is my "kick" method called each time a user press the key:\n\n```javascript\n  kick: function (t, errorRate) {\n    errorRate = errorRate * errorRate * errorRate;\n    var freq = mix(100, 120, errorRate);\n    var speed = mix(0.2, 0.3, errorRate) * 100 / vars.bpm;\n    var kick = new Kicker(freq, 0.01, speed, speed);\n    kick.volume = 1.5;\n    kick.osc.type = "sine";\n    var filter = ctx.createBiquadFilter();\n    filter.frequency.value = mix(200, 300, errorRate);\n    filter.Q.value = 10 + 10 * errorRate;\n    kick.out.connect(filter);\n    filter.connect(drumOut.inp);\n    setTimeout(function () {\n      filter.disconnect(drumOut.inp);\n    }, 1000);\n    kick.trigger(t);\n\n    var snare = new Snare(0.5, 1000, 10);\n    snare.out.connect(drumOut.inp);\n    setTimeout(function () {\n      snare.out.disconnect(drumOut.inp);\n    }, 1000);\n    snare.trigger(t);\n\n    E.pub("kick", t);\n  }\n```\n\n\n### Stereo Drumbox\n\nI\'ve used two Repeaters (one for the left, on for the right) on the Drumbox to produce some stereo echo effects.\n\nThe effect can be very weak to hear, so I made in the following audio example 2 different delays so you can understand what I mean:\n\n<iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F110622238"></iframe>\n\nAll sounds from the drumbox (snare, hihat, kick) is piped into "drumOut", which have that Stereo system.\n\nHere is the code of the "drumOut" (the output where goes all Drum Box sounds):\n\n```javascript\n  var drumOut = (function () {\n    // using the second example delay effect (listen to the soundcloud sound)\n    var left = new Repeater(0.1, 0.5);\n    var right = new Repeater(0.2, 0.7); // Playing with different values for stereo effects\n    right.gain.gain.value = 0.8; // move the drum a bit to the left\n    return new Stereo(left, right);\n  }());\n  drumOut.out.connect(out);\n```\n\n## The GLSL shader\n\nHere is the GLSL code I used for the game, the final version is a bit crazy because I incrementally add features to it!\nAll the graphics are defined here!\n\n```glsl\n#ifdef GL_ES\nprecision mediump float;\n#endif\n\n#define BPM_MIN 30.0\n#define BPM_MAX 150.0\n\nuniform vec2 resolution;\nuniform float time;\nuniform float kick;\nuniform float kickSpeed;\nuniform float bpm;\nuniform float lvl;\n\nuniform bool dubstepAction;\nuniform float useraction;\nuniform float successState;\n\nuniform float dubloading;\nuniform bool dubphase;\nuniform float pulseOpenFrom;\nuniform float pulseOpenTo;\n\nconst vec2 center = vec2(0.5, 0.5);\n\nconst float PI = 3.14159265359;\nconst float PI_x_2 = 6.28318530718;\n\nconst vec3 COLOR_NEUTRAL = vec3(0.1, 0.2, 0.7);\nconst vec3 COLOR_SUCCESS = vec3(0.0, 0.7, 0.1);\nconst vec3 COLOR_ERROR = vec3(0.7, 0.0, 0.05);\n\nfloat expInOut (float a) {\n  return 0.0==a ? 0.0 : 1.0==a ? 1.0 : 1.0 > (a *= 2.0) ? 0.5 * pow(1024.0,a-1.0):0.5*(-pow(2.0,-10.0*(a-1.0))+2.0);\n}\n\nfloat random (vec2 pos) {\n  return fract(sin(dot(pos.xy ,vec2(12.9898,78.233))) * 43758.5453);\n}\nvec3 random3 (vec2 pos) {\n  return vec3(\n    random(pos),\n    random(pos*3.),\n    random(pos*13.)\n  );\n}\n\nfloat distanceRadius (float a, float b) {\n  float d = mod(distance(a, b), PI_x_2);\n  return d < PI ? d : PI_x_2 - d;\n}\n\nfloat spiralDistance (vec2 v, float r) {\n  float d = length(v);\n  float a = (PI + atan(v.x, v.y))/PI_x_2;\n  float n = log(d/r)+a;\n  return distance(1.0, 2.0 * smoothstep(0.0, 1.0, fract(n)));\n}\n\nfloat bpmToSec (float bpm) {\n  return 60. / bpm;\n}\n\nfloat circlePulse (\n  vec2 v, float kickForce,\n  float kickGlitchFreq, float kickGlitchAmp,\n  float thin, float pulseAngle, bool dubphase,\n  float waveFreq, float waveAmp, float waveDuration,\n  float bullForce\n) {\n  float angle = atan(-v.x, -v.y);\n  float clock = distanceRadius(0.0, angle) / PI;\n  float distAngle = distanceRadius(angle, PI_x_2 * pulseAngle) / PI;\n  float f = mix(1.0, smoothstep(-1.0, 1.0, cos(kickGlitchFreq * (clock+0.1*angle+kickForce))), kickGlitchAmp);\n  float r = mix(0.35, 0.2, kickForce*f);\n  float sc = smoothstep(1.0-waveDuration, 1.0, distAngle);\n  float intensity = 0.1+0.05*sc;\n  r /= mix(0.95, 1.0, waveAmp*sc*cos(angle*waveFreq));\n  float a = mod(PI_x_2+atan(v.x, v.y), PI_x_2)/PI_x_2;\n  float ring = abs(length(v)-r) - 0.03*bullForce*(!dubphase ? \n    smoothstep(1.0-1.5*waveDuration, 1.0, clock) : \n    (\n    a < pulseOpenFrom ? smoothstep(0.05, 0.0, distance(a, pulseOpenFrom)) : \n    a > pulseOpenTo ? smoothstep(0.05, 0.0, distance(a, pulseOpenTo)) : \n    1.0\n    )\n  );\n  float value = smoothstep(0.0, intensity, ring);\n  float returnValue = 1.0/sqrt(abs(value))/1.0 * pow(thin, 2.);\n  if ( length(v) < r) {\n    float sr = PI;\n    float s = spiralDistance(v, sr);\n    float a = (PI + atan(v.x, v.y))/PI_x_2;;\n    float v = \n      smoothstep(0.02, 0., distanceRadius(PI+pulseAngle*PI_x_2, a*PI_x_2)/PI) *\n      smoothstep(0.2, 0., s);\n    returnValue += v * 2.0;\n    s = 1.0 - pow(smoothstep(0.0, 0.3, s), 0.3);\n    returnValue += s;\n  }\n  float centerIntensity = dubphase ? 0.1 : 0.1*dubloading;\n  if (centerIntensity > 0.0) {\n    float s = bpmToSec(bpm);\n    float c = mix(1.0, 10.0, mod(time, s)/s) * smoothstep(centerIntensity, 0.0, length(v));\n    returnValue += c;\n  }\n  return returnValue;\n}\n\nvoid main (void) {\n  vec3 c = vec3(0.0);\n  vec2 p = gl_FragCoord.xy / resolution;\n  float sec = bpmToSec(bpm);\n  float statePower = smoothstep(0.8, 0.0, time-useraction);\n  float colorPower = dubstepAction ? 1.0 : statePower;\n  float cPulse = circlePulse(\n    p - center,\n    smoothstep(kickSpeed, 0.0, time-kick),\n    20.0,\n    0.5,\n    0.5 + 0.5 * smoothstep(smoothstep(0.6, 1.0, statePower), 0.0, distance(smoothstep(0.8, 1.0, statePower), distance(p, center))),\n    mod((time-kick)/sec, 1.0),\n    dubphase,\n    1.2*sqrt(bpm) + 4.0*statePower,\n    2.0,\n    min(0.5, bpm / 800.0),\n    1.0 - statePower\n  );\n  vec3 mainColor = mix(\n    COLOR_NEUTRAL,\n    mix(COLOR_ERROR, COLOR_SUCCESS, successState),\n    colorPower);\n  \n  c += cPulse * mainColor;\n\n  c = clamp(\n    c,\n    vec3(0.05, 0.05, 0.05),\n    vec3(1.0, 1.0, 1.0)\n  );\n\n  float bpmLight = smoothstep(BPM_MIN, BPM_MAX, bpm);\n  c = mix(c * (0.5 * random(p + time) + 0.5 * random(floor(p * 100.) + 0.01*time) - 0.5 * random(floor(p * 10.) + time)), c, min(1.0, 15.0*bpmLight));\n\n  c *= 0.1 + max(0.95, 100.0*(bpmLight-0.85));\n\n  gl_FragColor = vec4(c, 1.0);\n}\n```\n\n\n## Bonus\n\n**Did you recognize the melody I used in the freestyle part?**\nThe melody doesn\'t keep the rhythm though, but you should be able to recognize it!\n\n<iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F110614352"></iframe>\n'},PjKD:function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: \"Automatiser l'exportation d'un site statique avec wget\"\nauthor: Gaetan\nlayout: post\npermalink: /2010/04/automatiser-lexportation-dun-site-statique-avec-wget/\ntags:\n  - playframework\n---\n\nIl est pr\xe9f\xe9rable d\u2019**utiliser un framework web** m\xeame si l\u2019on veut r\xe9aliser un **site vitrine simple (statique)**, car l\u2019on b\xe9n\xe9ficie des avantages du framework notamment de l\u2019h\xe9ritage (entre autre) des templates, de l\u2019internationalisation, de la configuration des _routes_, du _SASS_, etc.\n\nDe plus, cela permet de rendre la maintenabilit\xe9 moins longue et couteuse.\n\nN\xe9anmoins, son h\xe9bergeur ne permet pas toujours de faire tourner son site avec le framework utilis\xe9 (par exemple _ruby on rails_ ou _play! framework_).\n\nPour rem\xe9dier \xe0 ce probl\xe8me, il suffit d\u2019**exporter son site statique en simples pages HTML**.\n\nCet article est donc destin\xe9 aux particuliers ne voulant pas investir dans un serveur d\xe9di\xe9, fans de framework avanc\xe9s qui ne sont pas support\xe9s par les offres d\u2019entr\xe9e de gamme des h\xe9bergeurs (qui n\u2019offrent g\xe9n\xe9ralement que le support du php).\n\n**D\u2019ailleurs, pour ce type de site, pourquoi utiliser un framework MVC si l\u2019on utilise que des vues ?**\n\n## La d\xe9marche\n\n### Le site web\n\n**R\xe9alisez le site** avec votre framework pr\xe9f\xe9r\xe9 et faites en sorte que la page principale (**/**) **permette l\u2019acc\xe8s \xe0 toutes les pages du site** par des liens (pas forc\xe9ment directs).\n\n### Exportation\n\nAvec **wget** r\xe9cup\xe9rez votre site \xe0 la ligne de commande :\n\n```bash\nwget -r -k -np \"http://localhost:9000/\"\n```\n\nA l\u2019instar d\u2019un moteur de recherche, c\u2019est cette commande qui va s\u2019occuper de **retracer toutes les pages web de votre site**, mais aussi toutes ses ressources (images, css, js, ..). En plus de cela, elle va **pr\xe9server le fonctionnement des liens** entre pages.\n\nAdaptez _http://localhost:9000/_ \xe0 l\u2019url de votre site.\n\nCela va cr\xe9er le dossier _localhost:9000_, il ne vous restera plus qu\u2019\xe0 l\u2019envoyer sur votre serveur http.\n\n## Internationalisation\n\nVoici une solution pour exporter son internationalisation.\n\nElle consiste \xe0 rediriger l\u2019utilisateur, depuis la page principale, sur la bonne page internationalis\xe9e en fonction de sa langue (indiqu\xe9e par le navigateur), tout **en gardant les fichiers publics en commun** (css, images).\n\n### Pr\xe9parer ses routes\n\npr\xe9parez les uri pour qu\u2019elles soient de la forme **/{lang}/\\*/** avec **lang** d\xe9signant la langue d\xe9sir\xe9e.\n\n#### Exemples de routes\n\n```\n/en/\n/en/about/\n/fr/\n/fr/about/\n```\n\n### Ajouter des liens dans les templates pour changer de langue\n\nCette action est d\xe9licate car, comme pr\xe9cis\xe9 auparavant, **wget** essaye de retracer tous les liens entre pages.\n\nAinsi, si l\u2019on cr\xe9e des liens entre les diff\xe9rentes langues, **wget** cr\xe9era un dossier _public_ pour chaque langue internationalis\xe9e.\n\nPour contourner ce probl\xe8me et ainsi factoriser les fichiers communs, **une solution est de cr\xe9er les liens \xe0 posteriori**.\n\n#### Solution exemple avec play framework\n\n```\n<p>\n#{if lang!='en'}\n  <a ADD_HERE_ENGLISH_LINK_ATTRIBUTES>english version</a>\n#{/if}\n#{if lang!='fr'}\n  <a ADD_HERE_FRENCH_LINK_ATTRIBUTES>french version</a>\n#{/if}\n</p>\n```\n\n```bash\n#!/bin/bash\n# script bash\nwget -r -k -np \"http://localhost:9000/\"\nsed -i s/ADD_HERE_ENGLISH_LINK_ATTRIBUTES/href=\\\"\\\\/en\\\\/\\\"/g $(find . -name \"*.html\")\nsed -i s/ADD_HERE_FRENCH_LINK_ATTRIBUTES/href=\\\"\\\\/fr\\\\/\\\"/g $(find . -name \"*.html\")\n```\n\n### Pr\xe9parer une page de redirection\n\n**Placez \xe0 posteriori un script de redirection \xe0 l\u2019url /** pour rediriger vers la page ad\xe9quat.\n\n#### Par exemple un script php\n\n```php\n<?php\n$langs = array();\n\nif (isset($_SERVER['HTTP_ACCEPT_LANGUAGE'])) {\n    preg_match_all('/([a-z]{1,8}(-[a-z]{1,8})?)\\s*(;\\s*q\\s*=\\s*(1|0\\.[0-9]+))?/i', $_SERVER['HTTP_ACCEPT_LANGUAGE'], $lang_parse);\n    if (count($lang_parse[1])) {\n        $langs = array_combine($lang_parse[1], $lang_parse[4]);\n        foreach ($langs as $lang => $val) {\n            if ($val === '') $langs[$lang] = 1;\n        }\n        arsort($langs, SORT_NUMERIC);\n    }\n}\n\nforeach ($langs as $lang => $val) {\n  if (strpos($lang, 'fr') === 0) {\n    header('Location: fr');\n    die();\n  }\n  else if (strpos($lang, 'en') === 0) {\n    header('Location: en');\n    die();\n  }\n}\nheader('Location: en');\n?>\n```\n"},Pkmy:function(e,n,t){"use strict";t.r(n),n.default=""},Q8dS:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Anomalie carr\xe9e (3/4)"\nthumbnail: /images/plots/169.jpg\ndescription: "One of the 4 plots of the series of \'Anomalie carr\xe9e\'. made with 2 fountain pens on A4 Bristol paper. The first buyer of this NFT sold by achetezdelart can collect the original copy. No other copy will be made. See information in the NFT."\n---\n\n<nft-card contractAddress="0x495f947276749ce646f68ac8c248420045cb7b5e" tokenId="47428341271170390733253974222101382154768714392453356712130950048008835694593"> </nft-card> <script src="https://unpkg.com/embeddable-nfts/dist/nft-card.min.js"><\/script>\n\nOne of the 4 plots of the series of \'Anomalie carr\xe9e\'. made with 2 fountain pens on A4 Bristol paper. The first buyer of this NFT sold by achetezdelart can collect the original copy. No other copy will be made. See information in the NFT.'},Q9oK:function(e,n,t){"use strict";const a=t("7104"),i=t("8Qj+"),o=t("X+87");e.exports=function(e){return"object"!==a(e)&&(e={content:e}),"object"!==a(e.data)&&(e.data={}),e.contents&&null==e.content&&(e.content=e.contents),o.define(e,"orig",o.toBuffer(e.content)),o.define(e,"language",e.language||""),o.define(e,"matter",e.matter||""),o.define(e,"stringify",(function(n,t){return t&&t.language&&(e.language=t.language),i(e,n,t)})),e.content=o.toString(e.content),e.isEmpty=!1,e.excerpt="",e}},QMpp:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Jumping blob (8 frames)"\nthumbnail: "/images/plots/129.gif"\ndescription: "8 frames plotted making an animated loop of a jumping blob. A 1920p video and 12cm square physical art is available as an NFT."\ntags:\n  - plotloop\nobjkts:\n  - 71006\n---\n\nHere is "Jumping blob" my second ["plot loop" (see article)](https://greweb.me/2021/05/plot-loops). The main digital art is a 1920p video loop of 8 frames available as a [Tezos hicetnunc NFT](https://www.hicetnunc.xyz/objkt/71006). The physical art is 8 frames of A5 size, the square of the drawing is 12cm by 12cm and they are offered when [buying the NFT](https://www.hicetnunc.xyz/objkt/71006) (8 editions, assigned in buy order).\n\nThere are 8 frames plotted recreating the "jumping blob" animation (shader implemented in [https://greweb.me/shaderday/67](https://greweb.me/shaderday/67)). Each frame is plotted with two fountain pens (Diamine inks: Pink and Turquoise) on Canson Bristal (A5 format), and takes about an hour to plot.\n\n<img width="100%" src="/images/plots/129_all.jpg" />\n\nEach frame revisit a specific technique that I explored in the past months:\n\n- Frame 1: Voronoi distribution + samples spiral\n- Frame 2: Voronoi distribution + samples sorted\n- Frame 3: Voronoi polygons\n- Frame 4: Voronoi distribtion + TSP\n- Frame 5: sampling points and starting lines with vector field (low frequency)\n- Frame 6: sampling points and starting lines with vector field (aligned horizontally)\n- Frame 7: sampling points and starting lines with vector field (more curvy)\n- Frame 8: circles plotting\n\n<img width="50%" src="/images/plots/129_zoom1.jpg" /><img width="50%" src="/images/plots/129_zoom2.jpg" />\n\nThe generator was completely reimplemented, including the "scene" itself which is a port of the GLSL code into Rustlang with some adjustments (two different colors are spread on different areas):\n\n```rust\nfn jumping_blob(f: f64, o: (f64, f64)) -> Vec<f64> {\n    let mut p = o;\n    let bezier = Bezier::new(0.0, 0.1, 1.0, 0.9);\n    let x = bezier.calculate(f as f32) as f64;\n    let t = x * 2. * PI;\n    let radius = 0.18;\n    let smoothing = 0.15;\n    let dist = 0.2;\n    p.0 -= 0.5;\n    p.1 -= 0.5;\n    p.1 *= -1.0;\n    p = p_r(p, PI / 2.0);\n    let q = p;\n    p = p_r(p, -t);\n    let s = f_op_difference_round(\n        f_op_union_round(\n            q.0.max(0.1 + q.0),\n            length((p.0 + dist, p.1)) - radius,\n            smoothing,\n        ),\n        length((p.0 - dist, p.1)) - radius,\n        smoothing,\n    );\n    let v = smoothstep(-0.6, 0.0, s).powf(2.0)\n        * (if s < 0.0 { 1.0 } else { 0.0 });\n    vec![\n        v * (0.001 + smoothstep(-0.5, 1.5, p.0)),\n        v * (0.001 + smoothstep(1.5, -0.5, p.0)),\n    ]\n}\nfn p_r(p: (f64, f64), a: f64) -> (f64, f64) {\n    (\n        a.cos() * p.0 + a.sin() * p.1,\n        a.cos() * p.1 - a.sin() * p.0,\n    )\n}\nfn length(l: (f64, f64)) -> f64 {\n    (l.0 * l.0 + l.1 * l.1).sqrt()\n}\nfn f_op_union_round(a: f64, b: f64, r: f64) -> f64 {\n    r.max(a.min(b))\n        - length(((r - a).max(0.), (r - b).max(0.)))\n}\nfn f_op_intersection_round(a: f64, b: f64, r: f64) -> f64 {\n    (-r).min(a.max(b))\n        + length(((r + a).max(0.), (r + b).max(0.)))\n}\nfn f_op_difference_round(a: f64, b: f64, r: f64) -> f64 {\n    f_op_intersection_round(a, -b, r)\n}\n\n```\n\n<img width="100%" src="/images/plots/129_zoom3.jpg" />\n\nIt\'s one of the first time I try to work on the "scene composition" and I\'ve also used a pattern filled with "+" for the background. I want to explore more of these in the future.\n\n\x3c!--\nJumping Blob (8 frames)\n@greweb\'s #2 plot loop. The 1920p animation is the main & digital art. First buyer also can collect one frame of the physical art (PM @greweb, ship anywhere in the world, frame # in buy order). Secondary market is digital only. There are 8 frames, one for each NFT edition. drawing is 12cm square, centered on a A5 bristol paper, two fountain pens. See greweb.me/plots/129\nanimated, plot, plotloop, physical, phygical\n--\x3e\n'},"QR/K":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Planet Holes #1"\nthumbnail: /images/plots/100.jpg\ntweet: https://twitter.com/greweb/status/1380855370101448705\nobjkts:\n  - 28236\n  - 28238\n  - 28263\n  - 28264\ntags:\n  - planet-holes\n  - collection\n---\n\nInspiration came from work from [@mellogood](https://twitter.com/mellogood) who made these: https://twitter.com/mellogood/status/1376565566283120645.\n\nI\'m starting from this idea here and trying to add some Perlin noise displacement on the polar coordinate.\n'},QhJx:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "wool ball"\nthumbnail: /images/plots/134.jpg\ndescription: "A simple experiment with randomly connected curves."\n---\n\nA simple experiment with randomly connected curves.\n'},QmdR:function(e,n,t){"use strict";t.r(n),n.default=""},"Qru/":function(e,n,t){"use strict";t.r(n),n.default=""},QzXX:function(e,n,t){"use strict";t.r(n),n.default=""},R4Of:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Relics NFT collection"\nthumbnail: /images/2021/05/relics.gif\ndescription: "Relics collection are unique animation made with Perlin noise, cellular automaton and GLSL."\ntags:\n  - NFT\n---\n\n<img width="400" src="/images/2021/05/relics.gif" />\n\n# Releasing **Relics**, my first curated NFT collectible series, on Tezos blockchain and platform [_hicetnunc.xyz_](https://hic.link/greweb).\n\n**Collection:** There are 28 curated visual loops that will be shared on the 7 days of this week. 4 NFT a day. I will use French day names as well as French seasons to name them all.\n\n**Technical:** Relics collection are unique animation made with Perlin noise, cellular automaton and GLSL. The generator is fully open source and available on my website here: https://greweb.me/shaderday/63 as I strongly believe in open sourcing literally everything I do even as an artist. That said, I curated carefully the 28 unique NFTs myself and it\'s the only official collection of that generator.\n\n> Contact me if you are the buyer to obtain the parameters of your NFT. Unfortunately it\'s not possible yet to "unlock" content as part of buying a NFT but I would be glad to give you the parameters of your NFT! I can also generate high resolution versions on demand (but also, the open sourced code allows it, once you have these parameters!).\n\n_Lundi d\'hiver, Lundi de printemps, Lundi d\'\xe9t\xe9, Lundi d\'automne._\n\n<a href="https://www.hicetnunc.xyz/objkt/61391"><img src="https://cloudflare-ipfs.com/ipfs/QmSbZ7iK1S2aDKtTM4HLkzjZrMCwgyDhNbqum8kQTfF44N" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/61403"><img src="https://cloudflare-ipfs.com/ipfs/QmbGrg2mckEbz5u6ShuQi5SbRcUKkEiY9S8irExUiJLizS" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/61410"><img src="https://cloudflare-ipfs.com/ipfs/QmZSQduPnXvmWvFo8JdC3WrxjzU9MbaKGD2JtywtWRq6C8" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/61413"><img src="https://cloudflare-ipfs.com/ipfs/Qmb2qS5Vp7YPfW5KqqgEm4aFqeTaGv2RXb81j1mG9dcLqL" width="25%"/></a>\n\n_Mardi d\'hiver, Mardi de printemps, Mardi d\'\xe9t\xe9, Mardi d\'automne._\n\n<a href="https://www.hicetnunc.xyz/objkt/63131"><img src="https://cloudflare-ipfs.com/ipfs/QmQHcBZ18wYDMq2B2i7AfQFC1e5CJytgsYxYzuanJ8Zxuy" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/63126"><img src="https://cloudflare-ipfs.com/ipfs/QmZRfP9fNKWRizNzHEiB4yHFPTSAuij53XJzXdeqz2qqNu" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/62848"><img src="https://cloudflare-ipfs.com/ipfs/QmT4xPg39PyVDEYGSi1BRce62jJnt2w8SmCDxEYJaZ47cQ" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/62839"><img src="https://cloudflare-ipfs.com/ipfs/QmXrWE4csSkPXYRg3BqhFmKVCzbXGDtNLRkku6Gc2PCY2Y" width="25%"/></a>\n\n_Mercredi d\'hiver, Mercredi de printemps, Mercredi d\'\xe9t\xe9, Mercredi d\'automne._\n\n<a href="https://www.hicetnunc.xyz/objkt/64885"><img src="https://cloudflare-ipfs.com/ipfs/QmcwpMrbg3n3iNo1TgQUS5LarKwFwz6kK9wexkc38ybRgT" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/64874"><img src="https://cloudflare-ipfs.com/ipfs/QmeDzVu5G1wLJxEsDXJXtdiJpMWAiRDfJnRgx16VmGH96X" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/64863"><img src="https://cloudflare-ipfs.com/ipfs/QmZuJcvNG2T7sCn959CWEuHZxi1C2Nr5H5JzbV6Sp5Pz3p" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/64852"><img src="https://cloudflare-ipfs.com/ipfs/Qmcomh1sD8L6wewENSWnqLT4akpRwrDpgABy8viu68b9Ua" width="25%"/></a>\n\n_Jeudi d\'hiver, Jeudi de printemps, Jeudi d\'\xe9t\xe9, Jeudi d\'automne._\n\n<a href="https://www.hicetnunc.xyz/objkt/66703"><img src="https://cloudflare-ipfs.com/ipfs/QmRe8RwPjLhatKbSMV5YGf3TDBKdB8W7xVnM8zQzNqe3dM" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/66686"><img src="https://cloudflare-ipfs.com/ipfs/QmNpPhofb4eJJq7YCDpjba8t3fNFQkY8W9ryM2iSreWkwB" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/66683"><img src="https://cloudflare-ipfs.com/ipfs/QmRN9L8PhKmfb4uM2LsFb2C2Gxa3YHZ7KQFZsSbSAUAMZ6" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/66674"><img src="https://cloudflare-ipfs.com/ipfs/QmXh2RAdgP841oJWdyMtBSQ78XnYQwHzEkTF8qze6hnbCn" width="25%"/></a>\n\n_Vendredi d\'hiver, Vendredi de printemps, Vendredi d\'\xe9t\xe9, Vendredi d\'automne._\n\n<a href="https://www.hicetnunc.xyz/objkt/68578"><img src="https://cloudflare-ipfs.com/ipfs/QmTXdtycdrp4v6UWymCeDJCamxHqUdHdy99XfK7vmVqqtx" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/68575"><img src="https://cloudflare-ipfs.com/ipfs/QmVyxcykCS8f1vpriReyedAfdP1M9wHq8pwyKtWtoUgXRb" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/68572"><img src="https://cloudflare-ipfs.com/ipfs/QmY1HcgrX7S5wxaYxRoFuxUWEdG6W6gAApDpzc1oYHSUDt" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/68522"><img src="https://cloudflare-ipfs.com/ipfs/QmSc8Q5ozk8nhLvzF6jry613WDhvFX6PjbqnKbyb97smhy" width="25%"/></a>\n\n_Samedi d\'hiver, Samedi de printemps, Samedi d\'\xe9t\xe9, Samedi d\'automne._\n\n<a href="https://www.hicetnunc.xyz/objkt/69282"><img src="https://cloudflare-ipfs.com/ipfs/QmasrfTskgzSj48gG62xFyWvXrJXWznyPakMB7GtYwgcY3" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/69280"><img src="https://cloudflare-ipfs.com/ipfs/QmdvFEWzkbK2yPNSNURPNNJTkGf55MoDfboXboCvYwVUob" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/69276"><img src="https://cloudflare-ipfs.com/ipfs/QmZhD4pwmRB43CN7hXKouGHMgCdwuFfnBweJfNBeSJeTBt" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/69275"><img src="https://cloudflare-ipfs.com/ipfs/QmdgVW9CnMY1P6o41EEaiwsJMDQdgxhPzo4xmrV8YLLJ66" width="25%"/></a>\n\n_Dimanche d\'hiver, Dimanche de printemps, Dimanche d\'\xe9t\xe9, Dimanche d\'automne._\n\n<a href="https://www.hicetnunc.xyz/objkt/70994"><img src="https://cloudflare-ipfs.com/ipfs/QmbTE4QGptyHGYsyemttEXSDoydapMuBiT94kooD3zLHc9" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/70991"><img src="https://cloudflare-ipfs.com/ipfs/QmXMUCZmptV4MyXJ8zUMM9ZoAfmWMLCTr5toPH99YLo6LY" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/70973"><img src="https://cloudflare-ipfs.com/ipfs/QmfVNN6bfzhsEK5fx45DwQTQ6hMrbASxgGzQnSgTwJEbJd" width="25%"/></a><a href="https://www.hicetnunc.xyz/objkt/70967"><img src="https://cloudflare-ipfs.com/ipfs/QmU1VEYV7zyyN3LhES4mgAm8qdgjgvDERDRqu7GJnKtVQL" width="25%"/></a>\n\n_published on [hic.link/greweb](https://hic.link/greweb)_\n'},RHpB:function(e,n,t){"use strict";t.r(n),n.default=""},RXE9:function(e,n,t){"use strict";t.r(n),n.default="---\ntweet: https://twitter.com/greweb/status/1380106073542131712\ntags:\n  - perlin\n  - spiral\n  - circle\n---\n"},RiMv:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "3-Blob"\nthumbnail: /images/plots/175.jpg\ndescription: "Exploration of marching squares contour and distance function technique"\n---\n\nExploration of marching squares contour and distance function technique.'},RuLc:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Rotation (11 frames)"\nthumbnail: /images/plots/188.gif\ndescription: "@greweb\'s #10 plot loop. That animation is the main digital art. A high-quality video is available in 11 NFT editions, one per frame, for buyers to acquire each physical frame."\ntags:\n  - shape-packing\n  - plotloop\n---\n\n**Every NFT sold allows acquiring a plotted frame. (code in the unlockable content)**\n\n<nft-card contractAddress="0x495f947276749ce646f68ac8c248420045cb7b5e" tokenId="47428341271170390733253974222101382154768714392453356712130950051307370577931"> </nft-card> <script src="https://unpkg.com/embeddable-nfts/dist/nft-card.min.js"><\/script>\n\n@greweb\'s #10 plot loop. That animation is the main digital art.\n\nA high-quality video is available in 11 NFT editions, one per frame, for buyers to acquire each physical frame.\n\nThis work took me a lot of dedication to plot the 11 frames for an (interrupted) one week long! Each frame taking almost 2 hours to plot, you can\'t really cheat here, I like to think the process to be some sort of *Proof Of Plot*.\n\nIt is getting sold by **achetezdelart** on OpenSea. Detail is in the description.\n\n## Plotting highlights\n\n<img width="100%" src="/images/plots/188plot1.gif">\n<img width="100%" src="/images/plots/188plot2.gif">\n<img width="100%" src="/images/plots/188plot3.gif">\n\n\n## Making-of and technical notes\n\nIt is probably one of the craziest main.rs source code I wrote for a plot, notably because I have combined in one script many different techniques, most of them explored earlier in other dedicated plots.\n\nI tried to put in this plot loop my best artwork and recent iterations of color packing experiments.\n\nThe work is technically composed of 3 circles rotating in the middle of a lot of circles packing. Each circle contains itself a specific art technique:\n\n- shape contouring, to remind a bit exploration of [plotloop#136](/plots/136)\n- square packing, which is a direct reuse of logic of [plot#180](/plots/180) with however a unique nesting of squares to create more depth.\n- layered lines in circles, which is an innovation that I\'m going to re-explore (starting with next [plot#189](/plots/189))\n\n\n## Full picture photos\n\n1 out of 11\n\n<img width="100%" src="/images/plots/188full0.jpg">\n\n2 out of 11\n\n<img width="100%" src="/images/plots/188full1.jpg">\n\n3 out of 11\n\n<img width="100%" src="/images/plots/188full2.jpg">\n\n4 out of 11\n\n<img width="100%" src="/images/plots/188full3.jpg">\n\n5 out of 11\n<img width="100%" src="/images/plots/188full4.jpg">\n\n6 out of 11\n<img width="100%" src="/images/plots/188full5.jpg">\n\n7 out of 11\n\n<img width="100%" src="/images/plots/188full6.jpg">\n\n8 out of 11\n\n<img width="100%" src="/images/plots/188full7.jpg">\n\n9 out of 11\n\n<img width="100%" src="/images/plots/188full8.jpg">\n\n10 out of 11\n\n<img width="100%" src="/images/plots/188full9.jpg">\n\n11 out of 11\n\n<img width="100%" src="/images/plots/188full10.jpg">\n\n## Early prototypes I had!\n\nIt was a hard choice to give up on colors and stay on a minimalistic black.\n\nI do not plan to sell these at this stage.\n\n<img width="100%" src="/images/plots/188proto1.jpg">\n<img width="100%" src="/images/plots/188proto2.jpg">\n<img width="100%" src="/images/plots/188proto3.jpg">\n'},"Sb+6":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "ZOUND live project initiated"\ndescription: \'Last week, I initiated ZOUND live following my previous "ZOUND" experiment but being much more ambitious this time: using both the Audio API, the new MIDI API and electronic music software experience, we start our own web collaborative audio modular tracker.\'\nthumbnail: /images/2013/07/nanokontrol.jpg\nauthor: Gaetan\nlayout: post\ntags:\n  - MIDI\n  - audio\n  - hackday\n  - zound\n---\n\n[zound]: /2012/08/zound-a-playframework-2-audio-streaming-experiment-using-iteratees/\n[webmidiapi]: http://webaudio.github.io/web-midi-api/\n[webaudioapi]: https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html\n[tracker]: http://en.wikipedia.org/wiki/Tracker_(music_software)\n[zenexity]: http://zenexity.com\n\n<img src="/images/2013/07/nanokontrol.jpg" alt="" class="thumbnail-left" />\n\nLast week, I initiated, with my [Zenexity][zenexity] Hackday team, **"ZOUND live"**\nfollowing the previous ["ZOUND"][zound] experiment but being much more ambitious this time:\nusing both the **Audio API**, the _new_ **MIDI API** and electronic music software experience,\nwe start our own **web collaborative audio modular tracker**.\n\n### Live demo of the Hackday application\n\n<iframe width="640" height="480" src="//www.youtube.com/embed/uyHWhCnE4L0" frameborder="0" allowfullscreen></iframe>\n\n\x3c!--more--\x3e\n\n## Inspiration\n\nA lot of features have been inspired from existing software like _SunVox_ or _Renoise_.\nHowever, our version uses 100% web technologies and add collaborative and real time aspects.\n\n<img src="/images/2013/07/sunvox.png" style="max-width: 300px" />\n\n### Our Tracker\n\nThe application has a [tracker][tracker] where you can put notes.\n\n<img src="/images/2013/07/tracker.png" style="max-width: 300px" />\n\n### Our Audio modules\n\nThe application integrates a [modular music](http://en.wikipedia.org/wiki/Modular_software_music_studio) concepts.\n\n<img src="/images/2013/07/nodeeditor.png" />\n\n## The web techs\n\n### About Web MIDI API\n\nWe bought a few **cheap MIDI controllers to interact with our application**.\n\n<img src="/images/2013/07/midicontrollers.jpg" class="thumbnail-right" style="max-width: 250px" alt="" />\n\nMIDI means _Musical Instrument Digital Interface_,\nit is the **protocol** used by a lot of electronic musical instruments for a few decades.\n\nThe [Web MIDI API](webmidiapi) is a recent specification which makes MIDI devices accessible from a web page,\nvia a Javascript API.\n\nRecently, _Chrome_ has started to [implement it](https://code.google.com/p/chromium/issues/detail?id=163795)\nand it is available under _Chrome Canary_ (the dev version) via a _flag_ that you need to enable.\n\nThis is the perfect time to start experimenting it!\n\nHowever, what I feared the most happened on the Hackday: **the MIDI API was broken on the morning\nafter a Chrome update during the night!** A first version of a browser MIDI permission was implemented\nbut I never succeeded to make it working. The state of the API seems to be still broken on Mac as of writing.\n\n<blockquote class="twitter-tweet"><p><a href="https://twitter.com/greweb">@greweb</a> If you know how to build chromium, I may be able to provide a patch to enable it. But it isn\'t so long until Canary supports it.</p>&mdash; \u3068\u3088\u3057\u307e (@toyoshim) <a href="https://twitter.com/toyoshim/statuses/360685543778041857">July 26, 2013</a></blockquote>\n<script async src="//platform.twitter.com/widgets.js" charset="utf-8"><\/script>\n\nWell, that was already too late for the Hackday,\nFortunately we fallbacked on an alternative which relies on a Java applet to access MIDI devices, it was a laggy polyfill though...\n\n**Lesson learned:** a nightly feature is a nightly feature, never assume features you add via flags are stable _(I never did, but it was a Hackday afterall!)_.\n\nBTW, cheers to <a href="https://twitter.com/toyoshim">@toyoshim</a> who is implementing the MIDI API in Chrome :-)\n\n### Using Web Audio API\n\nThe [Web Audio API][webaudioapi] is _a high-level JavaScript API for processing and synthesizing audio in web applications_.\n\nThe good thing about this API: it is already an **modular audio API**, so it\'s not so hard to build a modular audio application on top of it!\n\n### Playframework\n\n[Playframework](http://playframework.com/) has been used for **broadcasting events\nbetween clients via WebSocket and synchronize everything on the interface**.\nIt is only broadcasting and does not save the song yet.\n\n### Backbone.js\n\n[Backbonejs](backbonejs.org) was used for the **models**, **views** and its nice **event system**.\nIt was a good library for prototyping and architecture the different parts of the application.\n\nI found Backbone.js especially good when linking all parts together and especially for the network logic.\nThis leads to a very reactive style of programming:\n\n<script src="https://gist.github.com/gre/6107277.js"><\/script>\n\n## The team\n\n**This project has been started during our monthly Hackday at [Zenexity][zenexity],\nI want to thank my 6 awesome coworkers for being part of the project:**\n\n- [@mrspeaker](http://twitter.com/mrspeaker) for his awesome electronic music knowledge.\n- [@bobylito](http://twitter.com/bobylito) for his brilliant ideas and his JavaScript skills.\n- [@mandubian](http://twitter.com/mandubian) for his playframework experience and JSON superpower!\n- [@etaty](http://twitter.com/etaty) for helping with the server synchronization.\n- [@skaalf](http://twitter.com/skaalf) for his cool DrumBox module.\n- [@Noxdzine](http://twitter.com/Noxdzine) for his talentuous design.\n\nThis was actually my first real project managment and it was quite cool!\n\n**Hackday is only one day** and such an ambitious project is hard to achieve one in a row,\nthe project architecture needed to be a bit ready and having a PoC working before the Hackday. Also I wanted everyone to have fun by experimenting with the Audio API parts and not to be blocked on boring parts.\n\nAs a team manager, I also had to define goals to achieve for the Hackday.\n\nWoo, I realize that\'s **not an easy task to manage a team when running out of time!**\n\nBut fortunately, I think we fulfilled it just in time!\n\nWe ended the Hackday with a **Real Time demonstration of our application** with 4 people interacting together\nwith MIDI controllers.\n\n## More to come!\n\nToday, we have a **first working version of a\ncollaborative tracker with basic modular audio features**:\n\n- MIDI note support + MIDI control assignation allowing to change module properties.\n- a unique tracker with a 32 lines loop and 23 tracks.\n- Synchronisation of everything: the tracker and modules for all connected clients.\n- off-mode allowing one user to prepare a track which is muted for other users.\n- play/pause and record mode!\n- cursor of users displayed on the tracker.\n\n**Stay tuned because there is so much features to come!**\n\n[**The project on Github**](http://github.com/gre/zound-live)\n'},See4:function(e,n,t){"use strict";t.r(n),n.default=""},SqyK:function(e,n,t){"use strict";t.r(n),n.default=""},Ss4Z:function(e,n,t){"use strict";var a=t("Ga6R"),i=t("XCGq"),o=t("YJCK"),r=t("EOT6"),s=Object.prototype.toString,l=Object.prototype.hasOwnProperty,c={0:"\\0",7:"\\a",8:"\\b",9:"\\t",10:"\\n",11:"\\v",12:"\\f",13:"\\r",27:"\\e",34:'\\"',92:"\\\\",133:"\\N",160:"\\_",8232:"\\L",8233:"\\P"},u=["y","Y","yes","Yes","YES","on","On","ON","n","N","no","No","NO","off","Off","OFF"];function h(e){var n,t,o;if(n=e.toString(16).toUpperCase(),e<=255)t="x",o=2;else if(e<=65535)t="u",o=4;else{if(!(e<=4294967295))throw new i("code point within a string may not be greater than 0xFFFFFFFF");t="U",o=8}return"\\"+t+a.repeat("0",o-n.length)+n}function d(e){this.schema=e.schema||o,this.indent=Math.max(1,e.indent||2),this.noArrayIndent=e.noArrayIndent||!1,this.skipInvalid=e.skipInvalid||!1,this.flowLevel=a.isNothing(e.flowLevel)?-1:e.flowLevel,this.styleMap=function(e,n){var t,a,i,o,r,s,c;if(null===n)return{};for(t={},i=0,o=(a=Object.keys(n)).length;i<o;i+=1)r=a[i],s=String(n[r]),"!!"===r.slice(0,2)&&(r="tag:yaml.org,2002:"+r.slice(2)),(c=e.compiledTypeMap.fallback[r])&&l.call(c.styleAliases,s)&&(s=c.styleAliases[s]),t[r]=s;return t}(this.schema,e.styles||null),this.sortKeys=e.sortKeys||!1,this.lineWidth=e.lineWidth||80,this.noRefs=e.noRefs||!1,this.noCompatMode=e.noCompatMode||!1,this.condenseFlow=e.condenseFlow||!1,this.implicitTypes=this.schema.compiledImplicit,this.explicitTypes=this.schema.compiledExplicit,this.tag=null,this.result="",this.duplicates=[],this.usedDuplicates=null}function p(e,n){for(var t,i=a.repeat(" ",n),o=0,r=-1,s="",l=e.length;o<l;)-1===(r=e.indexOf("\n",o))?(t=e.slice(o),o=l):(t=e.slice(o,r+1),o=r+1),t.length&&"\n"!==t&&(s+=i),s+=t;return s}function m(e,n){return"\n"+a.repeat(" ",e.indent*n)}function g(e){return 32===e||9===e}function f(e){return 32<=e&&e<=126||161<=e&&e<=55295&&8232!==e&&8233!==e||57344<=e&&e<=65533&&65279!==e||65536<=e&&e<=1114111}function w(e,n){return f(e)&&65279!==e&&44!==e&&91!==e&&93!==e&&123!==e&&125!==e&&58!==e&&(35!==e||n&&function(e){return f(e)&&!g(e)&&65279!==e&&13!==e&&10!==e}(n))}function b(e){return/^\n* /.test(e)}function y(e,n,t,a,i){var o,r,s,l,c=!1,u=!1,h=-1!==a,d=-1,p=f(l=e.charCodeAt(0))&&65279!==l&&!g(l)&&45!==l&&63!==l&&58!==l&&44!==l&&91!==l&&93!==l&&123!==l&&125!==l&&35!==l&&38!==l&&42!==l&&33!==l&&124!==l&&61!==l&&62!==l&&39!==l&&34!==l&&37!==l&&64!==l&&96!==l&&!g(e.charCodeAt(e.length-1));if(n)for(o=0;o<e.length;o++){if(!f(r=e.charCodeAt(o)))return 5;s=o>0?e.charCodeAt(o-1):null,p=p&&w(r,s)}else{for(o=0;o<e.length;o++){if(10===(r=e.charCodeAt(o)))c=!0,h&&(u=u||o-d-1>a&&" "!==e[d+1],d=o);else if(!f(r))return 5;s=o>0?e.charCodeAt(o-1):null,p=p&&w(r,s)}u=u||h&&o-d-1>a&&" "!==e[d+1]}return c||u?t>9&&b(e)?5:u?4:3:p&&!i(e)?1:2}function v(e,n,t,a){e.dump=function(){if(0===n.length)return"''";if(!e.noCompatMode&&-1!==u.indexOf(n))return"'"+n+"'";var o=e.indent*Math.max(1,t),r=-1===e.lineWidth?-1:Math.max(Math.min(e.lineWidth,40),e.lineWidth-o),s=a||e.flowLevel>-1&&t>=e.flowLevel;switch(y(n,s,e.indent,r,(function(n){return function(e,n){var t,a;for(t=0,a=e.implicitTypes.length;t<a;t+=1)if(e.implicitTypes[t].resolve(n))return!0;return!1}(e,n)}))){case 1:return n;case 2:return"'"+n.replace(/'/g,"''")+"'";case 3:return"|"+k(n,e.indent)+x(p(n,o));case 4:return">"+k(n,e.indent)+x(p(function(e,n){var t,a,i=/(\n+)([^\n]*)/g,o=function(){var t=e.indexOf("\n");return t=-1!==t?t:e.length,i.lastIndex=t,A(e.slice(0,t),n)}(),r="\n"===e[0]||" "===e[0];for(;a=i.exec(e);){var s=a[1],l=a[2];t=" "===l[0],o+=s+(r||t||""===l?"":"\n")+A(l,n),r=t}return o}(n,r),o));case 5:return'"'+function(e){for(var n,t,a,i="",o=0;o<e.length;o++)(n=e.charCodeAt(o))>=55296&&n<=56319&&(t=e.charCodeAt(o+1))>=56320&&t<=57343?(i+=h(1024*(n-55296)+t-56320+65536),o++):i+=!(a=c[n])&&f(n)?e[o]:a||h(n);return i}(n)+'"';default:throw new i("impossible error: invalid scalar style")}}()}function k(e,n){var t=b(e)?String(n):"",a="\n"===e[e.length-1];return t+(a&&("\n"===e[e.length-2]||"\n"===e)?"+":a?"":"-")+"\n"}function x(e){return"\n"===e[e.length-1]?e.slice(0,-1):e}function A(e,n){if(""===e||" "===e[0])return e;for(var t,a,i=/ [^ ]/g,o=0,r=0,s=0,l="";t=i.exec(e);)(s=t.index)-o>n&&(a=r>o?r:s,l+="\n"+e.slice(o,a),o=a+1),r=s;return l+="\n",e.length-o>n&&r>o?l+=e.slice(o,r)+"\n"+e.slice(r+1):l+=e.slice(o),l.slice(1)}function D(e,n,t){var a,o,r,c,u,h;for(r=0,c=(o=t?e.explicitTypes:e.implicitTypes).length;r<c;r+=1)if(((u=o[r]).instanceOf||u.predicate)&&(!u.instanceOf||"object"===typeof n&&n instanceof u.instanceOf)&&(!u.predicate||u.predicate(n))){if(e.tag=t?u.tag:"?",u.represent){if(h=e.styleMap[u.tag]||u.defaultStyle,"[object Function]"===s.call(u.represent))a=u.represent(n,h);else{if(!l.call(u.represent,h))throw new i("!<"+u.tag+'> tag resolver accepts not "'+h+'" style');a=u.represent[h](n,h)}e.dump=a}return!0}return!1}function E(e,n,t,a,o,r){e.tag=null,e.dump=t,D(e,t,!1)||D(e,t,!0);var l=s.call(e.dump);a&&(a=e.flowLevel<0||e.flowLevel>n);var c,u,h="[object Object]"===l||"[object Array]"===l;if(h&&(u=-1!==(c=e.duplicates.indexOf(t))),(null!==e.tag&&"?"!==e.tag||u||2!==e.indent&&n>0)&&(o=!1),u&&e.usedDuplicates[c])e.dump="*ref_"+c;else{if(h&&u&&!e.usedDuplicates[c]&&(e.usedDuplicates[c]=!0),"[object Object]"===l)a&&0!==Object.keys(e.dump).length?(!function(e,n,t,a){var o,r,s,l,c,u,h="",d=e.tag,p=Object.keys(t);if(!0===e.sortKeys)p.sort();else if("function"===typeof e.sortKeys)p.sort(e.sortKeys);else if(e.sortKeys)throw new i("sortKeys must be a boolean or a function");for(o=0,r=p.length;o<r;o+=1)u="",a&&0===o||(u+=m(e,n)),l=t[s=p[o]],E(e,n+1,s,!0,!0,!0)&&((c=null!==e.tag&&"?"!==e.tag||e.dump&&e.dump.length>1024)&&(e.dump&&10===e.dump.charCodeAt(0)?u+="?":u+="? "),u+=e.dump,c&&(u+=m(e,n)),E(e,n+1,l,!0,c)&&(e.dump&&10===e.dump.charCodeAt(0)?u+=":":u+=": ",h+=u+=e.dump));e.tag=d,e.dump=h||"{}"}(e,n,e.dump,o),u&&(e.dump="&ref_"+c+e.dump)):(!function(e,n,t){var a,i,o,r,s,l="",c=e.tag,u=Object.keys(t);for(a=0,i=u.length;a<i;a+=1)s="",0!==a&&(s+=", "),e.condenseFlow&&(s+='"'),r=t[o=u[a]],E(e,n,o,!1,!1)&&(e.dump.length>1024&&(s+="? "),s+=e.dump+(e.condenseFlow?'"':"")+":"+(e.condenseFlow?"":" "),E(e,n,r,!1,!1)&&(l+=s+=e.dump));e.tag=c,e.dump="{"+l+"}"}(e,n,e.dump),u&&(e.dump="&ref_"+c+" "+e.dump));else if("[object Array]"===l){var d=e.noArrayIndent&&n>0?n-1:n;a&&0!==e.dump.length?(!function(e,n,t,a){var i,o,r="",s=e.tag;for(i=0,o=t.length;i<o;i+=1)E(e,n+1,t[i],!0,!0)&&(a&&0===i||(r+=m(e,n)),e.dump&&10===e.dump.charCodeAt(0)?r+="-":r+="- ",r+=e.dump);e.tag=s,e.dump=r||"[]"}(e,d,e.dump,o),u&&(e.dump="&ref_"+c+e.dump)):(!function(e,n,t){var a,i,o="",r=e.tag;for(a=0,i=t.length;a<i;a+=1)E(e,n,t[a],!1,!1)&&(0!==a&&(o+=","+(e.condenseFlow?"":" ")),o+=e.dump);e.tag=r,e.dump="["+o+"]"}(e,d,e.dump),u&&(e.dump="&ref_"+c+" "+e.dump))}else{if("[object String]"!==l){if(e.skipInvalid)return!1;throw new i("unacceptable kind of an object to dump "+l)}"?"!==e.tag&&v(e,e.dump,n,r)}null!==e.tag&&"?"!==e.tag&&(e.dump="!<"+e.tag+"> "+e.dump)}return!0}function I(e,n){var t,a,i=[],o=[];for(S(e,i,o),t=0,a=o.length;t<a;t+=1)n.duplicates.push(i[o[t]]);n.usedDuplicates=new Array(a)}function S(e,n,t){var a,i,o;if(null!==e&&"object"===typeof e)if(-1!==(i=n.indexOf(e)))-1===t.indexOf(i)&&t.push(i);else if(n.push(e),Array.isArray(e))for(i=0,o=e.length;i<o;i+=1)S(e[i],n,t);else for(i=0,o=(a=Object.keys(e)).length;i<o;i+=1)S(e[a[i]],n,t)}function j(e,n){var t=new d(n=n||{});return t.noRefs||I(e,t),E(t,0,e,!0,!0)?t.dump+"\n":""}e.exports.dump=j,e.exports.safeDump=function(e,n){return j(e,a.extend({schema:r},n))}},SsVj:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Triplanet (16 frames)"\ndescription: "Triplanet is my first plot loop, physical animation of 16 plotted frames. transition between parametric functions and perlin noise."\nthumbnail: /images/plots/121.gif\ntags:\n  - plotloop\n  - parametric\n  - perlin\nobjkts:\n  - 57902\n---\n\n[**\u270d\ufe0f See also: Plot loops** article](/2021/05/plot-loops).\n\nThis first plot loop is called "Triplanet". It\'s a transition of two parametric functions with many perlin noise displacements. This is a continuation of ["Planet Holes"](/plots/100) series as well as recent ["Parametric stack"](/plots/111) explorations.\nEvery frame is generated with a Rust script I wrote.\n\n16 frames has been plotted with fountain pen on bristol paper (ink: Red Dragon by Diamine). With a back and forth effect, this produces a 30 frames animation loop.\n\n<img width="100%" src="/images/plots/121_walled.jpg"/>\n\n**The animation is released as a NFT video** on [hicetnunc](https://www.hicetnunc.xyz/). There are 16 editions, as many as there were frames plotted. The NFT video is an art in itself.\n\nBy buying a frame (by order of buy), the first buyer also chose what happens to the physical plot: either I keep it OR you can claim it (contact me on Twitter) and have me sending it anywhere in the world!\n\n<img width="100%" src="/images/plots/121_zoom.jpg"/>\n\n**Plotting with fountain pen is challenging** as it requires many search on the ink, paper and many fail and retry. Plotting all these frames took an afternoon.\n\n<img width="100%" src="/images/plots/121_plot.jpg"/>\n\n\x3c!--\n@greweb\'s #1 plot loop. 16 physical plots, fountain pen on A4 Bristol paper, one NFT edition for each plot frame. The 1920p video animation is the digital art that can be collected as-is. First buyer also chose what happens to the frame: can claim the physical art (PM @greweb, ship anywhere in world). See greweb.me/plots/121\ntags: animated, plot, plotloop, physical\n--\x3e\n'},"T+M9":function(e,n,t){"use strict";t.r(n),n.default=""},T3W9:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Alien planet"\nthumbnail: "/images/plots/137.jpg"\ndescription: "transition of two parametric spirals repeated twice with different displacement. Fountain pen with \'Aurora Borealis\' on white bristol A4."\ntags:\n  - parametric\n---\n\ntransition of two parametric spirals repeated twice with different displacement. Fountain pen with \'Aurora Borealis\' on white bristol A4. The beginning of the spiral is not yet changing in radius to make a bolder border, this is a subtle but important aspect.\n\n<img src="/images/plots/137zoom1.jpg" width="100%">\n\nThe zoom is quite interesting here. let\'s also zoom at the center too:\n\n<img src="/images/plots/137zoom2.jpg" width="100%">\n'},"TjV/":function(e,n,t){"use strict";t.r(n),n.default=""},"U+Tf":function(e,n,t){"use strict";t.r(n),n.default=""},VQEG:function(e,n,t){"use strict";e.exports=function(e,n){let t=n.engines[e]||n.engines[function(e){switch(e.toLowerCase()){case"js":case"javascript":return"javascript";case"coffee":case"coffeescript":case"cson":return"coffee";case"yaml":case"yml":return"yaml";default:return e}}(e)];if("undefined"===typeof t)throw new Error('gray-matter engine "'+e+'" is not registered');return"function"===typeof t&&(t={parse:t}),t}},VV7m:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: Universal GL Effects for Web and Native\nauthor: Gaetan\nlayout: post\ntags:\n  - react\n  - webgl\n  - gl-react\n---\n\n[gl-react]: https://github.com/projectseptemberinc/gl-react\n[gl-react-dom]: https://github.com/projectseptemberinc/gl-react-dom\n[gl-react-native]: https://github.com/projectseptemberinc/gl-react-native\n[reconciliation]: https://facebook.github.io/react/docs/reconciliation.html\n[glsl-spec]: https://www.khronos.org/registry/gles/specs/2.0/GLSL_ES_Specification_1.0.17.pdf\n[gl-react-blur]: https://github.com/gre/gl-react-blur\n[gl-react-negative]: https://github.com/gre/gl-react-negative\n[gl-react-constrast-saturation-brightness]: https://github.com/gre/gl-react-constrast-saturation-brightness\n[gl-react-hue-rotate]: https://github.com/gre/gl-react-hue-rotate\n[gl-react-color-matrix]: https://github.com/gre/gl-react-color-matrix\n\n<script src="http://localhost:35729/"><\/script>\n\nLast February, I talked about [`gl-react`][gl-react] at React.js conference.\n\n<iframe width="560" height="315" src="https://www.youtube.com/embed/Xnqy_zkBAew" frameborder="0" allowfullscreen></iframe>\n\n> [Checkout talks](https://www.youtube.com/playlist?list=PLb0IAmt7-GS0M8Q95RIc2lOM6nc77q1IY) of this conference if you are interested by React subject.\n> I want to thanks the incredible team behind React.js for the awesome conference and giving me the opportunity to come to San Francisco.\n\n_This article will cover some more technical detail of [`gl-react`][gl-react] that wasn\'t explained in the talk._\n\n> _Also, I\'ll try to not go TOO MUCH into technical detail neither, because it would take weeks to cover gl-react features and its implementation tricks!_\n\n\x3c!--more--\x3e\n\n---\n\nWe have developed, at [Project September](http://projectseptember.com), an [universal](https://medium.com/@mjackson/universal-javascript-4761051b7ae9) OpenGL wrapper for React called [`gl-react`][gl-react] working with 2 other libraries: [`gl-react-dom`][gl-react-dom] (wraps WebGL) and [`gl-react-native`][gl-react-native] (wraps OpenGL).\n\nThe library allows to define **advanced effects** on top of **images, videos, texts or any other VDOM Content** (like UI Views).\n\nCheckout the following `gl-react` demos running with the **same codebase across iOS, Android and the Web !!!**\n\n## [**AdvancedEffects**](http://projectseptemberinc.github.io/gl-react-dom/Examples/AdvancedEffects/)\n\n<img src="/images/2016/03/advanced-effects.gif" style="width:100%" />\n\n## [**github.com/gre/gl-react-image-effects**](https://github.com/gre/gl-react-image-effects)\n\n<a href="http://greweb.me/gl-react-image-effects/" style="text-align:center"><img src="/images/2016/03/image-effects-ios.gif" style="width: 33%;" /><img src="/images/2016/03/image-effects-web.png" style="width: 33%;" /><img src="/images/2016/03/image-effects-android.png" style="width: 33%" /></a>\n\n## Adopting React paradigm\n\nThere are a few important points in React that `gl-react` follows to fit its paradigm.\n\n### 1. React is about composition\n\n**Components are first class citizen** in React.\nA Component provides isolation by exposing a simple API (props) and encapsulates internal lifecycle.\nOne particular prop is the `children` prop that, by convention, allows to pass-in children components to a component.\n\nFor instance, we can define a component called `Container` taking a `children` prop and use it like this in JSX:\n\n```html\n<Container>\n  <div>Hello</div>\n</Container>\n```\n\n> Note that "JSX" is a syntax sugar that, in this example, transpiles to something like:\n\n```js\nReact.createElement(Container, {\n  children: React.createElement("div", { children: "Hello" }),\n});\n```\n\n> There are really no magic here: JSX just tends to be more convenient to write and, most of the time, it would be more annoying to use createElement API.\n\n### 2. React is about Functional Programming...\n\nThis might not be that obvious at a first glance but React is about FP. In React paradigm, you describe the full rendering of your application _(in "Virtual DOM")_ for a given application state, and you do this every time something changes in the application. So fundamentally, you just have to implement that **function from State to Virtual DOM** to implement your web application \u2013 _which is close to render loops in game dev (but it\'s another subject^^)._\n\n### ...and reconciliation on top of an underlying Imperative API\n\nIn React, you don\'t go mutating the DOM but you just RENDER EVERYTHING everytime! It\'s very simple to reason about, it removes lot of inconsistency bugs and React is here to optimize this with [an algorithm called "reconciliation"][reconciliation] (or diff/patch).\n\n> Efficiently translating an high level immutable API into a lower level mutable API is the hard work that solves React on top of DOM, as well does gl-react on top of OpenGL.\n\nThe [reconciliation][reconciliation] work done by React is a complex optimization problem that have trade-offs. This work is all about **translating a imperative API (the DOM) to a functional API (React VDOM)**.\n\nIn [`gl-react`][gl-react], we have the **exact same problem to resolve**: [`gl-react`][gl-react] exposes a **functional API** and implements for you the complex work over the mutable, stateful and low-level API that is OpenGL / WebGL.\n\n### 3. React is a thin wrapper\n\nOne other key point of React is that it\'s a **thin wrapper on top of DOM**. React focus on translating **imperative API => functional API** with the most minimal & generic way, meaning that React won\'t hide you what the DOM elements are about _(same as React Native tries just to be on top of real Native components)_.\n\nWe tried to follow this principle as well when wrapping (Open/Web)**GL**:\nwe want to hide the complex and imperative part of GL but just expose the great functional parts that are the **Fragment Shaders** and the **Framebuffers**.\n\n## Hardcoding the vertex part of the pipeline\n\n![](/images/2016/03/hardcoded_pipeline.png)\n\n`gl-react` _currently_ focuses on what can be achieved with **composing Fragment Shaders** with multiple **Framebuffers** that define a **graph of effects**. The Vertex Data & Vertex Shaders are currently hardcoded.\n\n> `gl-react` might unlock this hardcoded part in the future \u2013 [some recent experiments by @snikhilesh](https://twitter.com/snikhilesh/status/707730742994833408) shows a promising overview of what can possibility by done there!\n\nBut for now, we focus on the huge challenge to implement `gl-react` seamlessly between the Web, Android and iOS implementations and to work on performance _(e.g of the content rasterization performance)_.\n\n<blockquote class="twitter-tweet" data-lang="fr"><p lang="en" dir="ltr">Notes from <a href="https://twitter.com/greweb">@greweb</a>&#39;s <a href="https://twitter.com/hashtag/reactjsconf?src=hash">#reactjsconf</a> talk Universal GL Effects for Web and Native <a href="https://t.co/JnIOjAQCOK">pic.twitter.com/JnIOjAQCOK</a></p>&mdash; Michael Chan (@chantastic) <a href="https://twitter.com/chantastic/status/702213897520943104">23 f\xe9vrier 2016</a></blockquote>\n<script async src="//platform.twitter.com/widgets.js" charset="utf-8"><\/script>\n\n## _"Functional Rendering"_\n\nWe mentioned earlier that `gl-react` focuses on one important piece of OpenGL that is the fragment shader.\n\n**A Fragment Shader is a function** that independently colors each pixel:\n\n![](/images/2016/03/functional_rendering.png)\n\n[Watch this talk](http://greweb.me/2013/11/functional-rendering/) for more detail on what I call _Functional Rendering_.\n\n> Fragment shaders use a language called GLSL for _OpenGL Shading Language_. GLSL is a DSL dedicated to the functional rendering paradigm with "graphics-ready" types (vectors, matrix, sampler2D for textures) and built-in functions (like mix, distance, pow, cos,...).\n> Checkout the [specification][glsl-spec].\n\n## GL*uing* with React\n\n**[`gl-react`][gl-react] is a core library**: it doesn\'t provide any built-in effects, users have to provide the shaders to render. Hopefully it\'s fairly simple to implement basic effects _(like saturation, contrast, brightness, inverse, hue,...)_ in GLSL language and _Functional Rendering_ paradigm.\n\n### HelloGL example\n\nLet\'s create HelloGL, our first fragment shader:\n\n```glsl\nprecision highp float;\nvarying vec2 uv; // This variable vary in all pixel position (normalized from vec2(0.0,0.0) to vec2(1.0,1.0))\nvoid main () { // This function is called FOR EACH PIXEL\n  gl_FragColor = vec4(uv.x, uv.y, 0.5, 1.0); // red vary over X, green vary over Y, blue is 50%, alpha is 100%.\n}\n```\n\nIt\'s a _Point to Color_ function:\n\n- **the input comes from `varying vec2 uv`**\n- **the output is set in `vec4` `gl_FragColor`** \u2013 `main()` is called for each pixel with a different `uv` (it\'s _varying_ like the keyword indicates).\n\nso this HelloGL glsl code basically do:\n\n```js\n[ x, y ] => [ x, y, 0.5, 1.0 ]\n```\n\n- The **RED** component increases with the X position of the pixel.\n- The **GREEN** component increases with the Y position of the pixel.\n\nwhich renders this nice 2D gradient:\n\n<img width="160" src="/images/2016/03/hellogl.png" />\n\nNow, in `gl-react`, we can define "HelloGL" as a GL Component with:\n\n```js\nimport GL from "gl-react";\nimport React from "react";\nconst shaders = GL.Shaders.create({\n  helloGL: {\n    frag: `\nprecision highp float;\nvarying vec2 uv;\nvoid main () {\n  gl_FragColor = vec4(uv.x, uv.y, 0.5, 1.0);\n}`,\n  },\n});\nconst HelloGL = GL.createComponent(() => <GL.Node shader={shaders.helloGL} />);\n```\n\nand then use it:\n\n```html\n<HelloGL />\n```\n\n### ColoredDisc example\n\nGL Component can have props in parameter that can be passed-in as GLSL Uniforms.\n\n<img class="thumbnail-right" src="/images/2016/03/colored-disc.png" />\n\n```html\n<ColoredDisc fromColor="{[" 1, 0, 1 ]} toColor="{[" 1, 1, 0 ]} />\n```\n\n<br />\n\n```js\nimport GL from "gl-react";\nimport React from "react";\nconst shaders = GL.Shaders.create({\n  ColoredDisc: {\n    frag: `\nprecision highp float;\nvarying vec2 uv;\nuniform vec3 fromColor;\nuniform vec3 toColor;\nvoid main () {\n  float d = 2.0 * distance(uv, vec2(0.5));\n  gl_FragColor = mix(\n    vec4(mix(fromColor, toColor, d), 1.0),\n    vec4(0.0),\n    step(1.0, d)\n  );\n}`,\n  },\n});\nconst ColoredDisc = GL.createComponent(({ fromColor, toColor }) => (\n  <GL.Node shader={shaders.ColoredDisc} uniforms={{ fromColor, toColor }} />\n));\n```\n\n### DiamondCrop example\n\n<img class="thumbnail-right" src="/images/2016/03/diamond-crop.png" />\n\n```html\n<DiamondCrop> http://i.imgur.com/rkiglmm.jpg </DiamondCrop>\n```\n\n<br />\n\n```js\nimport GL from "gl-react";\nimport React from "react";\nconst shaders = GL.Shaders.create({\n  DiamondCrop: {\n    frag: `\nprecision highp float;\nvarying vec2 uv;\nuniform sampler2D t;\nvoid main () {\n  gl_FragColor = mix(\n    texture2D(t, uv),\n    vec4(0.0),\n    step(0.5, abs(uv.x - 0.5) + abs(uv.y - 0.5))\n  );\n}`,\n  },\n});\nconst DiamondCrop = GL.createComponent(({ children: t }) => (\n  <GL.Node shader={shaders.DiamondCrop} uniforms={{ t }} />\n));\n```\n\n## Any content can be used\n\nLet\'s say we define a Blur effect with `gl-react`.\n\n```js\nconst Blur = GL.createComponent(({ children, factor }) => ...);\n```\n\nHere, we have just defined a GL Component `Blur` that accept a children as a props.\nIt also accept a factor prop to define the intensity of that blur.\nTherefore we can use `Blur` using JSX in many ways.\n\n> **N.B.** If you want such a Blur, checkout [gl-react-blur](https://github.com/gre/gl-react-blur).\n\nFirst of all you can blur an image:\n\n<img class="thumbnail-right" src="/images/2016/03/blur_image.png" />\n\n```html\n<Blur factor="{2}"> http://i.imgur.com/rkiglmm.jpg </Blur>\n```\n\n<br />\n\nBut really anything can be passed-in here. For instance, a video\n\n```html\n<Blur factor="{0.6}">\n  <video src="/video.mpg" />\n</Blur>\n```\n\nor a canvas:\n\n```html\n<Blur factor="{0.7}">\n  <canvas ... />\n</Blur>\n```\n\nand where that canvas can be provided by a library, like react-canvas:\n\n```html\n<Blur factor="{0.9}">\n  <ReactCanvas.Surface ...>\n    <ReactCanvas.Text ...>Hello World</ReactCanvas.Text>\n  </ReactCanvas.Surface>\n</Blur>\n```\n\nIn React Native context, we even have support for ANY view.\nIt can be a simple Text:\n\n<img class="thumbnail-right" src="/images/2016/03/text_blur.png" />\n\n```html\n<Blur factor="{0.9}">\n  <Text ...>Hello World</Text>\n</Blur>\n```\n\n<br />\n\nor even a native component like a Switch component\n\n<img class="thumbnail-right" src="/images/2016/03/switch_blur.png" />\n\n```html\n<Blur factor="{0.9}">\n  <Switch ... />\n</Blur>\n```\n\n<br />\n\nThe way this is implemented is platform specific. For instance the Web implementation will just render the content into WebGL (so it works with images, videos, canvas, but not any arbitrary DOM element due to Web Security limitations). However, the Native implementation will be able to **rasterize** (almost) any view and inject it as a texture (consider this feature experimental at the moment).\n\n## Compose, Compose, Compose\n\nBut **composition** is probably the MOST important part of this:\nYou can also pass a GL Component in uniforms!\n\nSo all possible composition of previous examples will just work\n\n<img class="thumbnail-right" src="/images/2016/03/diamond_hellogl.png" />\n\n```html\n<DiamondCrop>\n  <HelloGL />\n</DiamondCrop>\n```\n\n<br />\n\n<img class="thumbnail-right" src="/images/2016/03/blur_diamond_hellogl.png" />\n\n```html\n<Blur factor="{4}">\n  <DiamondCrop>\n    <HelloGL />\n  </DiamondCrop>\n</Blur>\n```\n\n<br />\n\n`gl-react` makes composition efficient using OpenGL Framebuffers.\nThis approach encourages you to write small and generic shaders (instead of one monolithic and specific shader).\n\n> For this composition to work correctly, the components must be created with `GL.createComponent` or directly be `GL.Node` components.\n\n## <Surface/>\n\nTo actually get a rendering with gl-react, **you need to put your GL Component stack into a <Surface/> element**.\n\nFor instance, to render HelloGL on a 200x200 canvas:\n\n<img class="thumbnail-right" src="/images/2016/03/hellogl.png" />\n\n```html\n<Surface width="{200}" height="{200}">\n  <HelloGL />\n</Surface>\n```\n\n```js\nimport { Surface } from "gl-react-dom";\nimport { Surface } from "gl-react-native";\n```\n\n<br/>\n\n**Surface** implements the rendering in the contextual platform:\n\n- If you import `{Surface}` from `gl-react-dom` it will renders into a **WebGL Canvas** **_(web)_**, (it\'s backed by great [stack.gl](http://stack.gl/) libs)\n- If, instead, it comes from `gl-react-native`, **GLKView** **_(iOS)_** / **GLSurfaceView** **_(Android)_** will be used.\n\n**Surface** have roughly the same API across these 2 libraries but some props might exist only on one of the implementations.\n\n## Dynamic Blur Image Title Example\n\nMy talk featured an advanced use-case that we had in my startup, [Project September](http://projectseptember.com/). We are developing a social mobile app with React Native and our designer wanted to have title over image with Blur effects around the title text.\n\n[![](/images/2016/03/hellosf.jpg)](http://greweb.me/reactjsconf2016/)\n\n[Open the demo](http://greweb.me/reactjsconf2016/) \u2013 [See the code](https://github.com/gre/reactjsconf2016)\n\nThis effect is just exposed as a simple **ImageTitle** React component that we can use like this:\n\n```html\n<ImageTitle text="Hello San Francisco \u263b">\n  http://i.imgur.com/XXXXXX.jpg\n</ImageTitle>\n```\n\nThe point of `gl-react` is we all know how to compose React components, just put it in a **Surface** and you obtain a title over image effect like on the image above.\n\n> we can even run the effect over a video\n\n```html\n<ImageTitle text="Hello San Francisco \u263b">\n  <video src="video.mp4" />\n</ImageTitle>\n```\n\nwhich is what [our demo](http://greweb.me/reactjsconf2016/) does if you enable the video mode.\n\n## Under the hood\n\n> This section will show **ImageTitle** implementation that will illustrate `gl-react` optimization techniques.\n\nLet\'s take a quick look at our ImageTitle shader. That shader renders the title text on top of the blurred image. The title text color is chosen based on the average pixel color (if the content is dark, we use a white title, otherwise a black one).\n\nI won\'t enter more into implementation detail, but here is the fragment shader:\n\n![](/images/2016/03/image-title-shader.png)\n\nNow, let\'s focus on our JavaScript gl-react code.\n\n**ImageTitle** is a GL Component that takes a few props (basically `title` and `children`) and delegates the job using a few other Components: **Title** that renders the text, **TitleBlurMap** that generates a blur map of that text, **BlurV** that apply the blurmap to generate a variable blur over the content (image/video), **AveragePixels** that generate one pixel out of the content.\nThese 4 elements are then composed into our final ImageTitle shader.\n\n![](/images/2016/03/image-title-imports.png)\n![](/images/2016/03/image-title-component.png)\n\nComposition is the key point here, we have defined our component with simple code, delegated and composed part of the effect with other component.\n\nAnd each sub-component is doing more work. For instance **TitleBlurMap** is itself another GL component, which uses composes a component **Blur** and apply a threshold to generate a black and white blur map:\n\n![](/images/2016/03/titleblurmap_impl.png)\n![](/images/2016/03/titleblurmap_node_detail.png)\n\nAnd so on! **Blur** is itself another GL component!\nAnd like **BlurV**, it is implementing a 4-pass blur, so it will pipe 4 times a Blur1D component:\n\n![](/images/2016/03/blurstack.png)\n\n**Blur** simply recursively composes Blur1D:\n![](/images/2016/03/blur_impl.png)\n\n> Have I lost you? Don\'t worry, we will show in a few section what the big picture scene looks like.\n\n### <a name="dedup"></a> How gl-react transform your Surface and effects stack\n\nWe have just overviewed how deep a GL effects stack can be: going down into each individual component that itself use many other components can ends a with a pretty big tree. That\'s true for any React application actually, but React is still performant.\n\n**However, we have a fundamental difference between classical React DOM and `gl-react`: a GL effects stack is just a single Canvas element at the end.**\n\n> When you write a tree of GL Components, each component don\'t get append into the DOM like would do a stack of Virtual DOM elements. Instead we need at the end to render the full Virtual GL tree into one single `<canvas/>`.\n\nTherefore, we don\'t treat GL Component the same way React does. `gl-react` will do internal work to **unfold user\'s Virtual GL tree** and convert it into a **"scene" object that contains everything a renderer need to know**. This object is passed as a `"data"` props to the underlying implementation (that we call internally **_GLCanvas_**).\n\nIf we inspect with React Dev Tools what our `<Surface/>` actually gets render into you will see something like this:\n\n![](/images/2016/03/resolved_rendering.png)\n\nActually, the `Surface` get rendered into a... `<div/>` **(1)**. We need to do this because we need to not only render the Canvas **(3)** but we also need to render any possible content that was passed-in the stack that would need to get rasterized (in web context, it can be a **video** or another **canvas**). In our case, it\'s the `<Title/>` component, that is backed with **react-canvas** to draw Text using a Canvas (the only simple way to get texts in WebGL). So this is why we need **(2)**, that is a container for the content, that container is moved behind the canvas and is made invisible (unless you enable some hidden secret props! [read more about advanced props of Surface in the documentation](https://projectseptemberinc.gitbooks.io/gl-react/content/docs/api/Surface.html)).\n\n### How gl-react optimizes the effects stack & factorize computation\n\nThe previous complex example, if implemented na\xefvely, ends up with this big tree:\n\n**1. Before factorization optimization:** _(na\xefve implementation)_\n![](/images/2016/03/reactjs2016_greweb.036.jpeg)\n\nIt contains a lot of duplicates: the Title rendering appears 6 times\nand the "Text Blurring 4-Blur stack" also appears 5 times.\n\nThis is just computing the same thing multiple times where we should be able to compute it once...\n\nTo solve this, we will just use the VDOM **referential transparency**: if 2 VDOM element have the same reference, we can assume it renders the same thing so we can just dedupe to share and render it once.\n\n> This is one of our biggest innovation in `gl-react`: when you give a stack of effects in Surface, we will dedupe the tree.\n\nAt the end of this process our example results of:\n\n**2. After factorization optimization:**\n![](/images/2016/03/reactjs2016_greweb.041.jpeg)\n\nWe have moved from 38 to 13 nodes and reduce the render speed from 20ms to 4ms.\n\n### Conclusion\n\nIf you would implement a stack of effects using the imperative OpenGL API, you would obviously write an ordered sequence of effects to do and that would naturally share the computations in temporary buffers for best performance.\n\n**The important job of gl-react is to allow you to write descriptive code without losing this advantage of using temporary pixel buffers and keeping a thin layer on top of the underlying OpenGL.**\n\n## Other side projects\n\n### gl-react-inspector\n\nOne of the most appreciated part in my talk is the Inspector we specially develop for gl-react.\n\nI initially developed it because I wanted to have charts to show people what gl-react graph looks like and without having to go Inkscape and handcrafting them...\nBut it ended up behind a useful tool to actually develop with, because you can see what\'s going on underneath (at each node step, and what the texture looks at intermediary steps). It also helps seeing investigating on performance.\n\nOur big future challenge with this is to make it work as a standalone devtools (I imagine it could be part of the React devtools, if we could have plugins there).\nand to make it work with React Native too.\n\n### gl-react-dom-static-container\n\n[https://github.com/gre/gl-react-dom-static-container](https://github.com/gre/gl-react-dom-static-container)\n\n### Some universal GL effects\n\n- [gl-react-blur][gl-react-blur]\n- [gl-react-negative][gl-react-negative]\n- [gl-react-constrast-saturation-brightness][gl-react-constrast-saturation-brightness]\n- [gl-react-hue-rotate][gl-react-hue-rotate]\n- [gl-react-color-matrix][gl-react-color-matrix]\n\n### gl-react-image\n\n[gl-react-image](https://github.com/gre/gl-react-image) is a component that solves preserving ratios of your images (because stretching is the default behavior).\n\n## We need your help!\n\n### What should come soon\n\n- caching framebuffers from one frame to another: allow different interesting things: cache part of the graph (e.g to allow to cache a static intensive part of the graph), cache part of a rendering with `discard;` (e.g if you make a Paint like) or even more crazy things like being able to inject the previous buffer as a texture to implement things like motion-blur or even [cellular automata](http://mathworld.wolfram.com/CellularAutomaton.html).\n\n### What might come after this\n\n- react-native-video / react-native-camera\n- static vertex data as well as static vertex shader is a current and decided (? chosen) limitation of `gl-react`. We want to focus on the incredible capabilities of fragment shaders and work on all optimization that can be made to improve the performance of working with this subset of OpenGL.\n\n### Other features\n\nThis library begin the journey of bringing OpenGL to most people using the React simplicity, hiding some complex parts of OpenGL but allowing to implement the fundamental functional bricks of it.\n\nThere are a bunch of other features that would take me weeks to explain, but feel free to [read the documentation to learn more about the other props and features](https://projectseptemberinc.gitbooks.io/gl-react/content/).\n'},WEXz:function(e,n,t){"use strict";t.r(n),n.default=""},WuK3:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Parametric brush"\nthumbnail: "/images/plots/127.jpg"\ndescription: "another parametric plotted with a brush pen and \'Bloody Brexit\' ink by Diamine."\ntags:\n  - parametric\n  - brush\n---\n\nanother parametric plotted with a brush pen and \'Bloody Brexit\' ink by Diamine.\n'},"X+87":function(e,n,t){"use strict";(function(e){const a=t("cKX6"),i=t("7104");n.define=function(e,n,t){Reflect.defineProperty(e,n,{enumerable:!1,configurable:!0,writable:!0,value:t})},n.isBuffer=function(e){return"buffer"===i(e)},n.isObject=function(e){return"object"===i(e)},n.toBuffer=function(n){return"string"===typeof n?e.from(n):n},n.toString=function(e){if(n.isBuffer(e))return a(String(e));if("string"!==typeof e)throw new TypeError("expected input to be a string or buffer");return a(e)},n.arrayify=function(e){return e?Array.isArray(e)?e:[e]:[]},n.startsWith=function(e,n,t){return"number"!==typeof t&&(t=n.length),e.slice(0,t)===n}}).call(this,t("HDXh").Buffer)},X4ni:function(e,n,t){"use strict";t.r(n),n.default="---\nthumbnail: /images/plots/107.jpg\ntweet: https://twitter.com/greweb/status/1383309202823680006\ntags:\n  - lines\n---\n"},X8lm:function(e,n,t){"use strict";t.r(n),n.default=""},XA8f:function(e,n,t){"use strict";t.r(n),n.default=""},XCGq:function(e,n,t){"use strict";function a(e,n){Error.call(this),this.name="YAMLException",this.reason=e,this.mark=n,this.message=(this.reason||"(unknown reason)")+(this.mark?" "+this.mark.toString():""),Error.captureStackTrace?Error.captureStackTrace(this,this.constructor):this.stack=(new Error).stack||""}a.prototype=Object.create(Error.prototype),a.prototype.constructor=a,a.prototype.toString=function(e){var n=this.name+": ";return n+=this.reason||"(unknown reason)",!e&&this.mark&&(n+=" "+this.mark.toString()),n},e.exports=a},XQEI:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Growing parametric"\ndescription: "stacking multiple parametric functions, fountain pen with \'Bloody Brexit\' ink which produces an interesting reflection. A4 bristol."\nthumbnail: /images/plots/111.jpg\ntags:\n  - parametric\n---\n\nParametric functions are classical entities that i\'ve explored many times (from first day!)...\n\n- ...in classical forms: [plot#001](/plots/001), [plot#003](/plots/003), [plot#007](/plots/007), [plot#013](/plots/013), [plot#038](/plots/038), [plot#096](/plots/096), [plot#096](/plots/096),...\n- ... in more funky forms: [plot#071](/plots/071), [plot#073](/plots/073), [plot#080](/plots/080), [plot#082](/plots/082), [plot#084](/plots/084), [plot#087](/plots/087), [plot#095](/plots/095), [plot#090](/plots/090), [plot#097](/plots/097),...\n\nThis is however the first time I think about stacking parametic functions: It might not be very perceptible but it is basically 150 parametric functions projected on different scales. The idea comes a bit from the "Planet holes" idea ([plot#100](/plots/100)), circles with different radius.\n\nI might not have taken the best parametric for this plot but it\'s still fun. Indeed, the pen digged a bit too much in the paper and I might try again with other parametric functions in future.\n\nThe ink used is "Bloody Brexit" by Diamine, like on [plot#109](/plots/109), which produces interesting reflection in combination with a good paper (A4 Canson 250g/mm Bristol) and lamp.\n\n<img src="/images/plots/bloodybrexit.jpg" width="100%" />\n'},XWFM:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Introducing gl-react\'\ndescription: \'This presentation is an introduction to WebGL in React and functional programming concept and showcases made with gl-react and gl-react-native\'\nthumbnail: \'/images/2015/10/funrendering.png\'\nauthor: Gaetan\nlayout: post\ntags:\n - gl-react\n---\n\n<img src="/images/2015/10/gl-react.png" alt="" class="thumbnail-left" /> Last Thursday, my talk at [React Paris Meetup](http://www.meetup.com/ReactJS-Paris/events/226103821/) was about using **the functional rendering** paradigm of **WebGL** in **React**. The library [`gl-react`](https://github.com/ProjectSeptemberInc/gl-react) wraps WebGL in React paradigm with a focus for developing 2D effects, that we need in my current startup, [Project September](https://twitter.com/ProjSeptEng), where I have the chance to develop it.\n\n## [Slides](http://greweb.me/reactmeetup7)\n\n<iframe src="http://greweb.me/reactmeetup7" width="600" height="400" frameborder="0"></iframe>\n\n\x3c!--more--\x3e\n\n## Abstract\n\nWe can write effects without having to learn the complex and imperative low-level WebGL API but instead composing React components, as simple as functional composition, using VDOM descriptive paradigm.\n\n[gl-react](https://github.com/ProjectSeptemberInc/gl-react) brings WebGL bindings for react to implement complex effects over content.\n\n[gl-react-native](https://github.com/ProjectSeptemberInc/gl-react-native) is the React Native implementation,\ntherefore allows universal effects to be written both for web and native.\n\nThese libraries totally hides for you the complexity of using the OpenGL/WebGL API but takes the best part of it: GLSL, which is a "functional rendering" language that runs on GPU.\n'},Xhx1:function(e,n,t){"use strict";t.r(n),n.default=""},Xq5V:function(e,n,t){"use strict";var a=t("NdRM"),i=Object.prototype.hasOwnProperty;e.exports=new a("tag:yaml.org,2002:set",{kind:"mapping",resolve:function(e){if(null===e)return!0;var n,t=e;for(n in t)if(i.call(t,n)&&null!==t[n])return!1;return!0},construct:function(e){return null!==e?e:{}}})},Xwm2:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "packing squares in triangles"\nthumbnail: /images/plots/182.jpg\ndescription: "Continuing my geometry minimalism series. This time, packing squares in triangles. Black fountain pen on 300g/m paper."\ntags:\n  - shape-packing\n---\n\nContinuing my geometry minimalism series. This time, packing squares in triangles. Black fountain pen on 300g/m paper.'},Y2Co:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Turquoise trispiral"\nthumbnail: /images/plots/132.jpg\ndescription: "A stable parametric spiral transition. Fountain Pen and Turquoise ink on Bristol A4."\ntags:\n  - parametric\n---\n\nA stable parametric spiral transition. Fountain Pen and Turquoise ink on Bristol A4.\n'},Y3sZ:function(e,n,t){"use strict";t.r(n),n.default=""},Y5WS:function(e,n,t){"use strict";t.r(n),n.default=""},YJCK:function(e,n,t){"use strict";var a=t("3rKx");e.exports=a.DEFAULT=new a({include:[t("EOT6")],explicit:[t("zAwM"),t("EGKs"),t("YQPJ")]})},YP5u:function(e,n,t){"use strict";n.a={title:"greweb.me",description:"Ga\xebtan Renaudeau (greweb). French developer at Ledger. creative coder experimenting with GLSL shaders, Rust, and fountain pens robot plots. infinite noise explorer.",thumbnail:"/profile.jpg",thumbnailDomain:"http://greweb.me",siteDomain:"https://greweb.me",social:[{id:"twitter",url:"https://twitter.com/greweb",icon:"/icons/twitter.svg",text:"@greweb"},{id:"instagram",url:"https://instagram.com/greweb",icon:"/icons/instagram.svg",text:"greweb"},{id:"github",url:"https://github.com/gre",icon:"/icons/github.svg",text:"gre"},{id:"twitch",url:"https://twitch.tv/greweb",icon:"/icons/twitch.svg",text:"greweb"},{id:"itch.io",url:"https://greweb.itch.io",icon:"/icons/iconmonstr-gamepad-3.svg",text:"greweb.itch.io"},{id:"hicetnunc",url:"https://hic.link/greweb",icon:"/icons/hic.svg",text:"hic.link/greweb"}]}},YQPJ:function(e,n,t){"use strict";var a;try{a=t("+U4B")}catch(o){"undefined"!==typeof window&&(a=window.esprima)}var i=t("NdRM");e.exports=new i("tag:yaml.org,2002:js/function",{kind:"scalar",resolve:function(e){if(null===e)return!1;try{var n="("+e+")",t=a.parse(n,{range:!0});return"Program"===t.type&&1===t.body.length&&"ExpressionStatement"===t.body[0].type&&("ArrowFunctionExpression"===t.body[0].expression.type||"FunctionExpression"===t.body[0].expression.type)}catch(i){return!1}},construct:function(e){var n,t="("+e+")",i=a.parse(t,{range:!0}),o=[];if("Program"!==i.type||1!==i.body.length||"ExpressionStatement"!==i.body[0].type||"ArrowFunctionExpression"!==i.body[0].expression.type&&"FunctionExpression"!==i.body[0].expression.type)throw new Error("Failed to resolve function");return i.body[0].expression.params.forEach((function(e){o.push(e.name)})),n=i.body[0].expression.body.range,"BlockStatement"===i.body[0].expression.body.type?new Function(o,t.slice(n[0]+1,n[1]-1)):new Function(o,"return "+t.slice(n[0],n[1]))},predicate:function(e){return"[object Function]"===Object.prototype.toString.call(e)},represent:function(e){return e.toString()}})},YZnb:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Elevation glitch"\nthumbnail: /images/plots/194.jpg\ndescription: "Usage of different harmonies of noise to reveal glitches. Various noise experiments and inks."\n---\n\nUsage of different harmonies of noise to reveal glitches. Various noise experiments and inks.\n\n<img width="100%" src="/images/plots/194zoom.jpg">\n\n<img width="100%" src="/images/plots/194b.jpg">\n\n<img width="100%" src="/images/plots/194c.jpg">\n'},Ycaf:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Triangle planet"\nthumbnail: /images/plots/116.jpg\ndescription: "Exploration of perlin noise triangle planets. various fountain pen on A4 bristol."\ntags:\n  - parametric\n  - perlin\n  - planet\n---\n\n**Exploration of perlin noise triangle planets. various fountain pen on A4 bristol.**\n\nThese are taking almost one hour to plot, with 2 passes of 2 different spirals. Each spiral varies a bit with different offset and displacement noise which creates a desired effect of bolder areas, caveats and craters.\n\nThe displacement noise is a simple perlin noise, only one harmony is used but the noise is split into two 2 different perlin noises: the angle noise (like a vector field, different angle of displacement) and the amplitude noise (how much does the displacement move the point).\n\nThe triangle is made with a parametric function, reusing technique explored on [plot#114](/plots/114).\nThere is an important effort on finding a good balance between noise and distribution of lines (it\'s not linear, it\'s closer on edges).\n'},YkbE:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "2-step flowers"\nthumbnail: /images/plots/145.jpg\ndescription: "A similar flower as in plot#123 but with 2 steps themself split into 2 steps and different spiral amplitude. Sakura pens on Black card."\ntags:\n  - parametric\n---\n\n\nA similar flower as in [plot#123](/plots/123) but with 2 steps themself split into 2 steps and different spiral amplitude. Sakura pens on Black card.'},ZKtb:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Frequency Modulation (FM) with Web Audio API\'\ndescription: \'\'\nauthor: Gaetan\nlayout: post\ntags:\n - fm\n - audio\n---\n\n [zoundarticle]: /2013/07/zound-live/\n [zoundrepo]: http://github.com/gre/zound-live/\n [zoundfm]: https://github.com/gre/zound-live/blob/master/app/assets/javascripts/modules/SimpleFM.js\n [fmwiki]: http://en.wikipedia.org/wiki/Frequency_modulation_synthesis\n\nThe main principle of [Frequency Modulation (FM)][fmwiki] is to **pipe an Oscillator (the Modulator)\ninto the frequency of another Oscillator (the Carrier)**.\n\nThis article will explain to you how FM Synthesis works with **interactive demos**.\nIn the meantime, all demos are implemented with the brand new **Web Audio API**,\nso feel free to hack the code for your own purpose.\n\nThis article will also introduce some Audio concepts like **LFO**, **Envelope** and **Finetuning**.\n\nI\'ve recently implemented a very first FM in [ZOUND live][zoundarticle] - *a HTML5 collaborative audio tracker*,\ngiving much more powerful Synthesizers (see in the following video).\n\n<iframe width="640" height="480" src="//www.youtube.com/embed/El4JvaDWQUM" frameborder="0" allowfullscreen></iframe>\n[*(here is the implementation of that FM)*][zoundfm]\n\n\n\x3c!--more--\x3e\n\n## Dive into Frequency Modulation Synthesis\n\nAs mentioned previously, FM is about **piping an Oscillator (the <u>Modulator</u>) into the frequency of another Oscillator (the <u>Carrier</u>)**.\n\nThe Modulator oscillation only affects the oscillation frequency of the Carrier but is not directly an audio signal.\n\n![](/images/2013/08/fm_principle.png)\n\nThe result of that modulation differs depending on each oscillator **frequency** and **amplitude**:\n\n[![](/images/2013/08/Frequencymodulationdemo-td.png)](http://en.wikipedia.org/wiki/File:Frequencymodulationdemo-td.png)\n\n***N.B.*** *Our interactive demos in this article will always play a sound and visualize it (waveform / spectrum analyzer).\nYou will have different kind of controls depending on each specific aspect I want to illustrate.*\n\n*The demos should work on Chrome. __However if you get an AudioContext failure, please reload the page__ (you may not be able to start them all in one row).*\n\n### LFO\n\n**Low-Frequency Oscillation (LFO)** is very used in electronic music for making rythmic audio effects.\n\nLFO is simply a specific subset of a oscillator in a sense that **its oscilation frequency is under\nthe human audible range (20 Hz)** and is then not generally used as an audio signal but as an effect controller.\n\nFor instance the frequency / the amplitude of an oscillator, or in the following example the frequency of the cut-off filter:\n\n<audio src="http://upload.wikimedia.org/wikipedia/commons/e/e4/Lfo-cutoff-frequency-wobble-bass.ogg" controls></audio>\n\nNow, as a first demo,\nlet\'s see what happens if our **FM Modulator is an LFO**,\n*(i.e. if that Modulator is in low frequency range)*.\n\n<iframe width="100%" height="310" src="http://fiddle.jshell.net/FvnJx/58/show/light/" allowfullscreen="allowfullscreen" frameborder="0"></iframe>\n<a href="http://jsfiddle.net/FvnJx/58/" target="_blank" style="display: block; text-align: right">Open on jsfiddle</a>\n\nObserve in the Carrier graphs how **the waveform is regulary compressed and decompressed**. If you increase the Modulator frequency, it will speed up this effect. A real FM is about speeding up that effect up to the audible range...\n\n***N.B.*** *With _Web Audio API_ (more generally with any modular synthesizers) we can easily control any module parameter with an LFO:*\n\n```javascript\nlfo.connect(carrier.frequency);\n```\n\n#### Modulator in audible range\n\nNow, if we increase the frequency to the hearing range, here is what happens:\n*(in that example you can also change the Carrier frequency)*\n\n<iframe width="100%" height="310" src="http://fiddle.jshell.net/x4CWR/36/show/light/" allowfullscreen="allowfullscreen" frameborder="0"></iframe>\n<a href="http://jsfiddle.net/x4CWR/36/" target="_blank" style="display: block; text-align: right">Open on jsfiddle</a>\n\n\nIt\'s as if that **once the Modulator reaches that audible barrier, it kind of becomes a second audible synthesizer**,\neven if it only modulate the frequency of the actual synthesizer.\nHowever, it\'s completely different than playing the two synthesizers directly into the output,\nagain the modulator influence the frequency of the carrier and is not directly piped into the output audio signal.\n\n*There is especially cool sound produced when the Modulator frequency is closed to the Carrier frequency. For more infos, see the <u>Finetuning</u> section.*\n\n\n### Frequency ratios: harmonic or dissonant sounds\n\nOne thing you may also have notice in the previous example is that most of the generated sounds was quite dissonant, non harmonic.\n\nNow, if we add more restrictions and only **snap the possible modulator frequencies**\nto a **multiple of the carrier frequency**, here is what happens:\n\n<iframe width="100%" height="310" src="http://fiddle.jshell.net/Euezv/17/show/light/" allowfullscreen="allowfullscreen" frameborder="0"></iframe>\n<a href="http://jsfiddle.net/Euezv/17/" target="_blank" style="display: block; text-align: right">Open on jsfiddle</a>\n\nThis harmonic result is due a simple fact in music: **Mutiplying a note frequency by 2 is equivalent to Increasing that note by one octave,** meaning the note has the same tone but is one-octave higher. (and vice versa for the division). *BTW, you may have noticed that fact by repetition of peaks in the previous example Spectrum Visualization.*\n\nNow we can release some restrictions by also allowing frequencies multiple of `carrier frequency / 4`, which means allowing to increase/decrease by an **octave**, a **semi-octave** or a **quarter-of-octave**.\n\n<iframe width="100%" height="310" src="http://fiddle.jshell.net/DFSwN/13/show/light/" allowfullscreen="allowfullscreen" frameborder="0"></iframe>\n<a href="http://jsfiddle.net/DFSwN/13/" target="_blank" style="display: block; text-align: right">Open on jsfiddle</a>\n\n\n*Eventually you could even allow more freedom using multiple of `carrier freq / 12`, because an octave is equally divided by 12 in the [Chromatic scale](http://en.wikipedia.org/wiki/Chromatic_scale).*\n\n### Mixing the power of the Modulator effect\n\nA very interesting part of the job is also to change the **amplitude of the modulator**. So far, we used a full amplitude modulating the carrier frequency from 0 to 2-times its original frequency which produces a quite rough sound.\n\nTry to change the modulator amplitude on the following demo:\n\n<iframe width="100%" height="310" src="http://fiddle.jshell.net/DAT5S/12/show/light/" allowfullscreen="allowfullscreen" frameborder="0"></iframe>\n<a href="http://jsfiddle.net/DAT5S/12/" target="_blank" style="display: block; text-align: right">Open on jsfiddle</a>\n\nTechnically, we can easily control that range to any by changing the gain of the Modulator with a `GainNode` which is just a tool to scale the amplitude of a signal.\n\n### Envelope\n\nNow, we need to add an **Envelope** for automating that amplitude change you just experiment with.\n\nAn envelope in electronic music will generally look like this:\n\n[![](/images/2013/08/500px-ADSR_parameter.svg.png)](http://en.wikipedia.org/wiki/File:ADSR_parameter.svg)\n\nAn Envelope corresponds to a **note lifespan**.\nIt is the minimum required for making our Synth.\n\nWe will generally **automate that amplitude through time for each note triggered**.\n\nHere is a demo.\nPlay, try to hold and release a note (using the Play button or SPACE), and observe how the Spectrum Analyzer is moving:\n\n<iframe width="100%" height="400" src="http://fiddle.jshell.net/tyEKr/32/show/light/" allowfullscreen="allowfullscreen" frameborder="0"></iframe>\n<a href="http://jsfiddle.net/tyEKr/32/" target="_blank" style="display: block; text-align: right">Open on jsfiddle</a>\n\n**Two different envelopes** has been used: one for the **Modulator** and one for the **Carrier** which produce **different sound effects in a note lifespan**.\n\n*We won\'t make an interactive demo for changing these envelope parameters,\nbut you can try them in the ZOUND project (or see again the video).*\n\n### Finetuning\n\nAnother interesting effect occurs **when the frequency of the Modulator is very close to the frequency of the Carrier**.\nIn the following example, we have set both oscillators to the same frequency but we expose a "detune" parameter which allows to change a bit the frequency of the Modulator.\n\n<iframe width="100%" height="400" src="http://fiddle.jshell.net/X95S6/10/show/light/" allowfullscreen="allowfullscreen" frameborder="0"></iframe>\n<a href="http://jsfiddle.net/X95S6/10/" target="_blank" style="display: block; text-align: right">Open on jsfiddle</a>\n\nYou can slightly notice that a sound is regulary looping like if it was an LFO effect. You can also visualize it on the graph.\n\nThis effect corresponds to the **[phase](http://tinyurl.com/nzkus8) change between both oscillators**: it regulary change from **"in-phase"** state (where it have exactly the same sine waveform at the same time) to a desynchronize **"out-of-phase"** (because of the small detune), and then slightly go to the next "in-phase" step. More the frequencies are close, more it takes time to oscillate from phase to phase.\n\nThis effect is especially awesome when you start mixing multiple synths together and finetune a bit each one so they don\'t sound exactly on the same frequency.\n\n### Modulating the Modulator\n\nThere is so much more possibilites to play with,\nfor instance, the previously introduced Envelope could be mixed\nwith an LFO to change the Modulator effect in a rythm,\nbut now let\'s see how we can...\n\n**...modulate the modulator!**\n\nEventually we can make a stack of modulators and use different kind of waveforms\nfor more powerful effects:\n\n![](/images/2013/08/fm_multiple.png)\n\n> Be careful when playing with stack of modulators, it is quite easy to have saturated or noisy sounds.\n\nAs an example, I made this experiment which randomly takes different frequencies and amplitude for a stack of 5 modulators:\n\n[**-> http://jsfiddle.net/s2MMR/45/ <-**](http://jsfiddle.net/s2MMR/45/)\n\nCareful! this experiment is a bit crazy! but it shows how different patterns can be when playing with FM.\n\n\x3c!-- TODO soon...\n## Last demo, polished FMs playing a famous song...\n\nAs a last demo example, and in a more readable & simple code, here is a polished example of FM.\n--\x3e\n\n----\n\nAlso, **If you are interested by ZOUND live, [fork it on Github][zoundrepo].**\n'},ZMnA:function(e,n,t){"use strict";t.r(n),n.default=""},ZYYP:function(e,n,t){"use strict";t.r(n),n.default=""},ZwJn:function(e,n,t){"use strict";t.r(n),t.d(n,"getAllPosts",(function(){return u})),t.d(n,"getPost",(function(){return h}));var a=t("cpVT"),i=t("hb5E"),o=t.n(i),r=t("DlQD"),s=t.n(r);function l(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function c(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?l(Object(t),!0).forEach((function(n){Object(a.a)(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}async function u(){const e=t("yPMl"),n=[];for(const a of e.keys()){const e=a.slice(2),i=e.match(/^(\d+)-(\d+)-(\d+)-(.*).md$/);if(!i)continue;const[,r,s,l,c]=i,u=await t("fN8t")(`./${e}`),h=o()(u.default);n.push({id:e.replace(".md",""),year:r,month:s,day:l,slug:c,content:h.content,data:h.data})}return n.reverse(),n}async function h(e,n,t){const a=(await u()).find((a=>a.year===e&&a.month===n&&a.slug===t));if(!a)throw new Error("not found");const i=s()(a.content);return c(c({},a),{},{content:i})}},bJea:function(e,n,t){"use strict";t.r(n),n.default=""},bPaa:function(e,n,t){"use strict";t.r(n),n.default=""},bYUS:function(e,n,t){"use strict";t.r(n),n.default=""},c8aL:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: The same game in HTML5 canvas\nthumbnail: /images/2010/same_game_screenshot.png\nauthor: Gaetan\nlayout: post\npermalink: /2010/02/the-same-game-in-html5-canvas/\ntags:\n  - gamedev\n  - canvas\n  - javascript\n---\n\n [2]: http://gre.github.io/same-game\n [3]: http://github.com/gre/same-game\n\nI\'ve made a simple canvas game in **HTML5 Canvas**.\n\n**Canvas is a really great API** which allows to do awesome things combined with **javascript** language. It\u2019s a **standard alternative to Flash** and for that kind of usage, I think it can fairly compete Flash.\n\n![screenshot](/images/2010/same_game_screenshot.png)\n\nYou can test the game in a **recent browser** *(canvas-compatible like firefox, chrome, \u2026)* **following [this link][2]**.\n\nIf you want to **hack the code**, see the javascript [here][3].\n\n\nThe game was simple to code, except maybe the animation managment which require some **optimization perspective**. The code source is still not perfect, I may improve soon.\n\n## Video demonstration\n\n<iframe src="http://player.vimeo.com/video/9606570" width="500" height="375" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>\n\n*Released with the GNU General Public Licence.*\n\n'},cCet:function(e,n,t){"use strict";t.r(n),n.default=""},cKX6:function(e,n,t){"use strict";e.exports=function(e){return"string"===typeof e&&"\ufeff"===e.charAt(0)?e.slice(1):e}},cPD4:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Play Framework \u2013 Enumerator.outputStream"\ndescription: "A few weeks ago, we\u2019ve introduced a new feature in Play Framework: the Enumerator.outputStream method, allowing you to work with Java API requiring an OutputStream to generate content, for instance the java.util.zip API."\nauthor: Gaetan\nlayout: post\npermalink: /2012/11/play-framework-enumerator-outputstream/\ntags:\n  - playframework\n  - iteratee\n---\n\n[1]: https://github.com/playframework/Play20/commit/0f1ec1479e490f2c8af4cd79dd0b6a14b0ea9f75\n[2]: http://www.playframework.org/\n[3]: http://mandubian.com/2012/08/27/understanding-play2-iteratees-for-normal-humans/\n\nA few weeks ago, [we\u2019ve introduced][1] a new feature in [Play Framework][2]: the `Enumerator.outputStream` method, allowing you to work with Java API requiring an `OutputStream` to generate content, for instance the `java.util.zip` API.\n\n**Now, let\u2019s see how easy it is to serve a big Zip generated on-the-fly without memory load with Play Framework.**\n\n\x3c!--more--\x3e\n\n## The Zip generation example\n\n<script src="https://gist.github.com/4058734.js?file=Application.scala"><\/script>\n\nThis demo shows how to **generate a zip file on-the-fly** and directly **stream it** to an HTTP client **without loading it in memory or storing it in a file**.\n\nIt uses an `Enumerator` created with the `Enumerator.outputStream` method.  \nThe `OutputStream` provided by the method is then plugged to the Java\u2019s `ZipOutputStream`.\n\nFor the example, we have generated a zip containing 100 text files, and each text files contains 100\u2019000 random long numbers (yes, 100\u2019000 !).\n\nThe zip size is approximatively 100 Mb. (and is generated in about 3Mb/s in my machine in localhost, but this can be improved)\n\nThe huge benefit of this is the download starts instantly, it means the Zip is streamed while it is generated.\n\n## Show me the code!\n\nInternally, it is implemented with a `Concurrent.unicast`, and a simple implementation of an `OutputStream` pushing into the unicast\u2019s channel:\n\n<script src="https://gist.github.com/4058734.js?file=Enumerator.scala"><\/script>\n\n## About Iteratee and Enumerator\n\nIf you want to learn more about Iteratee concepts in Play Framework, I recommend you [this article][3].\n'},cckB:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "CryptoAliens: Genesis [ethblock.art]"\nthumbnail: "/images/blockstyles/24.png"\ndescription: "CryptoAliens are digital creatures generated from Ethereum blockchain blocks. They can be minted on ethblock.at by anyone, which establishes a limited set of CryptoAliens species. Each block produced on Ethereum have unique elements that can be visualized in creative ways."\ntags:\n  - NFT\n  - shaders\n---\n\n[create]: https://ethblock.art/create/24\n[opensea]: https://opensea.io\n[tech]: /2021/04/cryptoaliens-tech\n\n> See also [CryptoAliens: Genesis, a technical look][tech].\n\n<img src="/images/posts/cryptoaliens/021_px.png" width="50%" /><img src="/images/posts/cryptoaliens/001_px.png" width="50%" />\n\n> CryptoAliens: Genesis establishes the first embryonic species. Which CryptoAliens are you going to chose? Each creature gets born on an Ethereum block that nourishes its shape: transactions, ETH value transferred, gas,... their unique skin comes from Mandelglitch\'s BlockStyle with the same rarity scheme.\n\n## What are CryptoAliens?\n\nCryptoAliens are digital creatures generated from Ethereum blockchain blocks. They can be minted on [ethblock.art][create] by anyone, to establishes a limited set of CryptoAliens species in a decentralized matter. Each block produced on Ethereum have unique elements that can be visualized in creative ways.\n\n<img src="/images/posts/cryptoaliens/014_px.png" width="50%" /><img src="/images/posts/cryptoaliens/017_px.png" width="50%" />\n\n> **CryptoAliens are born and nourished from transactions, transactions are bones, ETH is flesh,... and many other aspects that this article will explain!**\n\n<img src="/images/posts/cryptoaliens/032_px.png" width="50%" /><img src="/images/posts/cryptoaliens/013_px.png" width="50%" />\n\n### So I decide which ones are the CryptoAliens?\n\n**Yes! As a NFT minter, you are the creator and you contribute at establishing the first \'Genesis\' series of CryptoAliens.** You decide which creature deserve to live. You are the curator and it is your responsible to do a lot of research and find the most adorable (or the creepiest?) creature!\n\n<img src="/images/posts/cryptoaliens/036_px.png" width="50%" /><img src="/images/posts/cryptoaliens/004_px.png" width="50%" />\n\n### How many CryptoAliens are there?\n\nEvery single CryptoAliens species is unique and there are currently 12 millions because that\'s as many blocks there are today (April 2021). Every 15 seconds, a new block is minted on Ethereum blockchain (with usually hundreds of transactions in it) making a new CryptoAliens possibility.\nThe block is the DNA, but the creature only starts existing when minted!\n\n**TLDR. CryptoAliens only comes to life when someone mint it as an NFT on the [ethblock.art][create] contract.** They can then be sold and traded on [opensea.io][opensea]. There is **a limited amount of CryptoAliens possible to mint** so be wise at your choice. In this \'Genesis\' series, the current supply is set to 100!\n\n<img src="/images/posts/cryptoaliens/002_px.png" width="50%" /><img src="/images/posts/cryptoaliens/003_px.png" width="50%" />\n\n### What is \'Genesis\' series about?\n\nThe idea of \'Genesis\' is that we are collectively going to create the initial species of this universe (with the NFT we chose to mint).\n\nMinting a _CryptoAliens: Genesis_ specimen is giving birth to the creature, therefore the current NFT is visualized on [ethblock.art][create] as a video tape recording of that time of birth (with the block number, time, weight and number of bones). These data are included in the NFT itself and could be reused in future!\n\n## What determines how a CryptoAliens specimen looks like?\n\nThere are many information contains in Ethereum blocks that will get used to determine the general shape and gives its rarity.\n\n### Block\'s timestamp\n\n<img src="/images/posts/cryptoaliens/040_px.png" width="50%" /><img src="/images/posts/cryptoaliens/041_px.png" width="50%" />\n\nWhen the block happened during UTC night, the visual will be in dark mode.\n\n### Block\'s transactions amount\n\n<img src="/images/posts/cryptoaliens/007_px.png" width="50%" /><img src="/images/posts/cryptoaliens/008_px.png" width="50%" />\n\nWhen a block contains a lot of transactions it will impact its general weight. It will be highlighted by this very heavy blobs shapes. That said, the weight can be more or less dense based on amount of bones and also unique for each CryptoAliens specimen.\n\n### Block\'s heavy transfers in ETH\n\n<img src="/images/posts/cryptoaliens/035_px.png" width="50%" /><img src="/images/posts/cryptoaliens/020_px.png" width="50%" />\n\nAs said in the introduction, "ETH is flesh". Even tho most of the time it will impact the general weight of the creature, when a block contains an expectionally high transfer of Ethereum value, it will be highlighted by a big "head" on the creature. ("head" in doublequote because none of our scientist really figured what is this)\n\n### Block\'s exceptionally low amount of ETH transferred\n\n<img src="/images/posts/cryptoaliens/005_px.png" width="50%" /><img src="/images/posts/cryptoaliens/006_px.png" width="50%" />\n\nOn the contrary, when a block contains almost no ETH transfers, the arms will be very thin. Clearly ETH traders didn\'t nourish enough this poor creature.\n\n### Block\'s important ratio of gas used (vs ETH value transfer)\n\n<img src="/images/posts/cryptoaliens/023_px.png" width="50%" /><img src="/images/posts/cryptoaliens/016_px.png" width="50%" />\n\nIt often appears in combination with the previous criteria, if the ratio `total gas / total eth transfers` is high, meaning that a lot of the ETH is into gas, there will be some blobs at the end of the arms.\n\n### ...and more block rare features\n\nThere are a lot of special cases are rare conditions that can happen. I will not disclose and I will let you discover. Some are really rare and some will be discovered in the future (even the author of blockstyle won\'t be aware of all cases!).\n\n### Block\'s hash\n\nFinally, the block hash gives variety in the results. It\'s necessary in order to have truly unique 12 millions species. But it\'s only complementary to the various other criteria. There are many features that are getting impacted by it, including the skin texturing (see _Mandelglitch BlockStyle_ section).\n\n<img src="/images/posts/cryptoaliens/043_px.png" width="50%" /><img src="/images/posts/cryptoaliens/042_px.png" width="50%" />\n<img src="/images/posts/cryptoaliens/012_px.png" width="50%" /><img src="/images/posts/cryptoaliens/038_px.png" width="50%" />\n\n### What controls does the creator have?\n\nAt creation time, the minter also have the ability to move a bit the specimen:\n\n- `mod1` is a simple rotation around it.\n- `mod2` is a simple climbing and zooming.\n- `mod3` will flex a bit the shape to make it torn & twist a bit.\n- `mod4` have an impact on the color palette scaling.\n\n**On top of this, mods have the ability to transform the skin texturing** which is actually based on [Mandelglitch BlockStyle](https://ethblock.art/create/17)! That means the rarity elements of Mandelglitch are shared in this new BlockStyle.\n\n### mmh, Mandelglitch BlockStyle?\n\n<a href="https://ethblock.art/create/17"><img src="/images/posts/cryptoaliens/mandelglitch.png" width="10%" /></a> **[Mandelglitch](https://ethblock.art/create/17) is a BlockStyle on [ethblock.art](https://ethblock.art/create/17), derived from Mandelbrot fractal.**\n\nThe visibility of Mandelglitch on the skin has been intentionally contained, but sometimes it is more visible. Here are two examples:\n\n<img src="/images/posts/cryptoaliens/031_px.png" width="50%" /><img src="/images/posts/cryptoaliens/022_px.png" width="50%" />\n\n## ...and, What\'s next?\n\nWho knows what\'s next! As everything is available on the blockchain, what you mint is saved immutably and forever. Me or other artists could fork the code ([available on Github](https://github.com/gre/gre/tree/master/blockarts/CryptoAliens)) to make animated version of the CryptoAliens that were chosen (as this code is open source). Also we can imagine doing crossover between species or doing "evolution" of these species over time. Everything is possible!\n\n---\n\nSee also [CryptoAliens: Genesis, a technical look][tech].\n\nMy name is Ga\xebtan Renaudeau, and I\'m a noise explorer. **feel free to ping me on Twitter [@greweb](https://twitter.com/greweb)**\n'},ceB2:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Jumping man spiral"\nthumbnail: /images/plots/163.jpg\ndescription: "Revisit of plot#060 \'Jumping man\' using two fountain pen inks and a spiral fill technique with slight noise."\n---\n\nRevisit of [plot#060](/plots/060) \'Jumping man\' using two fountain pen inks and a spiral fill technique with slight noise.\n\nZoom:\n\n<img src="/images/plots/163zoom.jpg" width="100%">\n'},"cm/u":function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: \"Blue Circle Packing\"\nthumbnail: /images/plots/176.jpg\ndescription: \"My first plot experiment using 'circle packing' technique. More ideas and explorations to come!\"\ntags:\n  - circle-packing\n  - shape-packing\n---\n\nMy first plot experiment using 'circle packing' technique. More ideas and explorations to come!"},"d/gU":function(e,n,t){var a={"./001/README.md":"yCvz","./002/README.md":"bPaa","./003/README.md":"LBVh","./004/README.md":"t+o8","./005/README.md":"Icra","./006/README.md":"Otr/","./007/README.md":"vFoq","./008/README.md":"Y5WS","./009/README.md":"xgUO","./010/README.md":"3XcB","./011/README.md":"xNY0","./012/README.md":"11Sj","./013/README.md":"l4gz","./014/README.md":"eIIq","./015/README.md":"COZH","./016/README.md":"353+","./017/README.md":"Xhx1","./018/README.md":"RHpB","./019/README.md":"88+z","./020/README.md":"GQDz","./021/README.md":"ig9K","./022/README.md":"yF2V","./023/README.md":"ZYYP","./024/README.md":"rEsJ","./025/README.md":"2/YE","./026/README.md":"HGVa","./027/README.md":"uWLs","./028/README.md":"98/W","./029/README.md":"QmdR","./030/README.md":"naOd","./031/README.md":"BHC3","./032/README.md":"AccM","./033/README.md":"fUMH","./034/README.md":"8VEi","./035/README.md":"bJea","./036/README.md":"8pr5","./037/README.md":"TjV/","./038/README.md":"XA8f","./039/README.md":"ABVm","./040/README.md":"5/hP","./041/README.md":"ZMnA","./042/README.md":"zYy3","./043/README.md":"L4qi","./044/README.md":"qn1m","./045/README.md":"Pkmy","./046/README.md":"v2OP","./047/README.md":"QzXX","./048/README.md":"bYUS","./049/README.md":"xi4s","./050/README.md":"X8lm","./051/README.md":"tbEk","./052/README.md":"1Hz/","./053/README.md":"K+gO","./054/README.md":"Da1f","./055/README.md":"+bvG","./056/README.md":"I3+r","./057/README.md":"PdyT","./058/README.md":"Qru/","./059/README.md":"wBBG","./060/README.md":"J8yY","./061/README.md":"9nhf","./062/README.md":"kG1y","./063/README.md":"SqyK","./064/README.md":"WEXz","./065/README.md":"0wZB","./066/README.md":"nrZ5","./067/README.md":"yJmW","./068/README.md":"qVQq","./069/README.md":"CgTJ","./070/README.md":"9x/r","./071/README.md":"uCoZ","./072/README.md":"noTo","./073/README.md":"ADEy","./074/README.md":"See4","./075/README.md":"NSLj","./076/README.md":"T+M9","./077/README.md":"ugXF","./078/README.md":"U+Tf","./079/README.md":"i+J6","./080/README.md":"v9De","./081/README.md":"eqFi","./082/README.md":"7GSA","./083/README.md":"cCet","./084/README.md":"1cPK","./085/README.md":"2SOq","./086/README.md":"NtWT","./087/README.md":"B0EA","./088/README.md":"wLwo","./089/README.md":"H4Wf","./090/README.md":"zWTV","./091/README.md":"jBCP","./092/README.md":"Y3sZ","./093/README.md":"tOsZ","./094/README.md":"6d7H","./095/README.md":"eWTH","./096/README.md":"nQk3","./097/README.md":"6ykQ","./098/README.md":"RXE9","./099/README.md":"JmH0","./100/README.md":"QR/K","./101/README.md":"lZcA","./102/README.md":"yQP0","./103/README.md":"yVRA","./104/README.md":"rgdI","./105/README.md":"0hcx","./106/README.md":"krhY","./107/README.md":"X4ni","./108/README.md":"zaAt","./109/README.md":"z6oG","./110/README.md":"FO6U","./111/README.md":"XQEI","./112/README.md":"f6A/","./113/README.md":"EF3T","./114/README.md":"Bir5","./115/README.md":"vLLl","./116/README.md":"Ycaf","./117/README.md":"/41s","./118/README.md":"gqgv","./119/README.md":"mVQU","./120/README.md":"gTso","./121/README.md":"SsVj","./122/README.md":"Jy1k","./123/README.md":"3yhu","./124/README.md":"jmt2","./125/README.md":"nNS1","./126/README.md":"zEwe","./127/README.md":"WuK3","./128/README.md":"5Tfx","./129/README.md":"QMpp","./130/README.md":"lQeP","./131/README.md":"IceM","./132/README.md":"Y2Co","./133/README.md":"kru4","./134/README.md":"QhJx","./135/README.md":"HpC+","./136/README.md":"duRY","./137/README.md":"T3W9","./138/README.md":"Ekcc","./139/README.md":"0tIW","./140/README.md":"sRRH","./141/README.md":"nSud","./142/README.md":"0RtR","./143/README.md":"JxLd","./144/README.md":"qC5S","./145/README.md":"YkbE","./146/README.md":"E7uD","./147/README.md":"kyr6","./148/README.md":"0dpp","./149/README.md":"Gu2q","./150/README.md":"DQgZ","./151/README.md":"2Xg7","./152/README.md":"J3bC","./153/README.md":"skje","./154/README.md":"jgXF","./155/README.md":"KGBF","./156/README.md":"F4W1","./157/README.md":"mRba","./158/README.md":"1tWJ","./159/README.md":"fzot","./160/README.md":"G0yk","./161/README.md":"K6d5","./162/README.md":"3PTt","./163/README.md":"ceB2","./164/README.md":"u0RZ","./165/README.md":"1hZm","./166/README.md":"4/z1","./167/README.md":"9aUE","./168/README.md":"qPHC","./169/README.md":"Q8dS","./170/README.md":"6oDM","./171/README.md":"liTY","./172/README.md":"/HDy","./173/README.md":"E3sc","./174/README.md":"GOMj","./175/README.md":"RiMv","./176/README.md":"cm/u","./177/README.md":"ppE9","./178/README.md":"g+0Z","./179/README.md":"mFDB","./180/README.md":"9i9n","./181/README.md":"DKqw","./182/README.md":"Xwm2","./183/README.md":"f1D6","./184/README.md":"licy","./185/README.md":"ikex","./186/README.md":"214X","./187/README.md":"Nwz3","./188/README.md":"RuLc","./189/README.md":"sSon","./190/README.md":"rn5Z","./191/README.md":"C+rD","./192/README.md":"GeD1","./193/README.md":"hkxR","./194/README.md":"YZnb","./195/README.md":"6ubZ","./196/README.md":"pV1G"};function i(e){var n=o(e);return t(n)}function o(e){if(!t.o(a,e)){var n=new Error("Cannot find module '"+e+"'");throw n.code="MODULE_NOT_FOUND",n}return a[e]}i.keys=function(){return Object.keys(a)},i.resolve=o,e.exports=i,i.id="d/gU"},dAja:function(e,n,t){"use strict";t.r(n),n.default='---\npublished: false\ntitle: \'Qep4.: Zanimo.js, a promise-based animation library\'\ndescription: \'Zanimo.js, a promise-based animation library\'\nthumbnail: /images/2013/07/zanimo_animation_thumbnail.png\nauthor: Gaetan\nlayout: post\ntags:\n - AWOP\n - javascript\n - promise\n - Q\n - animation\n - library\n---\n\n [0]: /pages/a-world-of-promises/\n [1]: http://t.co/OeSukzxv3F\n [2]: http://github.com/42loops/Zanimo.js\n [3]: http://twitter.com/42loops\n [4]: http://github.com/kriskowal/q\n\n# A [World Of Promises][0], episode 4\n\n<img src="/images/2013/07/zanimo_animation_thumbnail.png" alt="" class="thumbnail-left" style="width: 200px" />\n\n*This fourth article on [Q][1] will introduce [Zanimo.js][2], \na Promisified animation library which helps to chain different\nCSS transitions with only Promises.\nIt is very interoperable with any other Promise library,\nmeaning that you can easily chain Zanimo animations with other asynchronous actions.*\n\n[Zanimo.js][2] is a smooth library developed by [@42loops][3] animation library based on the library [Q][4], a Javascript implementation of Promises.\n\nThis article is an introduction of the concept of Promises in Javascript with the library Q and will show a real use case of it: Promises used on top CSS Transitions to make powerful and efficient DOM animations in Javascript.\n\n\x3c!--more--\x3e\n\n## Zanimo.js\n\nTODO: overview of the library\n\n## Examples\n\n### Recursive tree particle animation\n\n[![tree-particle](/images/2013/05/tree-particle.png)][1]\n\nIt turns out that promise is very good tool for animating any recursive things.\n\nTODO\n'},duRY:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "White Protozoa (8 frames)"\nthumbnail: "/images/plots/136.gif"\ndescription: "8 frames plotted making an animated loop. A 1920p video and A4 physical art is available as an NFT."\ntags:\n  - plotloop\nobjkts:\n  - 82974\n---\n\nHere is "White Protozoa" my third ["plot loop" (see article)](https://greweb.me/2021/05/plot-loops). The main digital art is a 1920p video loop of 8 frames available as a [Tezos hicetnunc NFT](https://www.hicetnunc.xyz/objkt/82974). The physical art is 8 frames of A4 size, plotted with white Sakura gen pen on black card paper (210g), and offered when [buying the NFT](https://www.hicetnunc.xyz/objkt/71006) (8 editions, assigned in buy order).\n\n<img width="100%" src="/images/plots/136zoom.jpg" />\n\nlike in [plot#135](/plots/135), this is an exploration of domain warping and marching squares algorithms.\n\n<img width="100%" src="/images/plots/136full.jpg" />\n\nThe ending of #1 being plotted, speed x5:\n\n<img width="100%" src="/images/plots/136plot.gif" />\n\nIf you like bonus, I had considered many different animations, and they are viewable as GIF (digital black on white) on https://github.com/gre/gre/tree/master/plots/examples/136\n\nYou can also find the full source code, open sourced as 99% of my work. I essentially have a generator of plot loops and I ran it to generate 500 gif and chose among them! It was very hard to decide!\n\nEnjoy!\n'},eFEr:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Qep3.: QanimationFrame\'\ndescription: \'This third article on Q is a little parenthesis to the Qep articles series, featuring the requestAnimationFrame Javascript function and its general usage, and QanimationFrame, its Promisified version used as a "wait for DOM to be ready" API.\'\nthumbnail: /images/2013/07/qanimationframe.jpg\nauthor: Gaetan\nlayout: post\ntags:\n - AWOP\n - javascript\n - promise\n - Q\n - library\n---\n\n [0]: /pages/a-world-of-promises/\n [1]: http://github.com/gre/qanimationframe\n [2]: https://dvcs.w3.org/hg/webperf/raw-file/tip/specs/RequestAnimationFrame/Overview.html\n [3]: http://creativejs.com/resources/requestanimationframe/\n [4]: http://www.paulirish.com/2011/requestanimationframe-for-smart-animating/\n\n# A [World Of Promises][0], episode 3\n\n<img src="/images/2013/07/qanimationframe.jpg" alt="" class="thumbnail-left" style="width: 200px" />\n\n*This third article on [Q][1] is a little parenthesis to the Qep articles series,\nfeaturing the `requestAnimationFrame` Javascript function and its general usage,\nand [QanimationFrame][1], its Promisified version used as a "wait for DOM to be ready" API.*\n\n\x3c!--more--\x3e\n\n## `requestAnimationFrame`\n\n`requestAnimationFrame` is a function which **delays a Javascript function execution to the next browser render frame**.\nIt takes one argument in parameters which is **the function to call on next repaint**.\n*(N.B. there is not anymore a second DOM parameter like a few months ago, see the [spec][2])*\n\n### ...for animation loop\n\n`requestAnimationFrame` helps to easily make a **render loop**:\n\n```javascript\n(function loop(){\n  requestAnimationFrame(loop);\n  render();\n}());\n```\nIn that example, the `render` function can contains any Javascript code which updates\nsome graphics either using Canvas or DOM.\n\nA good practice is to always **compute time-relative** animations and \nnever assume the framerate to be constant.\n\n```javascript\nfunction badRenderFunction() {\n someObject.x += 0.1; // 10 pixels per 100 frame.\n // not so good with non-constant framerate\n}\n```\n\n```javascript\nvar lastTime = Date.now();\nfunction goodRenderFunction() {\n var now = Date.now();\n var delta = now-lastTime; // in milliseconds\n lastTime = now;\n someObject.x += 0.01 * delta; // 10 pixels per second\n // good because function of time\n}\n```\n\nMore information on `requestAnimationFrame` can be found [here][3] or [here][4].\n\n### ...for waiting a DOM update\n\n**We will now focus on another interesting benefit of that function:**\n\nInstead of using `requestAnimationFrame` for a render loop,\n**you can use it only once** in order to **wait for the next DOM update**.\n\nThere is a lot of use-cases where you need to wait for the next DOM update \nand `requestAnimationFrame` is perfect for that.\n\nMost of the code you can see on the internet rely on using a `setTimeout` with an arbitrary time\ngiven in second parameters *(sometimes 30, sometimes 0 !?)*.\nThis is, in my humble opinion, a wrong approach because you will never know if the repaint has \nreally been performed.\n\n## QanimationFrame\n\n`QanimationFrame` is a function which takes a **DOM Element** in parameter and return a \n**Promise of that "ready" DOM element**.\n\n**`QanimationFrame (elt: DOM Element) => Promise[DOM Element]`**\n\n**N.B.:** Even if `requestAnimationFrame` doesn\'t have anymore a second *DOM element* parameter,\nI found it quite cool that you can give it as argument and retrieve it back to manipulate it.\nIt also makes the function more composable because it behaves like an identity Promise function.\nWe will also see benefits when using with other DOM Promise libraries.\n\n### Basic example\n\n```javascript\nvar elt = document.createElement("div");\nelt.innerHTML = "Hello world";\n// wait for the DOM to be ready before using the height\nQanimationFrame(elt).then(function (elt) {\n  console.log("height="+elt.offsetHeight);\n});\n```\n\n### Composability\n\n```javascript\nfunction createDivInBody (html) {\n  var elt = document.createElement("div");\n  elt.innerHTML = html;\n  document.body.appendChild(elt);\n  return elt;\n}\n\nvar height = \nQ.fcall(createDivInBody, "Hello world!<br/>How are you today?")\n .then(QanimationFrame)\n .then(function (elt) {\n   return elt.offsetHeight;\n });\n\nheight.then(function(height){\n  console.log("height is "+height);\n});\n```\n\nThere is of-course a lot of more examples and use-cases of that library.\n\n## Next episode\n\nNext episode is a big one!\n\nWe will introduce you a Promisified animation library called **Zanimo.js** which\nhelps to chain different **CSS transitions with only Promises**.\nIt is very interoperable with any other Promise library,\nmeaning that you can easily chain Zanimo animations with other asynchronous actions.\n'},eIIq:function(e,n,t){"use strict";t.r(n),n.default=""},"eW+f":function(e,n,t){"use strict";var a=t("Ga6R"),i=t("NdRM"),o=new RegExp("^(?:[-+]?(?:0|[1-9][0-9_]*)(?:\\.[0-9_]*)?(?:[eE][-+]?[0-9]+)?|\\.[0-9_]+(?:[eE][-+]?[0-9]+)?|[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\\.[0-9_]*|[-+]?\\.(?:inf|Inf|INF)|\\.(?:nan|NaN|NAN))$");var r=/^[-+]?[0-9]+e/;e.exports=new i("tag:yaml.org,2002:float",{kind:"scalar",resolve:function(e){return null!==e&&!(!o.test(e)||"_"===e[e.length-1])},construct:function(e){var n,t,a,i;return t="-"===(n=e.replace(/_/g,"").toLowerCase())[0]?-1:1,i=[],"+-".indexOf(n[0])>=0&&(n=n.slice(1)),".inf"===n?1===t?Number.POSITIVE_INFINITY:Number.NEGATIVE_INFINITY:".nan"===n?NaN:n.indexOf(":")>=0?(n.split(":").forEach((function(e){i.unshift(parseFloat(e,10))})),n=0,a=1,i.forEach((function(e){n+=e*a,a*=60})),t*n):t*parseFloat(n,10)},predicate:function(e){return"[object Number]"===Object.prototype.toString.call(e)&&(e%1!==0||a.isNegativeZero(e))},represent:function(e,n){var t;if(isNaN(e))switch(n){case"lowercase":return".nan";case"uppercase":return".NAN";case"camelcase":return".NaN"}else if(Number.POSITIVE_INFINITY===e)switch(n){case"lowercase":return".inf";case"uppercase":return".INF";case"camelcase":return".Inf"}else if(Number.NEGATIVE_INFINITY===e)switch(n){case"lowercase":return"-.inf";case"uppercase":return"-.INF";case"camelcase":return"-.Inf"}else if(a.isNegativeZero(e))return"-0.0";return t=e.toString(10),r.test(t)?t.replace("e",".e"):t},defaultStyle:"lowercase"})},eWTH:function(e,n,t){"use strict";t.r(n),n.default=""},eqFi:function(e,n,t){"use strict";t.r(n),n.default=""},etif:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Chart libraries headaches \u2013 finding the best grid step"\ndescription: If you have ever made a chart library in your life, you\u2019ve probably asked yourself how to find the best scale for the grid in order to have nice values to display in the axis.\nthumbnail: /images/2012/02/wrong-chart-scale.png\nauthor: Gaetan\nlayout: post\npermalink: /2012/03/chart-libraries-headaches-finding-the-best-grid-step/\ntags:\n  - javascript\n  - math\n---\n\n#\n\n<img src="/images/2012/02/wrong-chart-scale.png" class="thumbnail-left" />\n\nIf you have ever made a chart library in your life, you\u2019ve probably asked yourself how to find the best scale for the grid in order to have **nice values to display in the axis**.\n\nMost of the time, **data ranges are unknown**, hence we need to **adapt the grid step** to provide the best display.\n\n## Check this out\n\n<iframe src="/demo/grid-utils/" frameborder="0" width="525" height="140"></iframe>\n\nLet\u2019s explain the algorithm\u2026\n\n\x3c!--more--\x3e\n\n## About scientific notation\n\nAny number can be formatted in scientific notation. It is written in the form of **A x 10N** and is noted **AeN**.\n\nFor instance, 2300 becomes **2.3e3** (because 2300 = 2.3 x 103), 12 becomes **1.2e1**, and 0.23 becomes **2.3e-1**.\n\nScientific notation is exactly made for **displaying huge or tiny values in a few characters**.  \nWe can use the same principle for finding good values for the step scale, we can just **keep the pow of 10** part (**N**) and **round the value part** (**A**).\n\n## Magic numbers\n\nBut **rounding is not enough**, I have found that good pattern numbers of step range is those divisible by 2, 5 and 10.\n\nIn math term, we need to find a step range _sr_, where\n\n```\n\u2200 n \u2208 |N, \u2200 a \u2208 {1, 2, 5}, \u2203 sr, sr = a x 10^n\n```\n\nThis is basically because 2 x 5 = 10 : using a step of 5 we have a 10 modularity every 2 step, and, using a step of 2 we have a 10 modularity every 5 step.\n\n** 2 step:** 0 2 4 6 8 **10** 12 14 16 18 **20** \u2026  \n** 5 step:** 0 5 **10** 15 **20** 25 **30** 35 **40** 45 \u2026  \n**10 step:** **0 10 20 30 40 50 60 70 80 90** \u2026\n\nFor any dataset, we need to fallback on the closest step range in all of possible step ranges: \u2026 0.002, 0.02, 0.2, 2, 20, 200, \u2026, \u2026 0.005, 0.05, 0.5, 5, 50, 500, \u2026, and \u2026 0.001, 0.01, 0.1, 1, 10, 100, \u2026,\n\n### Calculate the pow of 10\n\nTo get the **N** value of the **A x 10N** form, we can use the log of 10:\n\n```javascript\nN = Math.log(number) / Math.log(10);\n```\n\n### Calculate the value modulo 10\n\nTo get the **A** value of the **A x 10N** form, we can just divide the number by **10N**:\n\n```javascript\nA = number / Math.pow(10, N);\n```\n\n### \u2018Rounding\u2019 the number\n\nWe know just need to change the value of **A** and make it more \u201creadable\u201d.  \nWe can map the value as follow:\n\n```\nif A \u2208 [0, 1.5[ then A becomes 1\nif A \u2208 [1.5, 3.5[ then A becomes 2\nif A \u2208 [3.5, 7.5[ then A becomes 5\nif A \u2208 [7.5, 10[ then A becomes 10\n```\n\nNote that these rules may probably be improved, I would love if someone could improve this (because I use a arithmetic mean approach and it should probably be arithmetic).\n\n## Implementation\n\n### Scala\n\n<script src="https://gist.github.com/1987311.js?file=GridUtils.scala"><\/script>\n\n### Javascript\n\n<script src="https://gist.github.com/1987311.js?file=GridUtils.js"><\/script>\n\n**Usage example:**\n\n```javascript\nGridUtils.findNiceRoundStep(xMax, 10);\n```\n\nwhere _xMax_ is the scale of the axis, and _10_ is the desired number of graduation split.\n\n## Conclusion\n\nFinding the best grid step is finally a simple thing to implement but is an essential feature every chart libraries should have.\n'},f1D6:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "packing squares in circles"\nthumbnail: /images/plots/183.jpg\ndescription: "Packing many squares in circles. Black fountain pein on watercolor 300g/m paper."\ntags:\n  - shape-packing\n---\n\nPacking many squares in circles. Black fountain pein on watercolor 300g/m paper.'},"f6A/":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Pink fibers"\nthumbnail: /images/plots/112.jpg\ntags:\n  - fibers\n---\n\nThis is a continuation of exploration started at [plot#109](/plots/109).\nThere is an increase amount of perlin noise and a subtle use of two different ink tones: "Pink Glitz" and "Red Dragoon" by Diamine. Fountain pens on A4 bristol card.\n'},fN8t:function(e,n,t){var a={"./":"ZwJn","./2010-02-03-tutoriel-canvas-realiser-une-banniere-animee-en-quelques-lignes-de-code.md":"BHSx","./2010-02-20-the-same-game-in-html5-canvas.md":"c8aL","./2010-03-14-sass-levolution-du-css.md":"Ogqt","./2010-04-03-realiser-une-maquette-web-avec-le-css-3.md":"h8Le","./2010-04-04-automatiser-lexportation-dun-site-statique-avec-wget.md":"PjKD","./2010-05-05-css3-transitions-available-on-firefox-3-7.md":"6Q0G","./2011-01-05-how-to-make-dlink-dwa-140-perfectly-work-on-linux.md":"grKd","./2011-03-12-html-canvas-pour-les-neophytes.md":"k1ej","./2011-04-24-releasing-same-game-gravity-android.md":"nlun","./2011-06-01-automating-web-app-development-for-multiple-platforms.md":"side","./2011-07-12-same-game-gravity-for-ipad-iphone-android-facebook-chrome-and-web.md":"vDz1","./2011-07-12-same-game-gravity-technical-notes.md":"2VMy","./2011-07-30-improve-your-web-navigation-experience-flexible-nav-jquery-library.md":"3SEp","./2011-10-15-how-to-deploy-your-play-applications-on-archlinux-with-daemons.md":"pPTr","./2012-02-04-css-selector-based-templating-example-with-javascript.md":"ieJe","./2012-02-29-bezier-curve-based-easing-functions-from-concept-to-implementation.md":"niBl","./2012-03-06-chart-libraries-headaches-finding-the-best-grid-step.md":"etif","./2012-03-12-30-minutes-to-make-a-multi-user-real-time-paint-with-play-2-framework-canvas-and-websocket.md":"p5BC","./2012-03-17-play-painter-how-ive-improved-the-30-minutes-prototyped-version.md":"kHt+","./2012-04-09-blender-as-a-2d-game-map-editor-proof-of-concept.md":"96bJ","./2012-04-26-work-in-progress.md":"DpoN","./2012-05-03-html5-canvas-as-a-color-converter.md":"ufYd","./2012-05-10-illuminated-js-2d-lights-and-shadows-rendering-engine-for-html5-applications.md":"2bZF","./2012-05-12-minimize-your-javascript-files-with-curl.md":"4EJ6","./2012-07-03-how-i-learned-backbone-js-three-js-glsl-in-one-week.md":"uWG4","./2012-08-01-zound-a-playframework-2-audio-streaming-experiment-using-iteratees.md":"jxws","./2012-11-12-play-framework-enumerator-outputstream.md":"cPD4","./2013-01-10-be-careful-with-js-numbers.md":"wfFZ","./2013-01-30-playcli-play-iteratees-unix-pipe.md":"91iZ","./2013-02-11-glsl-js-a-javascript-glsl-library-dry-efficient.md":"1UPy","./2013-05-07-playframework-simple-deployment-scripts.md":"pjVY","./2013-07-10-q-a-promise-library.md":"jCcY","./2013-07-13-deferred.md":"wdUm","./2013-07-17-QanimationFrame.md":"eFEr","./2013-07-30-zound-live.md":"Sb+6","./2013-08-05-zanimo.md":"dAja","./2013-08-08-zound-wip-v1.md":"qLlP","./2013-08-21-FM-audio-api.md":"ZKtb","./2013-09-04-beez.md":"KHjv","./2013-09-17-timelapse.md":"Pfac","./2013-09-28-webaudioapi.md":"NvIL","./2013-11-12-functional-rendering.md":"mzFX","./2014-01-12-promisify-your-games.md":"/vfr","./2014-03-12-panzer-dragoon-1k.md":"0mXd","./2014-05-04-ld29.md":"KKCg","./2014-09-14-ibex.md":"iF92","./2014-09-22-ibex-cellular-automata.md":"DoYn","./2014-10-16-webglparis.md":"G+m4","./2015-08-04-making-performant-react-applications.md":"Myxv","./2015-10-01-introducing-gl-react.md":"XWFM","./2016-06-19-glreactconf.md":"VV7m","./2016-07-01-projectseptember-opengl.md":"CybH","./2016-09-19-relay-scrolling-connections.md":"yMwX","./2016-12-03-gl-react-v3.md":"BF22","./2021-04-08-cryptoaliens.md":"cckB","./2021-04-09-cryptoaliens-tech.md":"DsvB","./2021-05-01-plot-loops.md":"gTYa","./2021-05-03-relics.md":"R4Of","./index":"ZwJn","./index.js":"ZwJn"};function i(e){return Promise.resolve().then((function(){if(!t.o(a,e)){var n=new Error("Cannot find module '"+e+"'");throw n.code="MODULE_NOT_FOUND",n}return t(a[e])}))}i.keys=function(){return Object.keys(a)},i.id="fN8t",e.exports=i},fUMH:function(e,n,t){"use strict";t.r(n),n.default=""},fkQn:function(e,n,t){"use strict";var a=t("NdRM");e.exports=new a("tag:yaml.org,2002:seq",{kind:"sequence",construct:function(e){return null!==e?e:[]}})},fzot:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Bricks"\nthumbnail: /images/plots/159.jpg\ndescription: "A simple idea with bricks and slight variation of width/height of each brick."\n---\n\nA simple idea with bricks and slight variation of width/height of each brick.\n'},"g+0Z":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Shell (6 frames)"\nthumbnail: /images/plots/178.gif\ntags:\n  - plotloop\nobjkts:\n  - 154538\n---\n\n@greweb\'s #9 plot loop. The 1920p animation is the main digital art. NFT is available in 6 editions, one per frame. First buyer of each edition can collect related frame to acquire the physical art (selected by buy order. PM @greweb, ship anywhere in the world). Secondary market is digital only. plotted on Bristol paper with black fountain pen. See greweb.me/plots/178\n\nplotloop, physical, phygital, plot, loop, fountainpen\n\n\nHere is "Shell" my 9th ["plot loop" (see article)](https://greweb.me/2021/05/plot-loops). The main digital art is a 1920p video loop of 6 frames available as a [Tezos hicetnunc NFT](https://www.hicetnunc.xyz/objkt/154538). The physical art is 6 frames of A4 size, plotted with a black fountain pen on Bristol paper, and offered when [buying the NFT](https://www.hicetnunc.xyz/objkt/154538) (6 editions, assigned in buy order).\n\n<img src="/images/plots/178zoom1.jpg" width="100%">\n\n### Making of\n\nI\'ve rebooted one of my plot code (one from 100th\'s celebration) and animated it by rotating the center gravity. One of the usual challenge I had to face is the fact many strokes were placed at the same area and had risk to dig into the paper. I\'ve used my usual \'grid counter\' technique but this time pushed it to extreme in that it started making "dots" a bit like in the stippling technique. Dots are aligned to the grid that is used by the algorithm.\n\n<img src="/images/plots/178plotting0.gif" width="100%">\n\nI then met one of the biggest difficulty of my plot: the fact the paper will start waving a bit with the humidity of the ink. It creates two problem: imprecision and unplanned strokes (lines when the robot move it).\n\nI countered this problem by reversing my plot and starting from the center:\n\n<img src="/images/plots/178plotting1.gif" width="100%">\n\nSome of the plots have small remaining imperfection that I judged being part of the art.'},gCGJ:function(e,n,t){"use strict";var a=t("Ga6R"),i=t("NdRM");function o(e){return 48<=e&&e<=55}function r(e){return 48<=e&&e<=57}e.exports=new i("tag:yaml.org,2002:int",{kind:"scalar",resolve:function(e){if(null===e)return!1;var n,t,a=e.length,i=0,s=!1;if(!a)return!1;if("-"!==(n=e[i])&&"+"!==n||(n=e[++i]),"0"===n){if(i+1===a)return!0;if("b"===(n=e[++i])){for(i++;i<a;i++)if("_"!==(n=e[i])){if("0"!==n&&"1"!==n)return!1;s=!0}return s&&"_"!==n}if("x"===n){for(i++;i<a;i++)if("_"!==(n=e[i])){if(!(48<=(t=e.charCodeAt(i))&&t<=57||65<=t&&t<=70||97<=t&&t<=102))return!1;s=!0}return s&&"_"!==n}for(;i<a;i++)if("_"!==(n=e[i])){if(!o(e.charCodeAt(i)))return!1;s=!0}return s&&"_"!==n}if("_"===n)return!1;for(;i<a;i++)if("_"!==(n=e[i])){if(":"===n)break;if(!r(e.charCodeAt(i)))return!1;s=!0}return!(!s||"_"===n)&&(":"!==n||/^(:[0-5]?[0-9])+$/.test(e.slice(i)))},construct:function(e){var n,t,a=e,i=1,o=[];return-1!==a.indexOf("_")&&(a=a.replace(/_/g,"")),"-"!==(n=a[0])&&"+"!==n||("-"===n&&(i=-1),n=(a=a.slice(1))[0]),"0"===a?0:"0"===n?"b"===a[1]?i*parseInt(a.slice(2),2):"x"===a[1]?i*parseInt(a,16):i*parseInt(a,8):-1!==a.indexOf(":")?(a.split(":").forEach((function(e){o.unshift(parseInt(e,10))})),a=0,t=1,o.forEach((function(e){a+=e*t,t*=60})),i*a):i*parseInt(a,10)},predicate:function(e){return"[object Number]"===Object.prototype.toString.call(e)&&e%1===0&&!a.isNegativeZero(e)},represent:{binary:function(e){return e>=0?"0b"+e.toString(2):"-0b"+e.toString(2).slice(1)},octal:function(e){return e>=0?"0"+e.toString(8):"-0"+e.toString(8).slice(1)},decimal:function(e){return e.toString(10)},hexadecimal:function(e){return e>=0?"0x"+e.toString(16).toUpperCase():"-0x"+e.toString(16).toUpperCase().slice(1)}},defaultStyle:"decimal",styleAliases:{binary:[2,"bin"],octal:[8,"oct"],decimal:[10,"dec"],hexadecimal:[16,"hex"]}})},gTYa:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "\'Plot loops\' concept"\nthumbnail: /images/plots/121.gif\ndescription: "Releasing my first \'plot loop\', generative animation plotted and published as an NFT."\ntags:\n  - plot\n  - plotloop\n  - NFT\n---\n\nI am thrilled to release my first **"plot loop"** and plan to release one every week. Let me explain simply the idea:\n\n- an animation is generated with code, (SVG plottable files)\n- Each frame of this animation is plotted physically,\n- photographed back into a digital picture,\n- and post-processed back into a video that makes it an artistic creation by itself as well as each physical plot being one "edition" of that plot loop series.\n\n> **You can see all my plot loops made so far at [https://greweb.me/plots/tags/plotloop](https://greweb.me/plots/tags/plotloop)**\n\n**So there are two creations:**\n\n- the animation is itself digital art => it is released as an NFT, with as many editions as there are frames.\n- each individual frame is physical art => it can be shipped to first buyer.\n\n### Plots and NFT ?!\n\n**Plot loop animations will be released as [Non Fungible Token (NFT)](https://www.youtube.com/watch?v=Y-i9Jsm95ro)** on [hicetnunc](https://www.hicetnunc.xyz/). It allows anyone with Tezos crypto currency to acquire this video on Tezos blockchain. Digital collectors are collecting one edition of this NFT which adds to their collection: **The NFT video is an art in itself**. On top of this, physical collectors can also claim the shipping of the physical art of the frame corresponding to the collected NFT edition (there is as many editions as there are frames plotted).\n\n**This is a hybrid concept between physical and digital art.** By buying a frame (by order of buy), the first buyer has the possibility to chose what happens to the physical art: either you allow me to keep it OR you can claim it (contact me on Twitter) and have me sending it anywhere in the world!\n\n> I\'m writing a bigger article about my recent NFT exploration and my art in general. I\'ve been exploring so many ideas recently. I already sold some plots via NFTs, I am very honored to have found some buyers \ud83d\ude0d. They can still be found at [hic.link/greweb](https://hic.link/greweb). I\'m currently burning them one after the other to expire the possibility to buy them as I will focus on these new projects.\n\n## First release, the triplanet loop\n\n**hicetnunc NFT: [OBJKT#57902](https://www.hicetnunc.xyz/objkt/57902)**\n\n<a href="/plots/121"><img width="50% " src="/images/plots/121.gif"/></a>\n\nMy first plot loop is called "Triplanet". It\'s a transition of two parametric functions with many perlin noise displacements. This is a continuation of ["Planet Holes"](/plots/100) series as well as recent ["Parametric stack"](/plots/111) explorations.\nEvery frame is generated with a Rust script I wrote.\n\n**Triplanet was released in [plots#121](/plots/121).** 16 frames have been plotted with fountain pen on bristol paper (ink: Red Dragon by Diamine).\n\n<img width="100%" src="/images/plots/121_walled.jpg"/>\n<img width="50%" src="/images/plots/121_zoom.jpg"/><img width="50%" src="/images/plots/121_plot.jpg"/>\n\n**Plotting with fountain pen is challenging** as it requires many search on the ink, paper and many fail and retry. Plotting all these frames took an afternoon.\n\n## What\'s next?\n\nI plan to release a _plot loop_ every week.\n\nIt\'s taking a lot of time to plot all frames so there are great challenges: first of all is to reduce the number of frames, secondly is to make them worth it, to make them really good: I want every frame to be unique, to include some specific elements, easter eggs, that make it recognizable out of the other frames.\n\n---\n\n# Please also check out other great artists\n\nI believe a lot of this hybrid idea of mixing plot, animation, and NFTs. It was very funny for me to see all co\xefncidence and convergence of ideas on this topic. It\'s one of these moments when we have the same ideas at the same time. I\'m not the only one exploring this and I want to do a big kudos to these great artists.\n\n### Marion [@atelier_marion](https://twitter.com/atelier_marion/status/1388071908575490048)\n\nwho recently released a very similar idea! <del>She has 2 more frames yet to be taken!</del> Not anymore!\n\n<a href="https://www.hicetnunc.xyz/objkt/42546"><img src="https://cloudflare-ipfs.com/ipfs/QmXcAWQTaGHQp4BGy1krER284PoaPCNhKYzDrxp86MaM7b" style="max-width: 300px"></a>\n\nShe is also creating impressive drawing work as seen on her website: https://www.marionguy.com/shop\n\n### Maks Surguy [@msurguy](https://twitter.com/msurguy)\n\nwho is behind [plotterfiles.com](https://plotterfiles.com/) platform. He also does a lot of great plotting art and thought about similar concept recently! [Checkout this article about his work.](https://medium.com/poptwig/artist-in-focus-maks-surguy-26277c95b197)\n\n### Thomas Lin Pedersen [@thomasp85](https://twitter.com/thomasp85)\n\nwho is doing a [stuning work](https://www.hicetnunc.xyz/tz/tz2Pkj2xWJovKKCsABjnr3NbyMVJTMBkpTvb) and very impressive landscapes. Also selling NFT for shipping physical print.\n\nHe recently did a very cool NFT in collaboration with **Lionel Radisson** [@MAKIO135](https://twitter.com/MAKIO135):\n\n<a href="https://www.hicetnunc.xyz/objkt/53662"><video style="max-width: 300px" controls autoplay loop src="https://ipfs.io/ipfs/QmaGfhSgWX1UTq6jPX11mfHDxccK5eXGYqi6u71zNLaBhY"/></a>\n\n### ...so many other artists!\n\nLet\'s chat! You can join us on [hicetnunc\'s discord](https://discord.gg/jKNy6PynPK) on channel #phygital-objkts which explore very similar idea and where other artists will be active!\n\nI\'m also available for collaboration.\n'},gTso:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Bitcoin"\ndescription: "a parametric spiral, similar to recent exploration, allows to fill the color of the Bitcoin logo"\nthumbnail: /images/plots/120.jpg\ntags:\n  - bitcoin\n---\n\nThis is a pretty simple technique, which is almost like a spiral filling, except it\'s a parametric (a simple one that is close to a spiral). The idea to render something monochrome with a parametric is interesting, I would like to dig more in future. I also tried it on typography (for a family gift).\n\nThis plot is done with fountain pen and ink "Amber" by Diamine, which I really like.\n\nWhen you look closer, there are high frequency noise used to make it more fuzzy.\n\n<img width="100%" src="/images/plots/120_zoom.jpg">\n'},gWvi:function(e,n,t){"use strict";var a=t("3rKx");e.exports=new a({explicit:[t("BbHa"),t("fkQn"),t("KFpJ")]})},gqgv:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "concentric parametric flowers"\nthumbnail: /images/plots/118.jpg\ntags:\n  - parametric\n---\n\nContinuation of [plot#113](/plots/113) with different parametric functions.\n\n- Sakura Gelly Roll white on black. (clairefontaine 210g)\n- STA pigment liner 0.05mm on white. (canson bristol A4)\n\nThe black plot have an interesting precision which makes it smooth from a far look but the details of this plot are interesting as well. I\'m not yet sure what creates the vertical line glitch we see on both plots, is it the paper? is it my robot? It is part of the art now.\n'},grKd:function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: How to make DLink DWA-140 B2 perfectly work on Linux\nauthor: Gaetan\nlayout: post\npermalink: /2011/01/how-to-make-dlink-dwa-140-perfectly-work-on-linux/\ntags:\n  - linux\n---\n\n**[EDIT] Note: the DWA-140 B2 is now supported by recent Linux version.**\n\nI\u2019m using ArchLinux and I finally make my DWA-140 B2 Wifi USB adaptor work !\n\nIf you have the same problem, you can read this article to fix it !\n\n\x3c!--more--\x3e\n\n**My conf**:\n\n* Linux Kernel: *2.6.36*\n* Architecture: *x64*\n* Device: *ID 07d1:3c0a D-Link System DWA-140 RangeBooster N Adapter(rev.B2) [Ralink RT2870]*\n\n\n## What to use ?\n\nSo the only way I found to make it work nicely is to use **ndiswrapper**, a Windows XP driver wrapper, and **wpa_supplicant**, a WLAN tool.\n\nFirst, I\u2019ve tried some RaLink drivers but this was not really great, I\u2019ve succeed to make `ra2870` work only one time but there was some lags each 20 seconds (like 1000ms ping frequently).\n\nMoreover, I recommend not using NetworkManager with this method, it seems ndiswrapper and networkmanager produced awful results for this bundle (like waiting 30s for wifi to connect (or not connecting!), or freezing my Linux, \u2026). Use wpa_supplicant utils like netcfg instead of ! \n\n## Procedure\n\nAlternatives rejected, here is the solution step by step :\n\n### Pre-conditions\n\nWith a wired connection, install these packages (with your package manager) : **ndiswrapper**, **wpa_supplicant** and (optional) **netcfg**.\n\nUnfortunately, I had some freeze issues with the current ndiswrapper repository version so I checkout ndiswrapper SVN source code on  and recompile it. **Maybe you have to do the same.**\n\n1.  Don\u2019t plug your bundle yet. Insert the CD of the product. It contains the driver we need for ndiswrapper. You need to find the `/Drivers/WinXPx64/` (it may depend on your arch) **.inf** file. You can also download the last driver on the [D-Link website][2].\n2.  Go on commandline in root mode and type:\n\n```bash\nndiswrapper -i {path of the .inf file}\n```\n    \nExample:\n    \n```bash\nndiswrapper -i /media/cdrom0/Drivers/WinXPx64/Drt2870.inf\n```\n   \n* Plug your bundle and check if the command `ndiswrapper -l` say something like: \n\n```\ndrt2870 : driver installed  \ndevice (07D1:3C0A) present\n```   \n\nIf not you maybe need to `ndiswrapper -r drt2870` to remove the driver and return to the second step trying another `/Drivers/*/*.inf` file. \n\n*   Next, you need to configure your `wpa_supplicant.conf` configuration file for  your wifi access point. Refer to the [documentation][3].\n*   Try to run `wpa_supplicant` : \n\n```bash\nwpa_supplicant -i wlan0 -c /etc/wpa_supplicant.conf\n```\n\nOnce this working, you maybe need to run dhcpd :\n      \n```bash\ndhcpd wlan0\n```\n      \n*   Now you can try your internet connection, by pinging google.com or try to browse the web.\n*   If it works, you can save your configuration, refer to the [documentation][3]. \n        \n**For any problem, feel free to comment this article.**\n\n [2]: http://www.dlink.com/products/?tab=3&pid=DWA-140&rev=DWA-140_revB\n [3]: https://wiki.archlinux.org/index.php/WPA_supplicant\n"},h8Le:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: R\xe9aliser une maquette web avec le CSS 3\nauthor: Gaetan\nlayout: post\npermalink: /2010/04/realiser-une-maquette-web-avec-le-css-3/\ntags:\n  - css\n  - sass\n---\n\n [1]: http://compass-style.org/\n [2]: /2010/03/sass-levolution-du-css\n [3]: /images/2010/css3/exemple_border_radius.png\n [4]: /images/2010/css3/exemple_gradient.png\n [5]: /images/2010/css3/exemple_text_shadow.png\n [6]: /images/2010/css3/exemple_box_shadow.png\n [7]: /images/2010/css3/university_nostalgia_exemple.png\n [8]: http://github.com/gre/University-nostalgia\n [9]: /images/2010/css3/triangle_01.png\n [10]: /images/2010/css3/triangle_02.png\n [11]: /images/2010/css3/triangle_03.png\n [12]: /images/2010/css3/triangle_menus.png\n\nLe CSS depuis sa version 3 constitue une **bonne \xe9volution technologique pour palier l\u2019utilisation abusive d\u2019images** dans la r\xe9alisation d\u2019une application web.\n\nIl n\u2019est ainsi plus n\xe9cessaire de recourir \xe0 des images pour r\xe9aliser des **ombres**, des **d\xe9grad\xe9s**, des **bordures arrondis** ou encore utiliser des **polices sp\xe9cifiques**.\n\nL\u2019avenir du CSS3 nous promet encore plus : il est d\u2019ores et d\xe9j\xe0 possible sur certains navigateurs d\u2019effectuer des **animations**, des **transitions**, des **effets de reflets**,\u2026 sans devoir recourir au *javascript*, au *canvas* ou, pire encore, au *flash*.\n\n\x3c!--more--\x3e\n\n## G\xe9n\xe9ralit\xe9s\n\n### Pourquoi ?\n\nQuelques raisons pour utiliser le CSS 3\u2026\n  \n#### dans une optique de maintenabilit\xe9\n\nEn utilisant des images pour r\xe9aliser des effets simples, **il faut mettre \xe0 jour l\u2019image \xe0 chaque fois**. Si bien qu\u2019il est n\xe9cessaire d\u2019utiliser un logiciel de dessin et de garder les sources pour pouvoir facilement modifier les couleurs \xe0 l\u2019avenir.  \n**La modification d\u2019un th\xe8me est alors p\xe9nible** : Pour chaque image du th\xe8me : il faut ouvrir la source de l\u2019image avec son logiciel pr\xe9f\xe9r\xe9 (GIMP, Photoshop, \u2026), modifier la couleur, exporter l\u2019image, recharger la page,\u2026 A contrario, **il ne suffit que de modifier une ligne de code CSS pour changer sa couleur** (l\u2019utilisation de variable avec SASS est int\xe9r\xe9ssant).\n\n#### par simplicit\xe9\n\nLe CSS 3 **offre plus de possibilit\xe9s** donc **simplifie bien des t\xe2ches** qui \xe9taient complexe \xe0 r\xe9aliser auparavant. Bordures arrondis, ombres, d\xe9grad\xe9s, animations, reflets,\u2026 sont maintenant facilement r\xe9alisables avec le CSS 3.\n\nVoici un exemple frappant parmi tant d\u2019autres :  \nAuparavant, on voyait fleurir \xe0 foison des tableaux pour r\xe9aliser de simples bordures arrondis.\n\n##### On voyait auparavant\n\n```html\n<table class="radius">\n<tr>\n<td class="topleft"></td>\n<td class="top"></td>\n<td class="topright"></td>\n</tr>\n<tr>\n<td class="left"></td>\n<td class="content">content here...</td>\n<td class="right"></td>\n</tr><tr>\n<td class="bottomleft"></td>\n<td class="bottom"></td>\n<td class="bottomright"></td>\n</tr>\n</table>\n<style>\ntable.radius .topleft {\nbackground: url(topleft.png);\nwidth: 20px;\nheight: 20px;\n}\n/* DE MEME pour les 8 autres cases ... */\n</style>\n```\n\n##### Maintenant avec le CSS3\n\n```html\n<div class="radius">content here...</div>\n<style>\n.radius {\n  border-radius: 20px;\n}\n</style>\n```\n\n#### dans un objectif de scalabilit\xe9 des th\xe8mes\n\nL\u2019utilisation des possibilit\xe9s du CSS 3 au lieu d\u2019images va permettre d\u2019**\xe9tendre rapidement son application web \xe0 plusieurs th\xe8mes** et de modifier facilement ces th\xe8mes. Il suffira d\u2019avoir un fichier pour chaque th\xe8me.\n\n### SASS et le framework Compass\n\nAfin de r\xe9soudre les probl\xe8mes de *cross-navigateur* abord\xe9s pr\xe9c\xe9demment, je vous conseille l\u2019utilisation du **SASS** et du framework [Compass][1].  \nPour plus de renseignements sur le SASS, n\u2019h\xe9sitez pas \xe0 lire [cet article][2].\n\n### Principales nouveaut\xe9s du CSS 3\n\nDans la suite de cet article, **pour plus de simplicit\xe9s, nous nous arr\xeatons \xe0 la compatibilit\xe9 de Firefox** (pr\xe9fix\xe9 par -moz) mais bien entendu, il est possible de les rendre compatibles avec tous les navigateurs r\xe9cents. Comme pr\xe9cis\xe9 avant, l\u2019utilisation du framework *Compass* permet entre autres de r\xe9soudre ce probl\xe8me.\n\n#### Les bordures arrondis\n\n![][3]\n\n```css\n.exemple {  \n\xa0 -moz-border-radius: 10px;  \n\xa0 border: 1px solid black;  \n\xa0 padding: 2px 5px;  \n}  \n```\n\n#### Les d\xe9grad\xe9s\n\nCompatibles depuis Firefox 3.6.  \n![][4]\n\n```css\n.exemple {  \n\xa0 -moz-border-radius: 10px;  \n\xa0 border: 1px solid black;  \n\xa0 padding: 2px 5px;  \n\xa0 background: -moz-linear-gradient(-90deg, green, yellow);  \n}  \n```\n\n#### Les ombres\n\n##### Sous les textes\n\n![][5]\n\n\n```css\n.exemple {  \n\xa0 -moz-border-radius: 10px;  \n\xa0 border: 1px solid black;  \n\xa0 padding: 2px 5px;  \n\xa0 background: -moz-linear-gradient(-90deg, green, yellow);  \n\xa0 text-shadow: -1px -1px 1px yellow;  \n}\n```\n\n\n##### Sous les \xe9l\xe9ments\n\n![][6]\n\n```css\n.exemple {  \n\xa0 -moz-border-radius: 10px;  \n\xa0 border: 1px solid black;  \n\xa0 padding: 2px 5px;  \n\xa0 background: -moz-linear-gradient(-90deg, green, yellow);  \n\xa0 text-shadow: -1px -1px 1px yellow;  \n\xa0 -moz-box-shadow: 1px 1px 1px rgba(0, 0, 0, 0.5);  \n}  \n```\n\nA noter d\u2019ailleurs que la couleur de format **rgba(r, g, b, a)** est une nouveaut\xe9 du CSS 3.\n\n### Optimiser la compatibilit\xe9 avec les navigateurs plus anciens\n\nVoici une utilisation intelligente des d\xe9grad\xe9s (avec SASS) pour permettre une meilleure **compatibilit\xe9** avec, en dernier recours, une couleur ou une image alternative :\n\n```sass\n=vertical-gradient(!from, !to, !alt=(!from/2   !to/2))  \n\xa0 background = !alt  \n\xa0 background = -webkit-gradient(linear, left top, left bottom, from(!from), to(!to))  \n\xa0 background = -moz-linear-gradient(-90deg, !from, !to)  \n  \n/* exemples d\'utilisation : */  \n#main > header  \n\xa0  vertical-gradient(#719369, #587451, url(header.png))  \n  \n#main > header  \n\xa0  vertical-gradient(green, yellow, #80FF80)\n```\n\n## Exemple de maquette\n\nVoici un **exemple d\u2019utilisation du CSS3** utilis\xe9 sur un projet r\xe9cent (r\xe9alis\xe9 \xe0 l\u2019universit\xe9).  \n\n![][7]\n\nIl n\u2019y a aucune image (sauf l\u2019avatar tux) et l\u2019application est enti\xe8rement compatible avec au minimum Firefox et Chrome.  \nSi l\u2019application vous int\xe9resse, elle est sur [github][8].\n\n\n### Extrait du code SASS\n\n```sass\n@import compass.sass  \n@import compass/reset.sass  \n@import theme.sass  \n  \n=vertical-gradient(!from, !to, !alt=(!from/2   !to/2))  \n\xa0 background = !alt  \n\xa0 background = -webkit-gradient(linear, left top, left bottom, from(!from), to(!to))  \n\xa0 background = -moz-linear-gradient(-90deg, !from, !to)  \n  \n!back = #e9f3e7  \n!back_aside = #F8FAF5  \n!back\\_header\\_from=#719369  \n!back\\_header\\_to=#587451  \n!back\\_footer\\_from=#b4c1b1  \n!back\\_footer\\_to=#9da89a  \n  \n#wrapper  \n\xa0  border-radius(!global\\_border\\_radius)  \n\xa0 :border 1px solid !back-#111  \n\xa0 >nav  \n\xa0 \xa0  border-top-radius(10px)  \n\xa0 \xa0 :background white  \n\xa0 >header  \n\xa0 \xa0  vertical-gradient(!back\\_header\\_from, !back\\_header\\_to, url(/public/images/header.png))  \n\xa0 \xa0 :color white  \n\xa0 \xa0 :z-index 1  \n\xa0 >footer  \n\xa0 \xa0  vertical-gradient(!back\\_footer\\_from, !back\\_footer\\_to)  \n\xa0 \xa0  border-bottom-radius(10px)  \n  \n\xa0 #main  \n\xa0 \xa0 background = !back_aside  \n\xa0 \xa0  box-shadow(0px, -1px, 2px, rgba(,,,0.25))  \n\xa0 \xa0 :z-index 2  \n\xa0 \xa0 >section  \n\xa0 \xa0 \xa0 :background white\n```\n\n### Un triangle en css ???\n\nCe n\u2019est pas de la magie mais **il est possible de faire des triangles en CSS** (m\xeame en CSS2) gr\xe2ce \xe0 une petite astuce. Explication en images :\n\n#### Une boite avec une couleur pour chaque bordure\n\n![][9]\n\n```css\n.box {  \n\xa0 background: black;  \n\xa0 width: 40px;  \n\xa0 height: 40px;  \n\xa0 border-width: 15px;  \n\xa0 border-color: yellow red blue green;  \n\xa0 border-style: solid;  \n}\n```\n\n\n#### width et height \xe0 0\n\n![][10]\n\n#### Bordures transparentes\n\n![][11]\n\n```css\n.box {  \n\xa0 background: black;  \n\xa0 width: 0;  \n\xa0 height: 0;  \n\xa0 border-width: 15px;  \n\xa0 border-color: transparent red transparent transparent;  \n\xa0 border-style: solid;  \n}  \n```\n\n#### Autre utilisation des triangles\n\nLe m\xeame proc\xe9d\xe9 m\u2019a permis de faire ceci :  \n![][12]\n\n'},hb5E:function(e,n,t){"use strict";const a=t(0),i=t("Pcej"),o=t("tfEw"),r=t("8Qj+"),s=t("mpv1"),l=t("n0UO"),c=t("Q9oK"),u=t("mx6s"),h=t("X+87");function d(e,n){if(""===e)return{data:{},content:e,excerpt:"",orig:e};let t=c(e);const a=d.cache[t.content];if(!n){if(a)return t=Object.assign({},a),t.orig=a.orig,t;d.cache[t.content]=t}return function(e,n){const t=o(n),a=t.delimiters[0],r="\n"+t.delimiters[1];let l=e.content;t.language&&(e.language=t.language);const c=a.length;if(!h.startsWith(l,a,c))return s(e,t),e;if(l.charAt(c)===a.slice(-1))return e;l=l.slice(c);const p=l.length,m=d.language(l,t);m.name&&(e.language=m.name,l=l.slice(m.raw.length));let g=l.indexOf(r);-1===g&&(g=p);e.matter=l.slice(0,g);""===e.matter.replace(/^\s*#[^\n]+/gm,"").trim()?(e.isEmpty=!0,e.empty=e.content,e.data={}):e.data=u(e.language,e.matter,t);g===p?e.content="":(e.content=l.slice(g+r.length),"\r"===e.content[0]&&(e.content=e.content.slice(1)),"\n"===e.content[0]&&(e.content=e.content.slice(1)));s(e,t),(!0===t.sections||"function"===typeof t.section)&&i(e,t.section);return e}(t,n)}d.engines=l,d.stringify=function(e,n,t){return"string"===typeof e&&(e=d(e,t)),r(e,n,t)},d.read=function(e,n){const t=d(a.readFileSync(e,"utf8"),n);return t.path=e,t},d.test=function(e,n){return h.startsWith(e,o(n).delimiters[0])},d.language=function(e,n){const t=o(n).delimiters[0];d.test(e)&&(e=e.slice(t.length));const a=e.slice(0,e.search(/\r?\n/));return{raw:a,name:a?a.trim():""}},d.cache={},d.clearCache=function(){d.cache={}},e.exports=d},hkxR:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Striped mountain"\nthumbnail: /images/plots/193.jpg\ndescription: "Layering lines with noise with another noise to produce random stripe distribution. Parker Quint on Watercolour paper (300g/m)."\n---\n\nLayering lines with noise with another noise to produce random stripe distribution. Parker Quint on Watercolour paper (300g/m).'},"i+J6":function(e,n,t){"use strict";t.r(n),n.default=""},iF92:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'IBEX, my js13k game\'\ndescription: \'IBEX is a game made in 13k of JavaScript code made for the js13kgames one-month contest.\'\nthumbnail: /images/2014/09/ibex.png\nauthor: Gaetan\nlayout: post\ntags:\n - gamedev\n - js13k\n---\n\n [js13kgames]: http://js13kgames.com/\n [submission]: http://js13kgames.com/entries/ibex\n [github]: http://github.com/gre/js13k-2014\n [cellular]: http://en.wikipedia.org/wiki/Cellular_automaton\n\n<a href="http://js13kgames.com/entries/ibex">\n  <img src="/images/2014/09/ibex.png" alt="" class="thumbnail-left" />\n</a>\n\n**I\'ve just [finished and submitted][submission] my game for [js13kgames][js13kgames],**\na contest where you have to make a web game in less than 13 kilobytes of a ZIP archive.\n\n**[PLAY IT HERE][submission]** / [github][github]\n\n**I had a lot of fun making this game and I think it is by far the best game I ever finished.**\nIt is a bit a continuation of my ["antsim" game](/2014/05/ld29) prototype in the idea\nthat you don\'t control directly the entities but you are at an higher level with simple interactions.\n\nThe game should be performant enough but however \nrequire that you have a good hardware to support WebGL and some advanced limits (I used too much uniforms).\nI\'ll talk more about the compatibility and performance issues in a next postmortem article.\n\nIf it doesn\'t work for you, please report me a dump of [http://webglreport.com/](http://webglreport.com/).\n\n## Playthrough\n\n<iframe width="100%" height="440" src="//www.youtube.com/embed/nqD2qIy4auU" frameborder="0" allowfullscreen></iframe>\n\n\x3c!--more--\x3e\n\n## The Story\n\nThe world is burning, Protect and Escort a group of wild ibex away from the inferno.\nOn the path there are sleeping ibex to rescue, wake them and they will join the group.\n\n## The Gameplay\n\n\nYou will have to use the **4 elements (Air, Earth, Fire, Water)**\nto make the ibex progress safely in the environnment.\n\nThe 4 elements are primary elements but there are also secondary elements at play:\n\n- The **Volcano** (creates fire)\n- The **Source** (drops water)\n- The **Forest** (created by Earth and Water)\n- The **Wind** (left wind and right wind is created randomly in Air)\n\n\nAll elements interact with each other and **the ibex also react to elements in different ways**.\n\n- Earth is a platform for the ibex\n- Fire scares the ibex\n- Water attracts the ibex\n- Forest makes the ibex running faster\n\n## The Controls\n\nSPACE to draw an element, ARROWS to move, W/Z + X + C + V to switch between Air + Earth + Fire + Water.\n\nKeyboard is recommended but playing only with mouse is also possible (click on elements and DRAG the inner cursor).\n\n\n## Some technical notes\n\nThis game uses a [cellular automaton][cellular] to simulate a world with different elements (Air, Earth, Fire, Water).\nThis cellular automaton is technically computed as a texture in the GPU through WebGL and a GLSL shader (`logic.frag`).\n\nWhile I was writing this game [@42loops](https://twitter.com/42loops) made me buy this awesome book that I\'m still reading:\n\n<blockquote class="twitter-tweet" lang="fr"><p><a href="http://t.co/8SiMZ9PWDX">pic.twitter.com/8SiMZ9PWDX</a></p>&mdash; Ga\xebtan Renaudeau (@greweb) <a href="https://twitter.com/greweb/status/506862098597834752">2 Septembre 2014</a></blockquote>\n<script async src="//platform.twitter.com/widgets.js" charset="utf-8"><\/script>\n\nYou can interact with this world by drawing elements with a brush.\n\nHowever, simulation is not enough to make a game so I mainly focused on the story and the gameplay:\nOn top of this simulation are living the ibex. They are managed in JavaScript and behaves with an AI.\nThe pixels collision and the ibex decisions (e.g; react on fire nearby) is based on querying the simulated world (stored in the GPU as a texture).\n\nThe rendering of the game is also performed in WebGL through another shader (`render.frag`).\nMy source code is [on Github][github].\n\n**I will try to write a technical post-mortem to explain you more of this \nand also what went wrong and what could have been more efficient in my usage of WebGL.**\n\n## Bonus\n\nDuring my early development, I\'ve experimented the fire propagation in deep forest:\n\n<iframe width="480" height="440" src="//www.youtube.com/embed/YU_pYAauFo4" frameborder="0" allowfullscreen></iframe>\n\n\n'},iFIo:function(e,n,t){"use strict";var a=t("NdRM");e.exports=new a("tag:yaml.org,2002:merge",{kind:"scalar",resolve:function(e){return"<<"===e||null===e}})},ieJe:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: CSS-selector-based templating system for scalable JavaScript applications\ndescription: In this article, we will focus on the power of CSS as a descriptive language, current template system approach and their problems with modularity and extensibility, and try to mix both features from the concept to a concrete implementation.\nthumbnail: /images/2012/02/218px-Mir_diagram-fr.svg_.png\nauthor: Gaetan\nlayout: post\npermalink: /2012/02/css-selector-based-templating-example-with-javascript/\ntags:\n  - css\n  - javascript\n  - templating\n---\n\n [2]: http://sliderjs.org/\n [3]: http://www.ubelly.com/2011/11/scalablejs/\n\n<img src="/images/2012/02/218px-Mir_diagram-fr.svg_.png" alt="" class="thumbnail-left" />\n\nIn this article, we will focus on the power of **CSS as a descriptive language**, current template system approach and their problems with **modularity** and **extensibility**, and try to mix both features from the **concept** to a **concrete implementation**.\n\n\x3c!--more--\x3e\n\n<br style="clear: both" />\n\n## What is CSS ?\n\nCSS is an extremely powerful descriptive language.  \nIt helps to define **how to display a document** (e.g. a web page).\n\nA style sheet contains a set of **CSS rules**.  \nEach CSS rule has a **CSS selector** associated with a set of **declarations**.  \nYou can see a CSS selector as a selection filter applied on every HTML element. A few element can match a CSS selector if they fit the structure describes in this selector.  \nEach **declaration** is composed of a couple (**property** : **value**).  \nThe **CSS property** is a predefined property related to a display or layout behavior.  \nThe **value** will apply a custom value for the property on all elements matching the CSS selector.\n\nLet\u2019s focus on some advantages of this descriptive language:\n\n### A CSS rule is independant from others.\n\nThe order of CSS rules *(selector declarations)* **really** does not matter.  \nThe priority between CSS rules is based on the selector itself and not on their arrangement.\n\n### You can \u201cmix\u201d CSS rule \n2 CSS rules can have the same CSS selector. An element can be matched with multiple CSS rules. CSS rules are merged, it\u2019s called the cascading.  \nThis is the most important feature of CSS.  \nIt implies a very modular and extensible language.\n\n#### Example\n\n```css\na {   \n\xa0 color: #33CC00;  \n\xa0 text-decoration: none;  \n}  \na:hover { text-decoration: underline; }  \n#articles {  \n\xa0 font-size: 12px;  \n}  \n#articles a {  \n\xa0 color: red; /* overriding the generic color of a */  \n}\n```\n\n## Some limitations of today\u2019s template system\n\nMost of template system are based on inherence between templates.\n\n*   You have usually an \u201cinclusion\u201d approach: a template will \u201cinclude\u201d multiple external template. *(Many template into Many template)*\n*   And an \u201cextension\u201d approach: You define in a main template an area where you can append a template. Others templates \u201cextend\u201d your main template. *(One main template for Many template)*\n\nThese approaches aims to factorize template codes and that\u2019s great.\n\nBut it doesn\u2019t fit my needs:\n\n*   It brings **dependencies between templates**. \n*   If you add a new template, you have to modify existing templates.  \n    If your application tend to go modules based, this is going to be unmaintainable. \n\n> **web application module (n)**  \n> 1 : an independent unit of functionality that is part of the total structure of a web application \n\n### A solution for scalable applications and libraries\n\nI\u2019ve recently started to rewrite my [SliderJS][2] library and I needed to split it into very modular features and having loose coupling between each component.\n\nI followed this [Scalable JavaScript Application Architecture][3] article.\n\nSo, **how to bring loose coupling in templating?**.  \nEach module have its own template and know where to append. Bringing this logic in a main template would break the independency and if I need to add new modules soon, it will not working without modifiyng it.  \nHow to keep the scalability of the main template without modifying it?\n\nThe best solution I found is to combine **CSS selectors** concepts with **template system** approaches.\n\n## CSS concepts applied on templating\n\nI\u2019ve decided to inspire from CSS: **attaching a CSS selector with a template**.  \nIt benefits from some CSS advantages explained before.\n\n### Simple twitter widget example\n\n```html\n<div class="twitter">\n  <h1>Twitter</h1>\n  <ul class="twitts">\n    <li class="twitt">Hello world!</li>\n  </ul>\n  <footer><a href="http://twitter.com/greweb">Follow me on twitter</a></footer>\n</div>\n```\n\n#### Classical approach\n\nThe way to template it with the classical approach would be:\n\n```html\n<div class="twitter">\n  <h1>Twitter</h1>\n  <ul class="twitts">\n    {for twitt in twitts}\n    <li class="twitt">{twitt}</li>\n    {/for}\n  </ul>\n  <footer><a href="http://twitter.com/{me}">Follow me on twitter</a></footer>\n</div>\n```\n\n#### CSS selector based approach\n\nBut we can also split the original \u201ctemplate\u201d in small fragments and mix all of them.  \nIt helps to define each templates independently.\n\n**We can identify:**\n\n- A **root template fragment**:\n\n```html\n<div class="twitter"></div>\n```\n\n- A **header fragment** appended with `.twitter` selector and with an **high priority**:\n\n```html\n<h1>Twitter</h1>\n```\n\n- A **twitts list fragment** appended with `.twitter` selector:\n\n```html\n<ul class="twitts">\n  {for twitt in twitts}\n  <li class="twitt">{twitt}</li>\n  {/for}\n</ul>\n```\n\nwith **parameters** `twitts = [ "Hello world!" ]`\n\n- An empty **footer fragment** appended with `.twitter` selector and with a **low** priority:\n\n```html\n<footer></footer>\n```\n\n- A \u201cfollow me\u201d **link fragment** appended with `.twitter footer` selector:\n\n```html\n<a href="http://twitter.com/{me}">Follow me on twitter</a>\n```\n\nwith **parameters** `me = "greweb"`\n\n### Advanced example\n\nThis is another example with a slider. \n\nLet\u2019s conceptually imagine the following template language:\n\n```html\n@root { html: <div class="slider"></div> }\n\n.slider {\n  html: <div class="slides"></div>\n}\n\n.slider div.slides {\n  html: <canvas class="slides"></canvas>\n}\n\n.slider div.slides {\n  html:\n  <div class="slide">\n    <a href="<%= link %>">\n      <img src="<%= img %>" />\n      <span class="caption"><%= title %></span>\n    </a>\n  </div>\n}\n\n.slider {\n  priority: -10\n  html: <div class="pager"></div>\n}\n\n.slider div.pager {\n  priority: 10\n  html: <a class="prevSlide" href="javascript:;">prev</a>\n}\n\n.slider div.pager {\n  priority: -10\n  html: <a class="nextSlide" href="javascript:;">next</a>\n}\n\n.slider div.pager {\n  html: <span class="pages"></span>\n}\n\n.slider div.pager {\n  html: <span class="pages">\n    <% for (var i=0; i<slides.length; ++i) { %>\n    <a class="page" href="javascript:;"><%= i+1 %></a>\n    <% } %>\n  </span>\n}\n```\n\ncombined with some parameters, it will result\n\n```html\n<div class="slider">\n  <div class="slides">\n    <div class="slide"><a href=".."><img src=".."/><span class="caption">...</span></a></div>\n    <div class="slide">...</div>\n    <div class="slide">...</div>\n    <canvas class="slides"></canvas>\n  </div>\n  <div class="pager">\n    <a href="javascript:;" class="prevSlide">prev</a>\n    <div class="pages">\n      <a href="javascript:;" class="page">1</a>\n      <a href="javascript:;" class="page">2</a>\n      <a href="javascript:;" class="page">3</a>\n    </div>                                                                      \n    <a href="javascript:;" class="nextSlide">next</a>\n  </div>\n</div>\n```\n\nOf-course we could also do this programmatically with DOM. But see the benefit of such a descriptive way to define things?\n\nYou should keep in mind that **the order of rules definition does not matter**. In that\u2019s sense, it is **a mixable, extensible, modular and loosely-coupled template system**.\n\n\n### More about this POC\n\nUnlike CSS, **two same rules aren\u2019t merged but are appended**.\n\nThe ***priority*** governs the order of append. The higher the value is, the sooner it is appended to the containers selected by the CSS selector.\n\nAs you can see, there is a **micro-templating** inside each rule. For this example, it looks like the John Resig \u2018s Micro Templating.\n\nNote also that a rule must be aware of its **parameters** to work properly. But this only concerns the implementation: You have to find a way to give a dynamic reference of these parameters when you add a rule.\n\n### Concrete implementation\n\nThe code above was a conceptual proof of concept, but I implement a subset of these features in Javascript and made \u201cSelectorTemplating.js\u201d available here : <https://gist.github.com/1731611>\n\nThis is how it can be used for (almost) the same example. You will see different style of usage:\n\n```javascript\nvar node = document.getElementById("slider");\nvar t = new SelectorTemplating(node);\nvar tmpl; // defined somewhere, the John Resig \'s Micro Templating.\n\n// root module\nfunction root () { return \'<div class="slider"></div>\' }\nt.add(null, root);\n\n// slides module\nvar slidesTmpl = tmpl(\'<div class="slides"> <% if(obj.slides) { for(var i=0; i<slides.length; ++i) { var s = slides[i]; %> <div class="slide"> <a href="<%= s.link %>"> <img src="<%= s.img %>" /> <span class="caption"><%= s.title %></span> </a> </div> <% }} %> </div>\')\nvar slides = [ ... ]; // mutable\nt.add(".slider", function () { return slidesTmpl(slides: slides) });\n\n// canvas module\nt.add(".slider div.slides", function () { return \'<canvas class="slides"></canvas>\' });\n\n// pager module\nvar pagesTmpl = tmpl(\'<div class="pager"> <span class="pages"> <% if(obj.slides) { for(var i=0; i<slides.length; ++i) { %> <a href="javascript:;" class="page"><%= i+1 %></a> <% }} %> </span> </div>\');\nvar slides = [...]; // synchronised with the slides module\nvar prevButton, nextButton; // DOM element init when templated\nvar pages = function () {\n  return pagesTmpl(slides: slides);\n}\nt.add(".sliderjs", pages, null, -10);\nt.add(".sliderjs .options", function () { return \'<a class="prevSlide" href="javascript:;">prev</a>\' }, function (n) { prevButton = n[0] }, 10 }); // prepend first in options\nt.add(".sliderjs .options", function () { return \'<a class="nextSlide" href="javascript:;">next</a>\' }, function (n) { nextButton = n[0] }, -10 }); // append at the end of options\n\n// when all modules are init :\nt.init();\n```\n\n```\nt.add (selector, templateFunction, callback, priority)\n * selector is the selector function. if null, append to root.\n * a template function is an identifier in the template.\n * the callback is called at the end of the templating with 2 arguments : the appended nodes and the global container.\n```\n\n#### Algorithm of the template process\n\n```\ncontainer := the container element\nrules := an array containing all rules.\nsort rules by priority.\n(1) take one rule from rules\n  - elements := []\n  - if the selector is @root, elements := [container]\n  - otherwise, elements := all elements which matches the selector\n  - if the elements is empty, back to (1) by taking the next rule.\n  - (2) if not, templatize the html and append it into all of these elements. remove the rule from rules. back to (1) by starting from the first rules. \n\nthe loop (1) must end when :\n  - there is no rules anymore\n  - you have covered all the rules array without finding a match (without passing by (2) for this loop). In that case, it means some rules are not used.\n```\n\nThere is a known limitation of the algorithm I intend to fix soon:\nOnce we found matching elements for a rule, we append the template in these elements once, and we remove the rule. It\u2019s a simple way to avoid recursion. But this approach doesn\u2019t work if a selector can potentially matches elements defined in different rules. **I know how to fix this but it\u2019s not yet implemented.**\n\n## What\'s next?\n\nWe are working hard for the next version (v2) of [SliderJS](http://sliderjs.org) by trying to make a revolutionary IDE platform for SliderJS. It requires a modulification of every components of SliderJS, we try to keep things simple (no external library required, the core system is only 4k sized). You will have more information soon!\n\nThis templating system should benefits of this work.\n\nKeep in touch!\n'},ig9K:function(e,n,t){"use strict";t.r(n),n.default=""},ikex:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "half-filled or half-empty?"\nthumbnail: /images/plots/185.jpg\ndescription: "Packing turquoise half-filled circles, plotted with a fountain pen and Diamine Turquoise ink on watercolor paper."\ntags:\n  - shape-packing\n---\n\nPacking turquoise half-filled circles, plotted with a fountain pen and Diamine Turquoise ink on watercolor paper.'},iyOL:function(e,n,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/elector",function(){return t("vHLE")}])},jBCP:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "seasonal roots"\nthumbnail: /images/plots/091fall.jpg\ndescription: "Experimentation of vector fields with a sinuso\xefdal distribution of lines."\ntags:\n  - field\n  - perlin\n---\n\nExperimentation of vector fields with a sinuso\xefdal distribution of lines.\n\nIt was made in 4 editions, one for each season.\n\n<img src="/images/plots/091winter.jpg" width="100%">\n<img src="/images/plots/091spring.jpg" width="100%">\n<img src="/images/plots/091summer.jpg" width="100%">\n<img src="/images/plots/091fall.jpg" width="100%">\n'},jCcY:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Qep1.: Q, a Promise library\'\ndescription: \'This article is the first of a series of small articles on the Q Javascript library and its eco-system. It is a brief introduction to Q Promises.\'\nthumbnail: /images/2013/07/promise_then_thumbnail.jpg\nauthor: Gaetan\nlayout: post\ntags:\n - AWOP\n - javascript\n - promise\n - Q\n - library\n---\n\n[0]: /pages/a-world-of-promises/\n[1]: http://github.com/kriskowal/q\n[2]: http://github.com/gre/qimage\n[3]: https://github.com/kriskowal\n[4]: http://wiki.commonjs.org/\n[5]: http://domenic.me/2012/10/14/youre-missing-the-point-of-promises/\n[6]: https://raw.github.com/kriskowal/q/master/design/README.js\n[7]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/EventLoop\n[8]: http://jquery.com/\n[9]: http://wiki.commonjs.org/wiki/Promises/A\n[10]: http://tritarget.org/blog/2012/11/28/the-pyramid-of-doom-a-javascript-style-trap/\n\n# [A World Of Promises][0], episode 1\n\n*This article is the first of a series of small articles \non the Q Javascript library and its eco-system.\nThis article is a brief introduction to Q Promises.*\n\n<img src="/images/2013/07/promise_then_thumbnail.jpg" alt="" class="thumbnail-left" />\n\n[Q][1] is a **Promise library** in **Javascript** \ncreated 4 years ago by [Kris Kowal][3] who is one of the main contributor to [CommonJS][4]\nwhere we can find the **[Promises/A][9]** specification.\n\n[Q][1] is probably **the most mature and powerful Promise library in Javascript**\nwhich inspired a lot of libraries like [jQuery][8].\nIt exposes a complete API with, in my humble opinion, \ngood ideas like the separation of concerns between a "Deferred" object (the resolver) \nand a "Thenable" Promise (the read-only promise).\n\nThis article is a brief introduction to Q Promises with some examples.\nFor more information on the subject, I highly recommend reading\nthe article ["You\'re Missing the Point of Promises"][5] \nand [the Q implementation design README][6].\n\n\x3c!--more--\x3e\n\n## What is a Promise\n\nA **Promise** is an object representing a **possible future value** which has \na `then` method to access this value via callback. A Promise is initially \nin a *pending* state and is then either *fulfilled* with a value or *rejected* with an error.\n\n![Schema representing Promise states: pending -> fulfilled|rejected](/images/2013/07/promise.png)\n### Some properties\n\nIt is **immutable** because the Promise value never changes and each `then` creates a new Promise. \nAs a consequence, one same Promise can be shared between different code.\n\nIt is **chainable** through the `then` method (and other Q shortcut methods),\nwhich transforms a Promise into a new Promise without knowing what\'s inside.\n\nIt is **composable** because the `then` method will unify any Promise returned as \na result of the callback with the current Promise (act like a map or flatmap). \n[Q][1] also has a `Q.all` helper for combining an Array of Promise into one big Promise.\n\n## A solution against the [Pyramid of Doom][10] effect\n\n*Javascript* is by nature an **asynchronous language** based on an [event loop][7] which enqueue events.\nAs a consequence, there is no way to block long actions (like Image Loading, ajax requests, other events), but everything is instead asynchronous:\nMost of Javascript APIs are using **callbacks** - functions called when the event has succeeded.\n\n**Problem with callbacks** is when you start having a lot of asynchronous actions.\nIt quickly becomes a [Callback Hell](http://callbackhell.com/).\n\n### Example\n\nHere is a simple illustration, let\'s say we have 2 functions, \none for **retrieving some photos meta-infos from Flickr** with a search criteria: `getFlickrJson(search, callback)`, \nanother for **loading an image from one photo meta-info**: `loadImage(json, callback)`. \nOf-course both functions are asynchonous so they need a callback to be called with a result.\n\nWith this callback approach, we can then write:\n\n```javascript\n// search photos for "Paris", load and display the first one\ngetFlickrJson("Paris", function (imagesMeta) {\n  loadImage(imagesMeta[0], function (image) {\n    displayImage(image);\n  });\n});\n```\n*(Imagine what it can look like with more nested steps.)*\n\n> we can easily turn a *callback* API into a *Promise* API\n\n#### Promise style\n\n`getFlickrJson` and `loadImage` can now be rewritten as Promise APIs:\n\nEach function has clean signatures:\n\n* `getFlickrJson` is a `(search: String) => Promise[Array of ImageMeta]`.\n* `loadImage` is a `(imageMeta: ImageMeta) => Promise[DOM Image]`.\n* `displayImage` is a `(image: DOM Image) => undefined`.\n\n...and are easily pluggable together:\n\n```javascript\ngetFlickrJson("Paris")\n  .then(function (imagesMeta) { return imagesMeta[0]; })\n  .then(loadImage)\n  .then(displayImage, displayError);\n```\n\n**This is much more flatten, concise, maintainable and beautiful!**\n\nNote that if we want to be safer we can write:\n\n```javascript\nQ.fcall(getFlickrJson, "Paris")\n  .then(function (imagesMeta) { return imagesMeta[0]; })\n  .then(loadImage)\n  .then(displayImage, displayError);\n```\n\n`Q.fcall` will call the function with the given parameters and ensure wrapping the returned value into a **Promise**.\nSo my code should continue working even if we change signatures to:\n\n* `getFlickrJson` is a `(search: String) => Array of ImageMeta`.\n* `loadImage` is a `(imageMeta: ImageMeta) => DOM Image`.\n\nOne other cool thing about this chain of Promises is **we can easily add more steps** between two `then` step, for instance a DOM animation, a little delay, etc.\n\n### Error Handling\n\nBut a much important benefit is, unlike the callbacks approach,\nwe can properly **handle the error in one row** because one of the following steps eventually fails:\n\n* `getFlickrJson` fails to perform the ajax request to retrieve the Flickr JSON data.\n* The array returned by Flickr was empty so `loadImage` throws an exception.\n* The `loadImage` fails (e.g. the image is unavailable).\n\nThis is called **propagation** and is exactly how **exceptions** work.\n\n**Promise Error Handling** really looks like **Exception Handling**.\n\nIf it would be possible to have two methods:\n\n* `getFlickrJsonSync` is a `(search: String) => Array of ImageMeta`.\n* `loadImageSync` is a `(imageMeta: ImageMeta) => DOM Image`.\n\nThen, the blocking code would look like this:\n\n```javascript\ntry {\n  var imagesMeta = getFlickrJsonSync("Paris")\n  var firstImageMeta = imagesMeta[0]\n  var image = loadImageSync(firstImageMeta)\n  displayImage(image);\n} catch (e) {\n  displayError(e);\n}\n```\n\n*...which is very close to Promise style.*\n\n**Q Promises also unify Exceptions and Rejected Promises**:\nthrowing an exception in any Q callback will result in a rejected Promise.\n\n```javascript\nvar safePromise = Q.fcall(function () {\n  // following eventually throws an exception\n  return JSON.parse(someUnsafeJsonString);\n});\n// safePromise is either fulfilled with a JSON Object\n// or rejected with an error.\n```\n\n> Error handling with the callbacks approach is hell:\n\n```javascript\ngetFlickrJson("Paris", function (imagesMeta) {\n  if (imagesMeta.length == 0) {\n    displayError();\n  }\n  else {\n    loadImage(imagesMeta[0], function (image) {\n      displayImage(image);\n    }, displayError);\n  }\n}, displayError);\n```\n\n\n## Next episode\n\nNext episode, we will show you how to create your own Promises with *Deferred* objects.\nWe will introduce **Qimage**, a simple Image loader wrapped with Q.\n\n---\n\nSpecial Kudos to <a href="http://twitter.com/42loops">@42loops</a> & <a href="http://twitter.com/bobylito">@bobylito</a>\nfor bringing Q in my developer life :-P\n'},jOok:function(e,n,t){"use strict";var a=t("NdRM"),i=Object.prototype.toString;e.exports=new a("tag:yaml.org,2002:pairs",{kind:"sequence",resolve:function(e){if(null===e)return!0;var n,t,a,o,r,s=e;for(r=new Array(s.length),n=0,t=s.length;n<t;n+=1){if(a=s[n],"[object Object]"!==i.call(a))return!1;if(1!==(o=Object.keys(a)).length)return!1;r[n]=[o[0],a[o[0]]]}return!0},construct:function(e){if(null===e)return[];var n,t,a,i,o,r=e;for(o=new Array(r.length),n=0,t=r.length;n<t;n+=1)a=r[n],i=Object.keys(a),o[n]=[i[0],a[i[0]]];return o}})},jgXF:function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: \"Rounded squares\"\nthumbnail: /images/plots/154.jpg\ndescription: \"Definitely overkill, but this is implemented with 'box' distance function of a square and marching squaring it with noise displacement.\"\ntags:\n  - squares\n---\n\nDefinitely overkill, but this is implemented with 'box' distance function of a square and marching squaring it with noise displacement.\n"},jmt2:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Noisy fibers"\nthumbnail: /images/plots/124.jpg\ndescription: "Jumping man with fibers."\ntags:\n  - fibers\n---\n\nRevisiting my classical "Jumping man" [plots#060](/plots/060) with combination of Fibers exploration ([plots#112](/plots/112)). It uses an image as a lookup for noise amplitude and reveals the shape of the Jumping man. Fountain pens. A4 on Bristol.\n'},jxws:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: Zound, a PlayFramework 2 audio streaming experiment using Iteratees\ndescription: Zound uses an audio generator (JSyn, an audio synthesizer), encode the output and stream it all using Play Iteratees to pipe everything in real-time.\nthumbnail: /images/2012/07/ZOUND.png\nauthor: Gaetan\nlayout: post\npermalink: /2012/08/zound-a-playframework-2-audio-streaming-experiment-using-iteratees/\ntags:\n  - audio\n  - iteratee\n  - playframework\n  - hackday\n---\n\n![ZOUND](/images/2012/07/ZOUND.png)\n\nLast Friday was HackDay #7 at [Zenexity][2], and we decided to work on a real-time audio [experiment][3] made with [Play Framework][4]. The plan was to use an audio generator ([JSyn][5], an audio synthesizer), encode the output and stream it all using Play Iteratees to pipe everything in real-time.\n\n [2]: http://zenexity.com\n [3]: http://github.com/gre/zound\n [4]: http://playframework.org\n [5]: http://www.softsynth.com/jsyn/\n [7]: https://twitter.com/mrspeaker\n [12]: http://www.playframework.org/\n [13]: scala-lang.org/\n [14]: http://sadache.tumblr.com/post/26784721867/is-socket-push-bytes-all-what-you-need-to-program\n [15]: http://www.infoq.com/presentations/Play-I-ll-See-Your-Async-and-Raise-You-Reactive\n [16]: https://github.com/playframework/Play20/tree/master/framework/src/play/src/main/scala/play/api/libs/iteratee\n [17]: http://en.wikipedia.org/wiki/WAV\n [19]: http://en.wikipedia.org/wiki/Broadcasting_(networking)\n\n<iframe width="640" height="360" src="http://www.youtube.com/embed/taDLKTcNHnQ?feature=player_embedded" frameborder="0" allowfullscreen></iframe>\n\n**First of all, let\u2019s highlight some interesting part of the project, then get into some of the details.**\n\nThanks to [@Sadache][6] for his Iteratee expertise, we ended up with a simple line of code that does all of the hard work:\n\n [6]: https://twitter.com/Sadache\n\n```scala\nval chunkedAudioStream = rawStream &> chunker &> audioEncoder\n```\n\nYou can think of the `&>` operator as the UNIX pipe `|`. So we simply take the `rawStream`, chunk it with a `chunker` and encode it with an `audioEncoder`.\n\nNow, **rawStream** is the raw stream of audio samples (numbers between -1 and 1) generated by the audio synthesizer. Next, the **chunker** buffers a data stream into chunk of bytes. For instance, if you send data stream at 1Kb/s to a 10Kb chunker, it will output one chunk of size 10Kb every 10 seconds. And finally, the **audioEncoder** takes **audio samples** and outputs encoded bytes implementing an audio format (like WAVE).\n\nWe can then make a broadcast of the stream:\n\n```scala\nval (sharedChunkedAudioStream, _) =   \n\xa0 Concurrent.broadcast(chunkedAudioStream)\n```\n\nAnd then the **sharedChunkedAudioStream** is now a shared stream for every consumer (clients). All that\u2019s left to do is to stream it over HTTP:\n\n```scala\ndef stream = Action {  \n\xa0 Ok.stream(audioHeader >>> sharedChunkedAudioStream).  \n\xa0 \xa0 \xa0withHeaders( ("Content-Type", audio.contentType) )  \n}\n```\n\nThe `>>>` operator means \u201cconcatenation\u201d, so here we\u2019re concatenating the **audio header** (given by the format like WAVE) with the current **chunked audio stream**. We also send the right HTTP **Content-Type** header (like \u201caudio/wav\u201d for WAVE).\n\nAnother interesting part of the project is the **multi-user web user interface: allowing users to interact with the sound synthesis**.\n\nUsing [@mrspeaker][7]\u2018s audio synthesis expertise, we started creating a synthesizer generator \u2013 3 oscillators, various wave shapes, frequency and volumes, and finally flowing through a high pass filter before entering our \u201crawStream\u201d above.\n\n\nThanks to the Play framework goodness, **this audio stream can be both consumed by the web page with an HTML audio tag, and with a stream player such as VLC!** Ok, that\u2019s the project \u2013 let\u2019s have a closer look at some of the concepts\u2026\n\n\x3c!--more--\x3e\n\n\n## What is sound?\n\n> Sound is a mechanical wave that is an oscillation of pressure transmitted through a solid, liquid, or gas, composed of frequencies within the range of hearing and of a level sufficiently strong to be heard, or the sensation stimulated in organs of hearing by such vibrations. ***Wikipedia***\n\nWe can represents the sound like any wave as a graphic of the amplitude (the oscillation pressure) as a function of time. Here you see it in Audacity:\n\n![sound-audacity](/images/2012/07/sound-audacity.png)\n\nElectricity is used to pump these amplitudes to your speakers, over time.\n\n### About primitive wave sounds\n\nThere are some patterns \u2013 some primitives waves \u2013 we can easily generate with computers (or before with analog oscillators). Those are well known by mathematicians and physicians: Sine wave, Triangle wave, Square wave,\u2026\n\n[![](/images/2012/07/557px-Waveforms.svg_.png)][10]\n\n [10]: http://en.wikipedia.org/wiki/File:Waveforms.svg\n\nA sine wave produce a smooth tone, whereas Triangle and Square wave are more aggressive sounds. The shorter a wave period is, the lower the note you hear: it\u2019s called the frequency.\n\n### How is sound represented by computer?\n\nWhereas analog oscillators generate sounds in an *almost** continuous stream of electricity, computers are not able to generate continuous stream of data. This is why with computers the sound is divided in to discrete **samples**, usually **44100 samples per second** for standard CD quality audio. Each sample is a value (amplitude) for a given time position.\n\n[See Sampling (wikipedia)][10].\n\n [10]: http://en.wikipedia.org/wiki/Sampling_(signal_processing)\n\nIf you zoom in Audacity, you can actually see each sample:  \n![audacity-zoom](/images/2012/07/audacity-zoom-ah.png)\nThis is an \u201cAH\u201d timbre of my voice. A timbre is unique to everyone, it\u2019s the pattern the sound wave take when you speak. **The amplitude of an audio sample is usually represented as a Real number between -1.0 and 1.0**.\n\n** electricity is not strictly continuous, we have electrons out there!*\n\nOk, Let\u2019s go back to our experiment now!\n\n## The experiment\n\nOur experiment is using [Play Framework][12] and is written in [Scala language][13]. Specifically, our project takes advantage of Play framework\u2019s powerful **Iteratee**s.\n\n\n> Take the expressivity of UNIX pipes, bring the power of Scala, mix it with Play Framework and you got a powerful framework for handling real-time and web streaming.\n\nThe iteratee (and related constructs) can take a bit of getting used to. I recommend checking out [this article on Iteratees in Play][14] and/or [this presentation][15] if you are interested in learning more about Play2 and reactive programming with Iteratees. And if you just want to see how it work \u2013 you can read the source code at [Play20 Github source code][16].\n\n\n### Generating the audio stream\n\n```scala\nval (rawStream, channel) = Concurrent.broadcast[Array[Double]]  \nval zound = new ZoundGenerator(channel).start()\n```\n\nWe create an `Array[Double]` broadcast which return two values: the **rawStream** will be used to read the generated data, and the **channel** used by the generator to push generated audio samples. We give this channel to the **ZoundGenerator**. The `.start()` then starts the audio generation. All of the generation is done using the JSyn library.\n\nHere\u2019s a snippet from the **ZoundGenerator** class showing the connection between **JSyn** and **Channel**:\n\n```scala\nclass ZoundGenerator(output: Channel[Array[Double]]) {  \n\xa0 val out = new MonoStreamWriter()  \n  \n\xa0 val synth = {  \n\xa0 \xa0 val synth = JSyn.createSynthesizer()  \n\xa0 \xa0 synth.add(out)  \n\xa0 \xa0 out.setOutputStream(new AudioOutputStream(){  \n\xa0 \xa0 \xa0 def close() {}  \n\xa0 \xa0 \xa0 def write(value: Double) {  \n\xa0 \xa0 \xa0 \xa0 output.push(Array(value))  \n\xa0 \xa0 \xa0 }  \n\xa0 \xa0 \xa0 def write(buffer: Array[Double]) {  \n\xa0 \xa0 \xa0 \xa0 write(buffer, , buffer.length)  \n\xa0 \xa0 \xa0 }  \n\xa0 \xa0 \xa0 def write(buffer: Array[Double], start: Int, count: Int) {  \n\xa0 \xa0 \xa0 \xa0 output.push(buffer.slice(start, start count))  \n\xa0 \xa0 \xa0 }  \n\xa0 \xa0 })  \n\xa0 \xa0 synth  \n\xa0 }  \n\xa0 // ...\n```\n\nWe have to implement the methods of AudioOutputStream \u2013 but it\u2019s just a matter of pushing each audio sample to the channel. It\u2019s that simple!\n\n### Encoding the raw audio stream\n\nFor now, we have only implemented the [WAVE format][17]. Basically, WAVE has 2 parts; the WAVE header which describes important information (like the framerate and the bits per sample), and the data.  \nThe data is encoded in a simple manner I won\u2019t describe here but you can look to the encoder I made here: \n\n\nNow more interesting, let\u2019s wrap it with Play Iteratees:\n\n```scala\nval audio = MonoWaveEncoder() // instanciate the WAV encoder  \nval audioHeader = Enumerator(audio.header)  \nval audioEncoder = Enumeratee.map[Array[Double]](audio.encodeData)\n```\n\n***N. B.***: *Remember that Scala is a typed language but where the type declaration is optional because the compiler can infer the type.*\n\n**audioHeader** is an `Enumerator` which means it can *produce* data, and here the data is the audio header. More precisely it\u2019s an `Enumerator[Array[Byte]]` because audio.header is an `Array[Byte]`. Note that contained data is not \u201cconsumed\u201d like it would be for an `InputStream`. Each time you use this enumerator, it gives you its entire content.\n\n**audioEncoder** is an `Enumeratee[Array[Double], Array[Byte]]`. It takes an `Array[Double]` from input and returns an `Array[Byte]` as output. The input is a raw array of audio samples (double numbers between -1.0 and 1.0). The output is the encoded array of bytes.\n\nMore formally, an `Enumeratee[A, B]` is an *adapter* which maps some data of type A to new data of type B. You can implement the way the data is transformed with the map function. Here we just give it the `audio.encodeData` function.\n\n### Streaming it\n\nWe can basically stream the audio stream with Play2 like so:\n\n```scala\ndef stream = Action {  \n\xa0 val audioStream = rawStream &> audioEncoder  \n\xa0 Ok.stream(audioHeader >>> audioStream).  \n\xa0 \xa0 \xa0withHeaders( (CONTENT_TYPE, audio.contentType) )  \n}\n```\n\nThe `rawStream &> audioEncoder` takes the raw stream and **pipes** it into the encoder which results in the encoded audio stream. `audioHeader >>> audioStream` will **concatenate** `audioHeader` with `audioStream`. Hence, the first thing the server will do is start sending the audio header to the client **and then** stream the audio in real-time.\n\n**A client can connect at any time and will hear current stream**, so it should simultaneously hear the same thing as any other client (with some delay depending on the client buffer). If the generator stops emitting audio samples, the http client will stop receiving audio data \u2013 but it will still be waiting for the server, so the audio play will pause until the server re-sends new audio samples. **That is pretty cool!** \u2013 because of the way iteratees work, the stream doesn\u2019t just die when all of the input is consumed.\n\n#### A chunker to reduce HTTP packet numbers\n\nUp to now we\u2019ve been streaming the audio in **very small chunks** because by default JSyn writes out arrays of just 8 audio samples and the `.stream()` function consumes all data as it comes. This means *a lot* of HTTP chunks per second are sent \u2013 which is less efficient and take more bandwidth.\n\nIn order to fix this, we need to use a **buffer on the server side**. In other words, instead of sending audio samples as they come we need to **group audio samples**. We have currently grouped audio samples in arrays of 5000 which is quite reasonable (it\u2019s about 10 chunks per second using 44100 samples/s). We can easily change this later. This logic is implemented in an `Enumeratee` we called \u201cchunker\u201d. In that sense, it is reusable and modular:\n\n```scala\nval chunker = Enumeratee.grouped(  \n\xa0 Traversable.take[Array[Double]](5000) &>> Iteratee.consume()  \n)\n```\n\nAnd now, we can easily plug it in like this:\n\n```scala\ndef stream = Action {  \n\xa0 val chunkedAudioStream = rawStream &> chunker &> audioEncoder  \n\xa0 Ok.stream(audioHeader >>> chunkedAudioStream).  \n\xa0 \xa0 \xa0withHeaders( (CONTENT_TYPE, audio.contentType) )  \n}\n```\n\n### Broadcast\n\nNow, another improvement we made was to **factorize this chunking and encoding part: avoiding having this computing tasks done for every stream consumer**.\n\nBasically, we move it out of the stream function:\n\n```scala\nval chunkedAudioStream = rawStream &> chunker &> audioEncoder  \ndef stream = Action {  \n\xa0 Ok.stream(audioHeader >>> chunkedAudioStream).  \n\xa0 \xa0 \xa0withHeaders( (CONTENT_TYPE, audio.contentType) )  \n}\n```\n\nBut to allow broadcasting, we have to use a broadcast:\n\n```scala\nval chunkedAudioStream = rawStream &> chunker &> audioEncoder  \nval (sharedChunkedAudioStream, _) = \xa0=   \n\xa0 Concurrent.broadcast(chunkedAudioStream)  \ndef stream = Action {  \n\xa0 Ok.stream(audioHeader >>> sharedChunkedAudioStream).  \n\xa0 \xa0 \xa0withHeaders( (CONTENT_TYPE, audio.contentType) )  \n}\n```\n\nHere we only care about the enumerator (the left argument in the Tuple2), we put the wildcard "_" to ignore the return value.\n\n[![](/images/2012/07/320px-Broadcast.svg_.png)][19]\n\nUsing a broadcast, generated audio samples pushed by the audio generator can be simultaneously spread to multiple consumers. This is perfect for our needs, multiple players can connect to this web radio!\n\n### Avoiding the server load\n\nThe last important fix we made was to **avoid the server load**:\n\n```scala\n\xa0 def stream = Action {  \n\xa0 \xa0 Ok.stream(audioHeader >>> sharedChunkedAudioStream   \n\xa0 \xa0 \xa0 &> Concurrent.dropInputIfNotReady(50)).  \n\xa0 \xa0 \xa0 \xa0withHeaders( (CONTENT_TYPE, audio.contentType) )  \n\xa0 }\n```\n\nIf a client is opening the stream connection but doesn\u2019t consume enough or doesn\u2019t consume it at all (download is paused), the server will fill in memory the chunks to send to the client and the server can reach an *out of memory* exception. To avoid that **we have to drops chunks if the consumer is not ready**. Then the client will just lose messages if it is not ready (in our case, we give them 50 milliseconds).\n\nAnd this is what `Concurrent.dropInputIfNotReady(50)` is actually doing \u2013 with yet another **Enumeratee**! **Dropping old chunks is really what we want in an audio streaming application**: We want the consumer to subscribe to the current audio stream and not to continue from where they stopped.\n\n### Client consumers\n\n#### HTML5 Audio tag\n\nIn HTML5, we have the Audio tag \u2013 and we can just consume our stream like this:\n\n```html\n<audio src="/stream.wav"></audio>\n```\n\nOr if we want to make it auto loading:\n\n```html\n<audio src="/stream.wav" preload autoplay controls></audio>\n```\n\nIt may be a bit \u201cwrong\u201d to use `` for streaming, but it works because we are using it as if the server was hosting a static audio file. The only disputable hack is to have to set the max ChunkSize in the WAVE header which is 2147483647 (it\u2019s about 6 hours 45mn!), so the browser believes the audio is not finished.\n\nThe issue we are currently facing is this crazy latency (a few seconds) between user actions and the produced sound. This problem is due to the browser audio cache buffer: if we were able to minimize it we would have an almost real-time audio player.\n\n#### Playing it with VLC\n\nThis stream is spread through HTTP so we need a HTTP client to consume it. But a HTTP client doesn\u2019t mean only browsers! We can also use VLC for this, as if it was a web radio! One advantage of using VLC is it suffers far less latency (presumably because the cache buffer is smaller than the audio tag).\n\n![vlc](/images/2012/07/vlc.png)\n\n## Making the real-time control UI\n\nOur experiment **mixes different oscillators to generator one sound**. The web user interface allows a user to control the parameters of those. Two knobs control the **volume** and the **pitch** (tuned to a dorian mode scale) and you can select the oscillator **wave primitive** (sine, sawtooth, square, noise). It\u2019s not fancy at the moment \u2013 but JSYN offers a lot of features for expanding our simple demo.\n\n![](/images/2012/07/Capture-d\u2019\xe9cran-2012-07-31-\xe0-16.42.15.png)\n\nThis interface is **multi-users**, so if you use it with other people, **the interface will stay synchronized over multiple browsers** (turn the knobs, change the wave primitive, \u2026). All this is done with WebSockets, and on the server-side it\u2019s using, again, **Iteratees**!\n\nThe workflow is simple: When someone does some action on the user interface, events are sent to the server. These events are interpreted by the *ZoundGenerator* resulting in updates to the audio synthesis configuration. These events are then broadcast to each client, and some Javascript handlers are called in order to keep the interface synchronized.\n\n## Source code\n\n**[Fork me on Github][3]**\n\n## What\u2019s next?\n\nThis was just a simple demo to show the power and flexibility of Play2\u2032s Iteratee concept. Because of the modular nature, extending the demo is easy. For example, we could plug a new audio encoder such an OGG encoder. The code would be simple and we could even choose on a request-by-request basis which encoder to use:\n\n```scala\nimport Concurrent.broadcast  \nval (chunkedWaveStream, _) =   \n\xa0 broadcast(rawStream &> chunker &> waveEncoder)  \nval (chunkedOggStream, _) =   \n\xa0 broadcast(rawStream &> chunker &> oggEncoder)  \n  \ndef stream(format: String) = Action {  \n\xa0 val stream = format match {  \n\xa0 \xa0 case "wav" => waveHeader >>> chunkedWaveStream  \n\xa0 \xa0 case "ogg" => oggHeader >>> chunkedOffStream  \n\xa0 }  \n\xa0 Ok.stream(stream).  \n\xa0 \xa0 \xa0withHeaders( (CONTENT_TYPE, audio.contentType) )  \n}\n```\n\n**Now it\u2019s up to you!**\n\nHopefully you get a feel for the possibilities of stream processing and piping with Play. You can now reuse these concepts and make your own stuff: Maybe you don\u2019t need to generate sounds on the fly, but instead you simply want to play a collection of audio files and stream them like radio? **Well you can make a web radio engine now!**. \n\nBut that\u2019s just the beginning \u2013 I would love to see someone taking the concept, and running even further\u2026 Do you know that in Youtube, during the time you are uploading a video, Youtube is already re-encoding it and can start streaming it *before* the file has finished uploading? Hmm, that\u2019s starting to sound almost simple\u2026\n'},k1ej:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: HTML Canvas pour les n\xe9ophytes\ndescription: Cette vid\xe9o de 20 minutes pr\xe9sente les possibilit\xe9s du Canvas \xe0 travers quelques d\xe9mos et l\u2019impl\xe9mentation pas \xe0 pas d\u2019un exemple basique.\nauthor: Gaetan\nlayout: post\npermalink: /2011/03/html-canvas-pour-les-neophytes/\ntags:\n  - canvas\n  - html\n  - javascript\n---\n\n [1]: http://whatwg.org/html\n [2]: http://www.whatwg.org/specs/web-apps/current-work/multipage/the-canvas-element.html\n [3]: http://www.mrspeaker.net/dev/parcycle/\n [4]: http://en.inforapid.org/\n [5]: http://gre.github.io/same-game-gravity\n [6]: http://fizz.bloom.io/ \n [7]: http://easeljs.com/\n [8]: http://processingjs.org/ \n\nCette vid\xe9o de 20 minutes pr\xe9sente les possibilit\xe9s du Canvas \xe0 travers quelques d\xe9mos et l\u2019impl\xe9mentation pas \xe0 pas d\u2019un exemple basique.  \nElle est destin\xe9e \xe0 des d\xe9veloppeurs d\xe9butant dans l\u2019utilisation de Canvas.\n\n<iframe src="http://player.vimeo.com/video/20957255?portrait=0" width="550" height="410" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>\n\n*Dans la suite de l\u2019article : les liens et codes de la vid\xe9o \u2026*\n\n\x3c!--more--\x3e\n\n## Liens\n\n### Specs\n\n*   [whatwg.org/html][1]\n*   [Canvas][2]\n\n### Exemples\n\n*   [parcycle][3]\n*   [Visualisation des relations entre sujets (wikip\xe9dia)][4]\n*   [Same Game][5]\n*   [fizz : visualisation des tweets][6]\n\n### Biblioth\xe8ques graphiques\n\n*   [EaselJS][7]\n*   [Processing JS][8]\n\n\n## Exemple de l\u2019impl\xe9mentation\n\n```html\n<html>\n  <head>\n    <style>\n      body {\n        background: #ddd;\n      }\n      canvas {\n        background: #fff;\n      }\n    </style>\n  </head>\n  <body>\n    <canvas id="sketch" width="300" height="300"></canvas>\n    <img id="image" src="http://www.whatwg.org/images/logo" style="display: none;" />\n    \n    <script type="text/javascript">\n    (function(){\n      \n      var canvas = document.getElementById(\'sketch\');\n      var ctx = canvas.getContext(\'2d\');\n      var img = document.getElementById(\'image\');\n      \n      var i = 0;\n      setInterval(function() {\n        ctx.clearRect(0, 0, 300, 300);\n        \n        ctx.drawImage(img, 0, 0, 300, 300);\n        \n        ctx.fillStyle = \'rgba(255, 0, \'+Math.floor(Math.sin(i/50)*255)+\', 0.8)\';\n        ctx.fillRect(100, i % 300, 100, 100);\n        \n        /*\n        \n        ctx.strokeStyle = \'#09F\';\n        ctx.lineWidth = 5;\n        \n        ctx.beginPath();               // commence \xe0 tracer un chemin\n        ctx.moveTo(0, 20);             // d\xe9fini le premier point de tracage \xe0 la position (0, 20)\n        ctx.lineTo(canvas.width-100, 30);  // Tracer une ligne jusqu\'\xe0 la position (canvas.width, 30). canvas.width d\xe9signe la largeur du canvas (500 dans notre exemple).\n        ctx.bezierCurveTo(100, 200, 0, 100, 300, 300);\n        ctx.stroke();                  // Indique au canvas de dessiner le chemin trac\xe9 depuis le beginPath\n        \n        */\n        \n        ++ i;\n      }, 30);\n      \n    }());\n    <\/script>\n  </body>\n</html>\n```\n'},kG1y:function(e,n,t){"use strict";t.r(n),n.default=""},"kHt+":function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Play Painter \u2013 how i\'ve improved the 30 minutes prototyped version"\ndescription: One week ago, I\u2019ve released a web experiment featuring a collaborative Paint-like application made with Play Framework 2 and relying on WebSocket and HTML5 Canvas. Here is how I\'ve improved it.\nthumbnail: /images/2012/03/twitt_playpainter.png\nauthor: Gaetan\nlayout: post\npermalink: /2012/03/play-painter-how-ive-improved-the-30-minutes-prototyped-version/\ntags:\n  - canvas\n  - playframework\n  - websocket\n  - javascript\n---\n\nOne week ago, I\u2019ve released a [technical web experiment][1] featuring **a collaborative real-time Paint-like application I\u2019ve called Play Painter**. It has been made with [Play Framework 2][2] and rely on WebSocket and HTML5 Canvas Javascript APIs.\n\n[1]: /2012/03/30-minutes-to-make-a-multi-user-real-time-paint-with-play-2-framework-canvas-and-websocket/\n[2]: http://playframework.org/\n[4]: https://github.com/playframework/Play20/wiki/Iteratees\n[5]: https://github.com/gre/playpainter/blob/master/scala/app/controllers/Application.scala\n[6]: http://github.com/gre/playpainter\n[7]: http://playpainter.greweb.fr/\n[8]: https://github.com/gre/playpainter/issues/1\n[9]: https://twitter.com/dbathily\n\nThanks to everyone having tested my Play Painter experiment, you helped me figure out bugs and bottlenecks and to benchmark the application running on my tiny server.  \nThe first version of Play Painter has been improved with some optimizations.\n\nExplanation\u2026\n\n<blockquote class="twitter-tweet" lang="fr"><p>Thanks guys for testing playpainter! but you are breaking my server :D <a href="http://t.co/F62qwk1i" title="http://twitter.com/greweb/status/179194592481116160/photo/1">twitter.com/greweb/status/\u2026</a></p>&mdash; Ga\xebtan Renaudeau (@greweb) <a href="https://twitter.com/greweb/status/179194592481116160">12 mars 2012</a></blockquote>\n\n\x3c!--more--\x3e\n\n## In brief\n\n- **80 twitts**, **3500 unique visitors** in a few days.\n- a peak of about **80 simultaneous painters**.\n- about **200 WebSocket messages per second** when 3-4 users are drawing => bottleneck found.\n- when it occurs, 100% CPU and about **1500 system interrupts per second** on my poor Atom 1.2 Ghz server.\n\n## Some reasons\n\nThe initial version of Play Painter was a basic fast-prototyped version:\n\nFirst, It was **spreading every mouse events** (down, up, move) to all clients **as fast as it comes**. It means that, depending on the computer and browser performance, a huge number of events could have been triggered and spread to all connected users.\n\nWe solved this by **Chunking draw events**.\n\nSecond, **a lot of informations was repeated in WebSocket messages.** No datas were stored on the server-side so to be sure a new user see the right draws, player name, brush color and size was sent in every message. Multiply this by the number of mouse events and you get a lot of useless information!\n\nWe are now **Storing painters information**.\n\n## Chunking draw events\n\nWhen an user starts drawing, mouse events give the brush positions (x, y). But instead of sending a websocket message for each of these new positions, they are stored, and every **X** milliseconds, are sent in a websocket message. Such message contains all points of the draw from the last sent draw message.\n\nThe **X** value has currently been fixed to **50 milliseconds** because it\u2019s enough for the human eye: It means about 20 messages per second for one painter. In movies we usually have a 24 frame rate.\n\nThe same principle has been applied on the painter brush positions.\n\n### Example\n\n**Before**  \n13 WebSocket messages:\n\n```javascript\n{"type":"lineTo","x":181,"y":259,"pid":19}\n{"type":"lineTo","x":183,"y":259,"pid":19}\n{"type":"lineTo","x":184,"y":257,"pid":19}\n{"type":"lineTo","x":187,"y":257,"pid":19}\n{"type":"lineTo","x":188,"y":257,"pid":19}\n{"type":"lineTo","x":191,"y":256,"pid":19}\n{"type":"lineTo","x":192,"y":255,"pid":19}\n{"type":"lineTo","x":192,"y":255,"pid":19}\n{"type":"lineTo","x":192,"y":254,"pid":19}\n{"type":"lineTo","x":193,"y":254,"pid":19}\n{"type":"lineTo","x":195,"y":254,"pid":19}\n{"type":"lineTo","x":196,"y":253,"pid":19}\n{"type":"lineTo","x":196,"y":253,"pid":19}\n```\n\n**After**  \n2 WebSocket messages: (50 ms apart)\n\n```javascript\n{"type":"trace","points":[{"x":181,"y":259},{"x":183,"y":259},{"x":184,"y":257},{"x":187,"y":257},{"x":188,"y":257},{"x":191,"y":256},{"x":192,"y":255}],"pid":19}\n{"type":"trace","points":[{"x":192,"y":255},{"x":192,"y":254},{"x":193,"y":254},{"x":195,"y":254},{"x":195,"y":253},{"x":196,"y":253},{"x":196,"y":253}],"pid":19}\n```\n\n### To a variable frame rate?\n\nI am also thinking about a variable rate depending of the number of active painters. In fact, the more we have painters, the more we will have messages, and the more the server will have system interrupts, we could then decrease the frame rate per second to reduce this load.\n\nThe problem of this extreme approach is the degradation of the feeling of real-time.\n\nFor now, I\u2019m keeping the constant frame rate version, we will see how far it goes.\n\n## Storing painters information\n\nAs I said, **a lot of informations was repeated in WebSocket messages.** In every draw events, painter name, brush size and brush color was sent from the client to the server, and the spread into all connected clients.\n\nThis was ok for prototyping but we have now optimize this by storing these painter generic informations in the server and sending them when a new WebSocket connection is opened.\n\n### Example\n\nThis is what a client can receive when a websocket is connected:\n\n```javascript\n{"type":"youAre","pid":24}\n{"name":"john","color":"red","size":5,"type":"painter","pid":21}\n{"name":"gre","color":"red","size":5,"type":"painter","pid":24}\n{"name":"peter","color":"red","size":5,"type":"painter","pid":4}\n{"name":"paul","color":"red","size":5,"type":"painter","pid":6}\n{"name":"jack","color":"red","size":5,"type":"painter","pid":2}\n```\n\nand then\u2026\n\n```\n{"type":"trace","points":[{"x":181,"y":259},{"x":183,"y":259},{"x":184,"y":257}],"pid":19}\n...\n```\n\nBy knowing all painter properties, when someone will draw something, he will not have to repeat which color and size its brush has.\n\n### Server side\n\nIt was quite interesting to implement the server part with [Play2\u2032s Iteratees][4], a new way of handling I/O \u2013 not so new in fact because it is directly related to Haskell Iteratee concepts.\n\nTo implement a WebSocket connection, you will provide an **Iteratee** for consuming the **input** and an **Enumerator** for producing the **output**.\n\nEnumerator are chainable, this is how I firstly send the painter id and painters informations:\n\n```scala\n// out: handle messages to send to the painter\nval out =\n\xa0 // Inform the painter who he is (which pid, he can them identify himself)\n\xa0 Enumerator(JsObject(Seq("type" -> JsString("youAre"), "pid" -> JsNumber(pid))).as[JsValue]) >>>\n\xa0 // Inform the list of other painters\n\xa0 Enumerator(painters.map { case (id, painter) =>\n\xa0 \xa0 (painter.toJson JsObject(Seq("type" -> JsString("painter"), "pid" -> JsNumber(id)))).as[JsValue]\n\xa0 } toList : _*) >>>\n\xa0 // Stream the hub\n\xa0 hub.getPatchCord()\n```\n\nThe **>>>** operator is a shortcut to the **andThen** method which is the way to chain enumerators.\n\nFor more details, [see the scala code of the controller][5].\n\n## Other features\n\nThe application has been improved in many other ways.\n\n- **A \u201cbuffering\u201d Canvas** in the foreground has been add **for the user draws**. It brings client-side reactivity and helps to avoid unpleasant lag feeling when drawing. When the user draw events are coming from the server and no other user events has been sent since, it\u2019s synchronized and we can clean this buffer.\n- **Painter positions are show with their names**.\n- It should now work properly on **smartphones and tablets**. Try on iPad and iPhone, and maybe on recent version of Android (WebSocket support required).\n- **Keyboard shortcut**: using arrows to change brush size and color.\n- The **[source code][6] has been polished and commented** especially the server side part (it\u2019s probably the hardest part if you don\u2019t know Play framework).\n- Error message displayed when a technology is not supported and when the WebSocket connection goes down (with a reconnecting try loop).\n\n## The demo is still online!\n\n**[playpainter.greweb.fr][7]**\n\n## Future\n\nWith these two optimizations, I\u2019ve reduce the global **number of socket messages** and also the **size of each message**.\n\nThe first benchmark sounds good, 3 painters was simultaneously crazily painting while the server application was only using less than 10% of CPU.\n\nNow, the most challenging part would be to scale the application to a huge number of connections, but having maybe solved this bottleneck, it\u2019s maybe now more a matter of system architecture than the application itself.\n\nThis experiment gave me a lot of interest in **WebSocket** and also in **the powerful way WebSockets are handled in Play framework**.\n\nIf anyone want to start a Java version of the application, please go on! [(this was requested on Github)][8]\n\nThanks to [@dbathily][9], we know have both Scala and Java version!\n\n### Next experiment\n\nI am thinking about making a multiplayer game on the web.  \nIt would be something like a shooter survival game (like Counter Strike Zombie Mod) a multi-plateform 2D side view game (like Mario) !\n\nYou will know more about this soon!\n'},krhY:function(e,n,t){"use strict";t.r(n),n.default="---\ntweet: https://twitter.com/greweb/status/1382954321214590980\ntags:\n  - lines\n---\n"},kru4:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Cross sines"\nthumbnail: /images/plots/133.jpg\ndescription: "A simple experiment with crosses and sine waves. Fountain Pens with Pink and Turquoise ink on Bristol A4."\ntags:\n  - cross\n---\n\nA simple experiment with crosses and sine waves. Fountain Pens with Pink and Turquoise ink on Bristol A4.\n\nalso tried with brush pens to try what happens with a 45\xb0 slope & unpredactibility:\n\n<img src="/images/plots/133bis.jpg" width="100%"/>\n'},kyr6:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Diamond noise"\nthumbnail: /images/plots/147.jpg\ndescription: "Drawing a lot of diamond in pink and blue with dimensions varying based on perlin noise."\ntags:\n  - perlin\n---\n\nDrawing a lot of diamond in pink and blue with dimensions varying based on perlin noise.'},l4gz:function(e,n,t){"use strict";t.r(n),n.default=""},lQeP:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "hexafold planet"\nthumbnail: "/images/plots/130.jpg"\ndescription: "Exploring a spiral transitioning between two parametric functions to create an hexagonal fold effect. Addition of perlin noise to offset a bit two similar spirals. Fountain pen on A4 Bristol."\ntags:\n  - parametric\n---\n\nExploring a spiral transitioning between two parametric functions to create an hexagonal fold effect. Addition of perlin noise to offset a bit two similar spirals. Fountain pen on A4 Bristol.\n\n<img width="100%" src="/images/plots/130_zoom.jpg"/>\n'},lZcA:function(e,n,t){"use strict";t.r(n),n.default="---\ntweet: https://twitter.com/greweb/status/1381338159573794823\ntags:\n  - planet-holes\n---\n"},liTY:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Ring of faces (8 frames)"\nthumbnail: "/images/plots/171.gif"\ndescription: "8 frames plotted making an animated loop. A 1920p video and A4 physical art is available as an NFT."\ntags:\n  - plotloop\n  - apophenia\nobjkts:\n  - 144002\n---\n\nHere is "Ring of faces" my 8th ["plot loop" (see article)](https://greweb.me/2021/05/plot-loops). The main digital art is a 1920p video loop of 8 frames available as a [Tezos hicetnunc NFT](https://www.hicetnunc.xyz/objkt/144002). The physical art is 8 frames of A4 size, plotted with a black fountain pen on 300 g/m2 grain paper, and offered when [buying the NFT](https://www.hicetnunc.xyz/objkt/144002) (8 editions, assigned in buy order).\n\n<img src="/images/plots/171zoom1.jpg" width="100%">\n\nThe name \'Ring of faces\' refers to generating different silhouettes of faces from pure noise. The work involved here is purely generative art (nothing draw manually). I had a selection phase where I chose this one among 100 results.\n\nI like these eight plots series because there are many unique faces here. You can even imagine faces in the inner area. That is purely a reflection of your own imagination.\n\nI also played a lot with this duality to put twice the art in inversed coloring filling mode as well as having a rotation. The animation between the two tiles is offset exactly by 50% while also allowing a good variety and similarity when you buy one specific frame.\n\nI used a high grain paper this time which works well with the cross-hatching filling method used, also thanks to a not too crowded area. I usually would avoid such paper for fountain pens that can "bleed" too much on it. It\'s time to do it more in the future!\n\n<img src="/images/plots/171zoom2.jpg" width="100%">\n\nThe general animation is inspired by a shader I wrote https://greweb.me/shaderday/68\n\n<img src="/images/plots/171all.jpg" width="100%">\n\nThe effect called \'Apophenia\' is, in this case, our ability to recognize a face silhouette in pure noise.\n\nI see these different silhouettes:\n- an indigenous face\n- Churchill\n- a bearded man\n- a woman\n\nGo figure why.'},licy:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "packing hexagons in hexagons"\nthumbnail: /images/plots/184.jpg\ndescription: "Packing 3963 filled hexagons in hexagons. 2 hours of plotting with fountain pens on watercolor 300g/m paper."\ntags:\n  - shape-packing\n---\n\nA total of 11307 hexagons are drawn with a fountain pen to fill 3963 hexagons. The shapes are themselves positioned in hexagons. It takes 2 hours to perform on the speed I chose for a watercolor 300g/m paper. The ink changes color due to the amount of ink flow (it flows less and less). The ink is \'Bloody Brexit\' and **there is only this one ink used!**.\n\n<img src="/images/plots/184zoom.jpg" width="100%">\n\n<img src="/images/plots/bloodybrexit.jpg" width="100%">'},mFDB:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "squares packing 001"\nthumbnail: /images/plots/179.jpg\ndescription: "Packing rotated squares in a square. Black fountain pens on Bristol."\ntags:\n  - shape-packing\n---\n\nPacking rotated squares in a square. Black fountain pens on Bristol. Interestingly one square didn\'t draw due to ink issues. It makes the final art pretty unique!\n\n## Technical notes\n\nThe algorithm brute-forces with 1 million iterations to find square location, for each iteration it will then search for the biggest square that can fit in the location space. I didn\'t even implemented dichotomic search for finding the square scale (it\'s a simple loop) but the overall script runs relatively fast in Rustlang (less than 10 seconds).\n\n**main loop**\n\n```rust\nlet mut polys = Vec::new();\nlet mut rng = rng_from_seed(opts.seed);\nfor i in 0..1000000 {\n    let x: f64 = rng.gen_range(bounds.0, bounds.2);\n    let y: f64 = rng.gen_range(bounds.1, bounds.3);\n    let a: f64 = rng.gen_range(0.0, 8.0);\n    if let Some(size) = poly_square_scaling_search(bounds, &polys, x, y, a, min_threshold) {\n        let poly = rotated_square_as_polygon(x, y, size - pad, a);\n        polys.push(poly);\n    }\n    if polys.len() > desired_count {\n        break;\n    }\n}\n```\n\n**search**\n\n```rust\nfn poly_square_scaling_search(\n    boundaries: (f64, f64, f64, f64),\n    polys: &Vec<Polygon<f64>>,\n    x: f64,\n    y: f64,\n    angle: f64,\n    min_threshold: f64\n) -> Option<f64> {\n    let mut size = 0.1;\n    let dsize = 0.1;\n    // TODO dichotomic search could help perf here...\n    loop {\n        let poly = rotated_square_as_polygon(x, y, size, angle);\n        let bounds = poly.bounding_rect().unwrap();\n        let topleft: Point<f64> = bounds.min().into();\n        let bottomright: Point<f64> = topleft + point!(\n            x: bounds.width(),\n            y: bounds.height()\n        );\n        if out_of_boundaries(topleft.x_y(), boundaries) || out_of_boundaries(bottomright.x_y(), boundaries) {\n            break;\n        }\n        if poly_collides_in_polys(polys, &poly) {\n            break;\n        }\n        size += dsize;\n    }\n    if size < min_threshold {\n        return None;\n    }\n    return Some(size);\n}\n```'},mRba:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Spring (8 frames)"\nthumbnail: /images/plots/157.gif\ndescription: "8 frames plotted making an animated loop. A 1920p video and A4 physical art is available as an NFT."\ntags:\n  - parametric\n  - plotloop\nobjkts:\n  - 117072\n---\n\n\x3c!--\n@greweb\'s #6 plot loop. The 1920p animation is the main digital art. NFT is available in 8 editions, one per frame. First buyer of each edition can collect related frame to acquire the physical art (selected by buy order. PM @greweb, ship anywhere in the world). Secondary market is digital only. plotted on A4 Bristol paper with fountain pen. See greweb.me/plots/157\n--\x3e\n\nHere is "Spring", my 6th [**plot loop**](/plots/tags/plotloop) [(see article)](https://greweb.me/2021/05/plot-loops). **The main digital art is a 1920p video loop of 8 frames available as a [Tezos hicetnunc NFT](https://www.hicetnunc.xyz/objkt/117072)**. The physical art are the 8 frames, plotted with 2 fountain pens on Bristol A4 paper (250g), and offered when [buying the NFT](https://www.hicetnunc.xyz/objkt/117072).\n\nThere are 8 plots available for sale and there will be no other editions of these plot loop frames. They all have the same inital price and the physical piece is selected in order of buy as each frame is relatively similar!\n\n### Closer look\n\nThe ink "Bloody Brexit" from Diamine have particularity to have coppery color reflections.\n\n<img src="/images/plots/157zoom1.jpg" width="100%">\n<img src="/images/plots/157zoom2.jpg" width="100%">\n<img src="/images/plots/157zoom3.jpg" width="100%">\n\n## Making off\n\nHere is a video of the plot, accelerated 5x.\n\n<iframe width="100%" height="400" src="https://www.youtube.com/embed/UBzsr0CcrSk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>\n\nBefore that result, I had many iterations and 3 prototypes where I adjusted many parameters each time:\n\n<img src="/images/plots/157proto1.jpg" width="100%">\n<img src="/images/plots/157proto2.jpg" width="100%">\n<img src="/images/plots/157proto3.jpg" width="100%">\n\nI also had this failure: (forgot to attach the paper!)\n\n<img src="/images/plots/157fail.jpg" width="100%">\n'},mVQU:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Blurry waves"\ndescription: "Yet another parametric stack, noisy one this time! white uniball on black A4."\nthumbnail: /images/plots/119.jpg\ntags:\n  - parametric\n---\n\nThis is, like [plot#114](/plots/114), yet another parametric "stack" (using parametric at different scales).\nThis time, the parametric is very noisy. There is a desired effect to make a blur illusion. It\'s very fuzzy. I have some glitches on the signature but it\'s part of the art now!\n'},mpv1:function(e,n,t){"use strict";const a=t("tfEw");e.exports=function(e,n){const t=a(n);if(null==e.data&&(e.data={}),"function"===typeof t.excerpt)return t.excerpt(e,t);const i=e.data.excerpt_separator||t.excerpt_separator;if(null==i&&(!1===t.excerpt||null==t.excerpt))return e;const o="string"===typeof t.excerpt?t.excerpt:i||t.delimiters[0],r=e.content.indexOf(o);return-1!==r&&(e.excerpt=e.content.slice(0,r)),e}},"mv/Q":function(e,n,t){"use strict";var a;try{a=t("HDXh").Buffer}catch(r){}var i=t("NdRM"),o="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\n\r";e.exports=new i("tag:yaml.org,2002:binary",{kind:"scalar",resolve:function(e){if(null===e)return!1;var n,t,a=0,i=e.length,r=o;for(t=0;t<i;t++)if(!((n=r.indexOf(e.charAt(t)))>64)){if(n<0)return!1;a+=6}return a%8===0},construct:function(e){var n,t,i=e.replace(/[\r\n=]/g,""),r=i.length,s=o,l=0,c=[];for(n=0;n<r;n++)n%4===0&&n&&(c.push(l>>16&255),c.push(l>>8&255),c.push(255&l)),l=l<<6|s.indexOf(i.charAt(n));return 0===(t=r%4*6)?(c.push(l>>16&255),c.push(l>>8&255),c.push(255&l)):18===t?(c.push(l>>10&255),c.push(l>>2&255)):12===t&&c.push(l>>4&255),a?a.from?a.from(c):new a(c):c},predicate:function(e){return a&&a.isBuffer(e)},represent:function(e){var n,t,a="",i=0,r=e.length,s=o;for(n=0;n<r;n++)n%3===0&&n&&(a+=s[i>>18&63],a+=s[i>>12&63],a+=s[i>>6&63],a+=s[63&i]),i=(i<<8)+e[n];return 0===(t=r%3)?(a+=s[i>>18&63],a+=s[i>>12&63],a+=s[i>>6&63],a+=s[63&i]):2===t?(a+=s[i>>10&63],a+=s[i>>4&63],a+=s[i<<2&63],a+=s[64]):1===t&&(a+=s[i>>2&63],a+=s[i<<4&63],a+=s[64],a+=s[64]),a}})},mx6s:function(e,n,t){"use strict";const a=t("VQEG"),i=t("tfEw");e.exports=function(e,n,t){const o=i(t),r=a(e,o);if("function"!==typeof r.parse)throw new TypeError('expected "'+e+'.parse" to be a function');return r.parse(n,o)}},mzFX:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Functional Rendering\'\ndescription: "This talk explains how to think the rendering in a more functional way. Let\'s see how we can just do things with a function of (Vec2 => Color)."\nauthor: Gaetan\nlayout: post\ntags:\n - functional\n - rendering\n - GLSL\n---\n\n[Gamelier]: http://gamelier.org/gaetan-renaudeau-on-procedural-vs-functional-rendering/\n[slides]: http://greweb.me/prez-functional-rendering\n\nI\'ve done a talk at **[Gamelier][Gamelier]** last Monday about \nhow to think the **rendering** in a more **functional** way.\n\n## Abstract\n\nMost of today 2D graphics libraries restrict us to a set of primitive procedures (`drawRect`, `drawCircle`, `drawImage`,...) but when it comes to bring more interesting features you tends to be stuck with it. Let\'s see how we can just do things with a function of `(Vec2 => Color)`.\n\nThis is the way (*WebGL*) **GLSL** has already took and the presentation examples will be built on it.\nLet\'s see what are the multiple benefits of taking that paradigm of rendering.\n\n## Talk\n\n<iframe src="//player.vimeo.com/video/78804695?title=0&amp;byline=0&amp;portrait=0" width="600" height="337" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n\n### [Open the slides][slides]\n\n## Checkout more presentations at Gamelier.org\n\n[![](/images/2013/11/gamelier.png)][Gamelier]\n'},n0UO:function(module,exports,__webpack_require__){"use strict";const yaml=__webpack_require__("0JaZ"),engines=exports=module.exports;engines.yaml={parse:yaml.safeLoad.bind(yaml),stringify:yaml.safeDump.bind(yaml)},engines.json={parse:JSON.parse.bind(JSON),stringify:function(e,n){const t=Object.assign({replacer:null,space:2},n);return JSON.stringify(e,t.replacer,t.space)}},engines.javascript={parse:function parse(str,options,wrap){try{return!1!==wrap&&(str="(function() {\nreturn "+str.trim()+";\n}());"),eval(str)||{}}catch(err){if(!1!==wrap&&/(unexpected|identifier)/i.test(err.message))return parse(str,options,!1);throw new SyntaxError(err)}},stringify:function(){throw new Error("stringifying JavaScript is not supported")}}},nNS1:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Parametric spiral on fire"\nthumbnail: "/images/plots/125.jpg"\ndescription: "parametric function and perlin noise. Brush pen with Bloody Brexit ink on A4 bristol."\ntags:\n  - parametric\n---\n\nparametric function and perlin noise. Brush pen with Bloody Brexit ink on A4 bristol.\n'},nQk3:function(e,n,t){"use strict";t.r(n),n.default=""},nSud:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Ink fabrics"\nthumbnail: "/images/plots/141.jpg"\ndescription: "Drop inks on simple robotic motions and let the medium speak."\n---\n\nDrop inks on simple robotic motions and let the medium speak.\n\nI\'ve used two different inks: Pink and Turquoise. The Pink ink ended up turning orange when it met a bit of the Turquoise\'s ink because chemistry!\n\n<img width="100%" src="/images/plots/141inks.jpg"/>\n\nThese are some other interesting plots with similar roboting actions.\n\n<img width="100%" src="/images/plots/141b.jpg"/>\n<img width="100%" src="/images/plots/141c.jpg"/>\n<img width="100%" src="/images/plots/141d.jpg"/>\n'},naOd:function(e,n,t){"use strict";t.r(n),n.default=""},niBl:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Bezier Curve based easing functions \u2013 from concept to implementation"\ndescription: Many animation libraries are today using easing functions \u2013 functions of time returning a progression percentage value. We will see how we can generalize them with bezier curves.\nthumbnail: /images/2012/02/bezier_transition_editor.png\nauthor: Gaetan\nlayout: post\npermalink: /2012/02/bezier-curve-based-easing-functions-from-concept-to-implementation/\ntags:\n  - animation\n  - bezier\n  - css\n  - javascript\n---\n\n[1]: /images/2012/02/Capture-d\u2019\xe9cran-2012-02-29-\xe0-11.26.01.png "Bezier example"\n[2]: /images/2012/02/TimingFunction.png\n[3]: http://13thparallel.com/archive/bezier-curves/\n[4]: http://en.wikipedia.org/wiki/Newton%27s_method\n[5]: http://en.wikipedia.org/wiki/Dichotomic_search\n[6]: http://sliderjs.org/\n[7]: http://en.wikipedia.org/wiki/Inventor\'s_paradox\n[8]: /2012/02/bezier-curve-based-easing-functions-from-concept-to-implementation/ "Bezier Curve based easing functions \u2013 from concept to implementation"\n\n> **EDIT 2014:** This article ends up in an updated library available on [NPM](http://npmjs.org/package/bezier-easing) (`bezier-easing`) and available on [Github](https://github.com/gre/bezier-easing). It has been used by Apple for the [mac-pro page](http://www.apple.com/mac-pro/) and by [Velocity.js](http://velocityjs.org/). You can also find its usage in the [glsl-transition examples](http://greweb.me/glsl-transition/example/).\n\n<img src="/images/2012/02/bezier_transition_editor.png" class="thumbnail-left" />\n\nMany animation libraries are today using **easing functions** \u2013 functions of time returning a progression percentage value. This is required to perform such cool effects:\n\n<iframe src="/demo/simple-easing-animation/" height="50" width="50%"></iframe>\n\nBut most of these libraries implement a huge collection of functions. We will see how we can generalize them with bezier curves.\n\n\x3c!--more--\x3e\n\nFor instance, we use to do this:\n\n```javascript\nEasingFunctions = {\n  linear: function (t) {\n    return t;\n  },\n  easeInQuad: function (t) {\n    return t * t;\n  },\n  easeOutQuad: function (t) {\n    return t * (2 - t);\n  },\n  easeInOutQuad: function (t) {\n    return t < 0.5 ? 2 * t * t : -1 + (4 - 2 * t) * t;\n  },\n  easeInCubic: function (t) {\n    return t * t * t;\n  },\n  easeOutCubic: function (t) {\n    return --t * t * t + 1;\n  },\n  easeInOutCubic: function (t) {\n    return t < 0.5 ? 4 * t * t * t : (t - 1) * (2 * t - 2) * (2 * t - 2) + 1;\n  },\n  easeInQuart: function (t) {\n    return t * t * t * t;\n  },\n  easeOutQuart: function (t) {\n    return 1 - --t * t * t * t;\n  },\n  easeInOutQuart: function (t) {\n    return t < 0.5 ? 8 * t * t * t * t : 1 - 8 * --t * t * t * t;\n  },\n  easeInQuint: function (t) {\n    return t * t * t * t * t;\n  },\n  easeOutQuint: function (t) {\n    return 1 + --t * t * t * t * t;\n  },\n  easeInOutQuint: function (t) {\n    return t < 0.5 ? 16 * t * t * t * t * t : 1 + 16 * --t * t * t * t * t;\n  },\n};\n```\n\nDefining such functions is lot of math fun but it is very **specific** and not really customizable. Hopefully, we can generalize these easing functions. With **Bezier curves**.\n\nIn fact, this work has already been done in CSS Transitions and CSS Animations specifications! You can use `transition-timing-function` CSS property and give a `cubic-bezier(x1, y1, x2, y2)` value (all **ease, linear, ease-in, ease-out, ease-in-out** values are just fallbacking on this cubic-bezier usage).\n\n![][2]\n\nIn a bezier curve based easing function, the X axis is the **time axis** whereas the Y axis represents the **percentage of progress** of the animation.  \nThe two points P1 and P2 are called **handles** and you can (exclusively) control their X and Y positions to generate every possible cubic timing function.\n\n### Live demo\n\nTry to interact with the handles:\n\n<iframe src="/demo/bezier-easing/" frameborder="0" width="560" height="400"></iframe>\n\n## Implementation\n\nOk, so, this bezier curve concept is great but how can I implement it?\n\nI\u2019ve read [here][3] how simple is it to **compute many points of a Bezier curve** and potentially draw them:\n\n```javascript\nfunction B1(t) {\n  return t * t * t;\n}\nfunction B2(t) {\n  return 3 * t * t * (1 - t);\n}\nfunction B3(t) {\n  return 3 * t * (1 - t) * (1 - t);\n}\nfunction B4(t) {\n  return (1 - t) * (1 - t) * (1 - t);\n}\nfunction getBezier(percent, C1, C2, C3, C4) {\n  var pos = new coord();\n  pos.x =\n    C1.x * B1(percent) +\n    C2.x * B2(percent) +\n    C3.x * B3(percent) +\n    C4.x * B4(percent);\n  pos.y =\n    C1.y * B1(percent) +\n    C2.y * B2(percent) +\n    C3.y * B3(percent) +\n    C4.y * B4(percent);\n  return pos;\n}\n```\n\nBut it\u2019s not enough. We need to project a point to the Bezier curve, in other words, we need to get the Y of a given X in the bezier curve, and we can\u2019t just get it with the `percent` parameter of the Bezier computation.  \n**We need an interpolation.**\n\n### Deep into Firefox implementation\n\nIn Mozilla Firefox, The bezier curve interpolation is implemented in nsSMILKeySpline.cpp : .\n\nWhat we can learn from it is:\n\n- A first optimization store **sample values of the bezier curve** in a small table used to roughly find a initial X guess.\n- Then, it use two different implementation strategies: One use the [Newton\u2019s method][4] and the other is just a [dichotomic search][5] (binary subdivision).\n- A **criteria** based on the **slope** give the best strategy to take.\n\nThese sub-optimizations probably make the difference for the C++ version but are not really relevant for the JavaScript implementation. Moreover, I have only used the Newton\u2019s method algorithm.  \nAnd this is the code:\n\n<script src="https://gist.github.com/1926947.js?file=KeySpline.js"><\/script>\n\nNow we can just alias some classic easing function \u2013 like CSS does.\n\n<script src="https://gist.github.com/1926947.js?file=EasingFunctions.json"><\/script>\n\nI\u2019m working on the next version of [Slider.JS][6] which relies on 3 different technologies for image transitions: **CSS Transitions**, **Canvas** and **GLSL shaders (from WebGL)**.\n\n---\n\nI have now found **a common way to describe easing functions for both CSS-based and Javascript-based animations**!\n\nThis example has shown that sometimes, finding a larger solution for a problem is more interesting than having specific solutions.  \n**This is called the [Inventor\u2019s paradox][7].**\n'},nlun:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: Releasing Same Game Gravity (Android)\ndescription: Following on from the success of my Same game made in HTML5 Canvas, I\u2019ve decided to extend it to a (web) mobile game.\nauthor: Gaetan\nlayout: post\npermalink: /2011/04/releasing-same-game-gravity-android/\ntags:\n  - mobile\n  - gamedev\n  - canvas\n---\n# \n\nFollowing on from the success of my Same game made in HTML5 Canvas, I\u2019ve decided to extend it to a (web) mobile game.\n\nIt\u2019s now available on Android market.\n\nMore infos on <http://gre.github.io/same-game-gravity>.\n\n<iframe width="640" height="360" src="http://www.youtube.com/embed/Qyd69g9hmIY?feature=player_embedded" frameborder="0" allowfullscreen></iframe>\n\nThis ball removal puzzle game is made with HTML5 technologies and PhoneGap. Source code will be published within a few months.\n'},noTo:function(e,n,t){"use strict";t.r(n),n.default=""},nrZ5:function(e,n,t){"use strict";t.r(n),n.default=""},p5BC:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: 30 minutes to make a multi user real time paint with Play 2 framework, Canvas and WebSocket.\ndescription: "[VIDEO] I will show you how to implement a multi user paint using latest web technologies like Play framework (version 2), HTML5 Canvas and WebSocket."\nthumbnail: /images/2012/03/playpainter_teaser2.png\nauthor: Gaetan\nlayout: post\npermalink: /2012/03/30-minutes-to-make-a-multi-user-real-time-paint-with-play-2-framework-canvas-and-websocket/\ntags:\n  - canvas\n  - javascript\n  - playframework\n  - websocket\n---\n\n [1]: http://playpainter.greweb.fr/\n [2]: http://playframework.com\n [3]: http://www.whatwg.org/specs/web-apps/current-work/multipage/the-canvas-element.html\n [4]: http://dev.w3.org/html5/websockets/\n [5]: /2012/03/play-painter-how-ive-improved-the-30-minutes-prototyped-version/\n [6]: https://github.com/gre/playpainter\n\n[  \n<img src="/images/2012/03/playpainter_teaser2.png" alt="" class="thumbnail-left" />\n][1]\n\n> I will show you how to **implement a multi user paint** using latest web technologies like [Play framework][2] (version 2), [HTML5 Canvas][3] and [WebSocket][4].\n\n\nLet\u2019s see how to implement this from scratch in about 30 minutes\u2026\n\n<iframe width="640" height="360" src="http://www.youtube.com/embed/NHEbm-WEbRw?feature=player_embedded" frameborder="0" allowfullscreen></iframe>\n\n\x3c!--more--\x3e\n\n[and read how I\u2019ve improved this initial version\u2026][5]\n\n[or try the demo below\u2026][1]\n\n<iframe frameborder="0" src="http://playpainter.greweb.fr/" width="550" height="501" style="overflow: hidden; max-width: 550px"></iframe>\n\n[Fork me on Github.][6]\n'},pPTr:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: How to deploy your play applications on ArchLinux with daemons\ndescription: "This video shows how to run different instances of Play framework server in the most Linux friendly way: using daemons. Example with ArchLinux, using yaourt, the playframework AUR package and nginx."\nauthor: Gaetan\nlayout: post\npermalink: /2011/10/how-to-deploy-your-play-applications-on-archlinux-with-daemons/\ntags:\n  - sysadmin\n  - linux\n  - playframework\n---\n\n [1]: http://playframework.org\n [2]: http://aur.archlinux.org/packages.php?ID=45541\n [3]: http://nginx.org\n [4]: https://wiki.archlinux.org/index.php/Play_framework\n\nThis video shows how to run different instances of [Play framework][1] server in the most Linux friendly way: using daemons. Example with ArchLinux, using yaourt, the [playframework AUR package][2] and [nginx][3].\n\n<iframe src="http://player.vimeo.com/video/30603225?title=0&amp;byline=0&amp;portrait=0" width="400" height="300" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>\n\n# Some links\n\n*   [Play framework website][1]\n*   [Play framework Archlinux documentation][4]\n*   [Play framework AUR package][2]\n\n\x3c!--more--\x3e\n\n# Abstract summary\n\n## Introduction\n\nExisting Platform as a Service: [Playapps.net][5], [Heroku.com][6].\n\n [5]: http://playapps.net\n [6]: http://heroku.com\n\nOur needs are quite different: you sometimes need to have your own server on your own infrastructure and not depending on third party web services.\n\nLet\u2019s see how to deploy some play applications from scratch with ArchLinux.\n\n## Requirement\n\n[Install ArchLinux on your server][7]\n\n [7]: http://archlinux.org\n\n[Install yaourt][8]\n\n [8]: http://archlinux.fr/yaourt-en\n\n## Installation\n\n```bash\nyaourt -S playframework\n```\n\n## Creating 2 play framework applications\n\n```bash\nmkdir sites && cd sites  \nplay new app1  \nplay new app2 # editing app/views/\n```\n\n## Configuring daemons\n\n```bash\ncd /etc/rc.d  \nln -s skeleton_playapp app1  \nln -s skeleton_playapp app2  \ncd /etc/conf.d  \ncp playapp_sample app1  \ncp playapp_sample app2  \nvim app1 # configure variables  \nvim app2 # configure variables\n```bash\n\nFor app1 :\n\n```bash\nPLAY_APP=/home/gre/sites/app1  \nPLAY_USER=gre  \nPLAY_ARGS="--%prod --http.port=9001" \n```\n\nFor app2 :\n\n```bash\nPLAY_APP=/home/gre/sites/app2  \nPLAY_USER=gre  \nPLAY_ARGS="--%prod --http.port=9002" \n```\n\n## Starting daemons\n\n```bash\nrc.d start app1  \nrc.d start app2\n```\n\nMake it permanent in /etc/rc.conf by adding them in the DAEMONS variable.\n\n```bash\n...\nDAEMONS=(... app1 app2) \n```\n\n## Nginx, as a front end proxy server\n\nInstall nginx using pacman.\n\nEdit `/etc/nginx/conf/nginx.conf`\n\n```nginx\n...  \n\xa0 \xa0 server {  \n\xa0 \xa0 \xa0 \xa0 listen 80;  \n\xa0 \xa0 \xa0 \xa0 server_name app2.archdemo;  \n\xa0 \xa0 \xa0 \xa0 location / {  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy_pass http://127.0.0.1:9002;  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy\\_set\\_header Host $host;  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy\\_set\\_header X-Forwarded-For $proxy\\_add\\_x\\_forwarded\\_for;  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy\\_set\\_header X-Forwarded-Host $host;  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy\\_set\\_header X-Forwarded-Port $server_port;  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy\\_set\\_header X-Forwarded-Proto https;  \n\xa0 \xa0 \xa0 \xa0 }  \n\xa0 \xa0 }  \n\xa0 \xa0 server {  \n\xa0 \xa0 \xa0 \xa0 listen 80;  \n\xa0 \xa0 \xa0 \xa0 server_name app1.archdemo;  \n\xa0 \xa0 \xa0 \xa0 location / {  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy_pass http://127.0.0.1:9001;  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy\\_set\\_header Host $host;  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy\\_set\\_header X-Forwarded-For $proxy\\_add\\_x\\_forwarded\\_for;  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy\\_set\\_header X-Forwarded-Host $host;  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy\\_set\\_header X-Forwarded-Port $server_port;  \n\xa0 \xa0 \xa0 \xa0 \xa0 proxy\\_set\\_header X-Forwarded-Proto https;  \n\xa0 \xa0 \xa0 \xa0 }  \n\xa0 \xa0 }  \n...\n```\n'},pV1G:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Brume"\nthumbnail: /images/plots/196.jpg\ndescription: "Brume means Mist in French. Diamine Earl Grey ink on watercolor paper."\n---\n\nBrume means Mist in French. Diamine Earl Grey ink on watercolor paper.'},pYlj:function(e,n,t){"use strict";var a=t("PMAo"),i=t("Ss4Z");function o(e){return function(){throw new Error("Function "+e+" is deprecated and cannot be used.")}}e.exports.Type=t("NdRM"),e.exports.Schema=t("3rKx"),e.exports.FAILSAFE_SCHEMA=t("gWvi"),e.exports.JSON_SCHEMA=t("NGCR"),e.exports.CORE_SCHEMA=t("rMOK"),e.exports.DEFAULT_SAFE_SCHEMA=t("EOT6"),e.exports.DEFAULT_FULL_SCHEMA=t("YJCK"),e.exports.load=a.load,e.exports.loadAll=a.loadAll,e.exports.safeLoad=a.safeLoad,e.exports.safeLoadAll=a.safeLoadAll,e.exports.dump=i.dump,e.exports.safeDump=i.safeDump,e.exports.YAMLException=t("XCGq"),e.exports.MINIMAL_SCHEMA=t("gWvi"),e.exports.SAFE_SCHEMA=t("EOT6"),e.exports.DEFAULT_SCHEMA=t("YJCK"),e.exports.scan=o("scan"),e.exports.parse=o("parse"),e.exports.compose=o("compose"),e.exports.addConstructor=o("addConstructor")},pjVY:function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: 'Playframework simple deployment scripts'\ndescription: 'Playframework simple deployment scripts'\nauthor: Gaetan\nlayout: post\ntags:\n - sysadmin\n - playframework\n---\n\n<script src=\"https://gist.github.com/gre/5528826.js\"><\/script>\n\n"},ppE9:function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: \"3-colors spiral packing\"\nthumbnail: /images/plots/177.jpg\ndescription: \"Spirals with 3 colors distributed with 'circle packing' technique. 3 fountain pens on Bristol.\"\ntags:\n  - circle-packing\n  - shape-packing\n---\n\nSpirals with 3 colors distributed with 'circle packing' technique. 3 fountain pens on Bristol."},qC5S:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "tensed mountains"\nthumbnail: /images/plots/144.jpg\ndescription: "A variation of plot#108 with more \'tensed\' lines. The distribution creates an interesting visual illusion that edges are \'blurred\'."\ntags:\n  - perlin\n---\n\n\nA variation of [plot#108](/plots/108) with more "tensed" lines. The distribution creates an interesting visual illusion that edges are "blurred".'},qLlP:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'ZOUND live v1 in development\'\ndescription: \'Here is a preview video of the Work In Progress development of ZOUND live, the collaborative modular audio tracker built with bleeding edge web technologies: Web Audio API, Web MIDI API, WebSocket & Playframework.\'\nauthor: Gaetan\nlayout: post\ntags:\n - MIDI\n - audio\n - zound\n---\n\nHere is a preview video of the Work In Progress development of [ZOUND live](/2013/07/zound-live/),\nthe **collaborative modular audio tracker** built with bleeding edge **web technologies**: *Web Audio API, Web MIDI API, WebSocket & Playframework*.\n\n<iframe width="640" height="480" src="//www.youtube.com/embed/621dpTK8OOc" frameborder="0" allowfullscreen></iframe>\n\n<img src="/images/2013/07/nanokontrol.jpg" alt="" class="thumbnail-left" style="width: 150px">\n\n**N.B.** In the video, I\'ve used the nanoKONTROL2 for changing some properties in real time and using the MIDI API.\n\n----\n\n**If you are interested by the project, [fork it on Github](https://github.com/gre/zound-live).**\n\nMore to come, stay tuned!\n'},qPHC:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Anomalie carr\xe9e (2/4)"\nthumbnail: /images/plots/168.jpg\ndescription: "One of the 4 plots of the series of \'Anomalie carr\xe9e\'. made with 2 fountain pens on A4 Bristol paper. The first buyer of this NFT sold by achetezdelart can collect the original copy. No other copy will be made. See information in the NFT."\n---\n\n<nft-card contractAddress="0x495f947276749ce646f68ac8c248420045cb7b5e" tokenId="47428341271170390733253974222101382154768714392453356712130950046909324066817"> </nft-card> <script src="https://unpkg.com/embeddable-nfts/dist/nft-card.min.js"><\/script>\n\nOne of the 4 plots of the series of \'Anomalie carr\xe9e\'. made with 2 fountain pens on A4 Bristol paper. The first buyer of this NFT sold by achetezdelart can collect the original copy. No other copy will be made. See information in the NFT.'},qVQq:function(e,n,t){"use strict";t.r(n),n.default=""},qn1m:function(e,n,t){"use strict";t.r(n),n.default=""},rEsJ:function(e,n,t){"use strict";t.r(n),n.default=""},rMOK:function(e,n,t){"use strict";var a=t("3rKx");e.exports=new a({include:[t("NGCR")]})},rgdI:function(e,n,t){"use strict";t.r(n),n.default="---\ntweet: https://twitter.com/greweb/status/1382766950984597505\ntags:\n  - planet-holes\n---\n"},rn5Z:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Mountain moons"\nthumbnail: /images/plots/190.jpg\ndescription: "Continuation on packing circles with layered lines."\ntags:\n  - shape-packing\n---\n\nContinuation on packing circles with layered lines.'},sRRH:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "many plus"\nthumbnail: "/images/plots/140.jpg"\ndescription: "Plotter\'s journey is made of simple plots like these. The robot had one job: plot a lot of plus."\n---\n\nPlotter\'s journey is made of simple plots like these. The robot had one job: plot a lot of plus. The result has been pretty unexpected.\n\nFirst of all, I had issue on offset of my second color which make the plus literally colliding, secondly the center area had the paper waving and raising a bit which made brush paint more color. Finally, the way the plus are no longer plus is interesting, it almost looks like some sort of plants or snail shapes, depending on your imagination!\n\n<img width="100%" src="/images/plots/140zoom.jpg"/>\n\nBefore that plot, I had a first try with bigger and more distanced plus, but it was too simple to me:\n\n<img width="100%" src="/images/plots/140bis.jpg"/>\n'},sSon:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Layers"\nthumbnail: /images/plots/189.jpg\ndescription: "Packing circles with layered lines inside. exploration made before plot#188."\ntags:\n  - shape-packing\n---\n\nPacking circles with layered lines inside. exploration made before [plot#188](/plots/188)\'s plot loop.\n\nAlso made a second one:\n\n<img width="100%" src="/images/plots/189bis.jpg">\n\nThere is an infinity of variants.'},side:function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: Automating Web App development for multiple platforms\ndescription: In this article, we will explain why we\u2019d choose web technologies to make applications and introduce WebAppBuilder, a tool to easily build different instances of an application. We\u2019ll examine the Same Game Gravity as an example.\nthumbnail: /images/2011/webappmaker.png\nauthor: Gaetan\nlayout: post\npermalink: /2011/06/automating-web-app-development-for-multiple-platforms/\ntags:\n  - linux\n---\n\n [1]: /2011/06/automating-web-app-development-for-multiple-platforms/#webappbuilder\n [2]: http://gre.github.io/same-game-gravity\n [3]: https://github.com/gre/WebAppBuilder\n [4]: http://diveintohtml5.org/\n [6]: http://www.phonegap.com/\n [8]: http://mustache.github.com/\n [9]: http://sass-lang.com\n [10]: http://compass-style.org\n [12]: http://mrspeaker.net/\n [13]: https://github.com/jquery/jquery/tree/master/build\n\n\nIn this article, we will explain why we\u2019d choose web technologies to make applications and introduce [**WebAppBuilder**][1], a tool to easily build different instances of an application. We\u2019ll examine the [Same Game Gravity][2] as an example.\n\n\nUsing web to develop mobile applications is very **productive** and web technologies are **rich**.\n\n[Fork WebAppBuilder on Github.][3]\n\n\x3c!--more--\x3e\n\n## Rich?\n\nNew web technologies have become rich with CSS3, HTML5 and new Javascript APIs are now being supported on most of smartphones. CSS3 animations, Web Service usage, local storage, Geolocation, drawing shapes (Canvas),.. are some example of new web features.\n\nI won\u2019t expand more on this topic but invite you to [visit this link][4] for more details.\n\n## Productive?\n\nCompared to a native application, the web application **paradigm is reversed**.  \nThe Web provide a common way to make applications.  \nTo develop a native application, you must adapt yourself for each device, each new API, or each new language,\u2026 but with Web, the device fits to you by proving bridges (accessible via JavaScript) to access device features!  \nI mean, you don\u2019t need to dive into the Java Android API or Objective-C language (for iPhone/iPad), or any other API for other devices\u2026 You just have to learn **web technologies**.\n\nWe are in 2011, the \u201conly desktop application\u201d model is over now, and mobile and tablet are two new platforms you should be aware of. So it changes everything about the technology to use.\n\n### Having a common language for all instances\n\nInstances of a single application can be numerous.  \nIn fact, an application can be projected in at least 3 axis of instance : The **platform** (mobile, tablet, desktop, \u2026), the **Operating System** (Android, iPhone, webOS) and the **application version** (free version, full version, \u2026).\n\n![](/images/2011/application-axis3.png)\n\nThat\u2019s pretty expensive to develop X instances of an application. This is a problem for developing the first version and mainly for maintainability : You want to fix bugs and add features once, and only once.\n\n**So, the point is we need a common language to describe an application with multiple instances.**\n\n### Web is great for that!\n\nComputers have browsers, mobiles and tablets device have recent browsers.\n\nTo make your application development fully independent from the device, firstly you need a great **framework** to bridge your application and the device (like [PhoneGap][6]), secondly you need a great tool to easily **build** all applications from your common source code.\n\n\nFirst of all, let\u2019s see how to organize a web project.\n\n### Good practice\n\nThis is how I\u2019ve organize my project :\n\n#### The source code directory\n\nThis directory contains all your web app source code. You should keep your application source code (with HTML, CSS, Javascripts, images, sounds, \u2026) in one directory (like */src* ).  \nYou should **avoid specific code**, but sometimes you still need some specific behaviors for different devices. If so, I recommend you to put these differences inside different files (for exemple: *mobile.html*, *tablet.html*, *computer.html*,\u2026).\n\n#### Project skeletons\n\nKeep one skeleton directory for each instance of your application.  \nA skeleton directory will contains all the specific code related to the platform/device/version.  \n**Frameworks like PhoneGap bring you these skeletons.**\n\n* * *\n\n## WebAppBuilder\n\n![](/images/2011/webappmaker.png)\n\nI created **WebAppBuilder : a lightweight Makefile to build your project**. This is a mashup of existing cool stuff like : a small template system (Mustache), SASS with Compass, Javascript minimizer, \u2026\n\n### Features of WebAppBuilder\n\n*   Template easily your HTML files with [Mustache][8].\n*   Copy, concatenate, minimize Javascripts however you want.\n*   Retrieve Javascript files from URLs (useful for libraries).\n*   Compile SASS files into CSS files (if you use [this awesome stylesheets language][9])\n*   Support [Compass][10] if installed (you don\u2019t need to provide it in your source, only an import works)\n*   Merge your CSS files.\n*   Copy and optionally rename resources you want to include (images, fonts, sounds,\u2026).\n*   Error handling and atomicity : if one operation fail, the make fail (javascript syntax error, sass syntax error, \u2026)\n\nYou must have one Makefile per project skeleton, so you can easily define what to do with the */src* for the related platform/device/OS.\n\n### Download or Contribute\n\n[Fork me on Github][3]\n\n### Example with my Same Game Gravity game\n\nI developed these tools during the [Same Game Gravity][2] game development. \n\nA **make** inside my android/ skeleton gives me :\n\n![](/images/2011/webappmaker-term.png)\n\nAnd here is the Makefile I use :\n\n#### Android Makefile\n\n```makefile\n# Same Game Gravity - Android full version #\n        \n        ###             ~ Web App Builder ~               ###\n        #       a Makefile to compile a web project.        #\n        #  designed for web project with different devices  #\n        #  (mobile, tablet, desktop) but with common code.  #\n        ###        by @greweb  -  http://greweb.fr/       ###\n \n# BUILD_DIR : PATH to Web App Builder /build directory (the directory containing all build tools)\nBUILD_DIR = ../build\n \n# SRC_DIR : the source directory\nSRC_DIR = ../app\n \n# DIST_DIR : the dist directory (ex: assets for android, www for iphone)\nDIST_DIR = assets\n \n# RESOURCES : Your assets (images, sounds, fonts... and other static files)\n# You can rename dist file by prefix newname= ( ex: index.html=iphone_version.html )\nRESOURCES = Chewy.ttf logo.png background.jpg pop.mp3 swosh.mp3 gravity_exemple.png\n \n# VIEWS : Views will be interpreted by Mustache.js\n# You can pass arguments with JSON format.\n# Example: index.html:\"{key1:value1,key2:value2,...}\"  <= no spaces!\nVIEWS = index.html=mobile.html:\"{versionType:'',version:'1.0',platform:'mobile',android:true,free:false}\"\n \n### SCRIPTS : all javascripts\n# - You can pass an URL to retrieve\n# - if you want to minimize the JS, prefix with '!'\n# - to mix scripts, concat them with a comma ','\n# - to set the destination name, you can prefix scripts with 'myname.js=' else the first script name is used ( exemple: all.js=util.js,ui.js,main.js ).\nSCRIPTS = game.min.js=!game.js,!game.mobile.js,!md5.js \\\n          phonegap.min.js=!phonegap.js,!phonegap.webintent.js \\\n          jquery.min.js=http://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js,jquery.ba-hashchange.min.js,jquery.tmpl.min.js\n \n### STYLES : all styles : CSS or SASS\n# - For .sass files, we compile them to css\n# - Like before, you can mix styles with ',' and you can name your target by prefixing 'name='\nSTYLES = game.css=mobile.sass\n \n########################################################################\n \n \nall: welcome clean assets_views assets_scripts assets_styles assets_files\n \nwelcome:\n\t@@${BUILD_DIR}/welcome.sh\n \nassets_base: \n\t@@mkdir -p ${DIST_DIR}\n \nassets_views: assets_base\n\t@@${BUILD_DIR}/compile_views.sh ${SRC_DIR} ${DIST_DIR} ${VIEWS}\n \nassets_scripts: assets_base\n\t@@${BUILD_DIR}/compile_scripts.sh ${SRC_DIR} ${DIST_DIR} ${SCRIPTS}\n \nassets_styles: assets_base\n\t@@${BUILD_DIR}/compile_styles.sh ${SRC_DIR} ${DIST_DIR} ${STYLES}\n \nassets_files: assets_base\n\t@@${BUILD_DIR}/copy_resources.sh ${SRC_DIR} ${DIST_DIR} ${RESOURCES}\n \nclean: \n\t@@rm -rf ${DIST_DIR}\n \n.PHONY: welcome clean assets_views assets_scripts assets_styles assets_files\n```\n\n### Configuring your IDE\n\nI use mainly komodo and geany as an IDE. They both have a build system. I recommand you to configure your IDE to make && open the page just by pressing a shortcut key.\n\n### Features planned\n\n*   make should build the .apk for Android app\n\n## Special thanks\n\n*   to [mrspeaker][12] for English review.\n*   to [jQuery build system][13] (js minifier)\n\n"},skje:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Warp Glitch 02"\nthumbnail: /images/plots/153.jpg\ndescription: "Continuation of plot#152 using two different inks: Diamine Pumpkin and Diamine Turquoise. Reveals an overall green tone. Using similar noise domain warping with glitches technique."\ntags:\n  - noise\n---\n\nContinuation of previous [plot#152](/plots/152) using two different inks: Diamine Pumpkin and Diamine Turquoise. Reveals an overall green tone. Using similar noise domain warping with glitches technique.\n\n<img src="/images/plots/153zoom.jpg" width="100%">\n'},"t+o8":function(e,n,t){"use strict";t.r(n),n.default=""},tOsZ:function(e,n,t){"use strict";t.r(n),n.default=""},tbEk:function(e,n,t){"use strict";t.r(n),n.default=""},tfEw:function(e,n,t){"use strict";const a=t("n0UO"),i=t("X+87");e.exports=function(e){const n=Object.assign({},e);return n.delimiters=i.arrayify(n.delims||n.delimiters||"---"),1===n.delimiters.length&&n.delimiters.push(n.delimiters[0]),n.language=(n.language||n.lang||"yaml").toLowerCase(),n.engines=Object.assign({},a,n.parsers,n.engines),n}},u0RZ:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Montagne muable (8 frames)"\nthumbnail: /images/plots/164.gif\ndescription: ""\ntags:\n  - plotloop\n  - mountain\n  - perlin\n---\n\n\n**Every NFT sold allows acquiring a plotted frame. (code in the unlockable content)**\n\n<nft-card contractAddress="0x495f947276749ce646f68ac8c248420045cb7b5e" tokenId="47428341271170390733253974222101382154768714392453356712130950043610789183496"> </nft-card> <script src="https://unpkg.com/embeddable-nfts/dist/nft-card.min.js"><\/script>\n\n<video loop autoplay controls src="/images/plots/164-showcase.mp4" width="100%"></video>\n\n\nMy 7th [plotloop](/plots/tags/plotloop) is a very special one, inspired from the mother of all of my plot loops: [plot#108](/plots/108) which wasn\'t planned to be animated but a way to visualize randomness and chose one frame! This is still what gave me the idea to do these plot loops.\n\n> The concept of Plot Loop, as described in https://greweb.me/2021/05/plot-loops article, is an hybrid concept between a digital video art and physical plot that produces topology of the same art.\n\n\nThe main digital art is a 1920p video loop of 8 frames available as NFT on Opensea.io sold by [@achetezdelart](https://twitter.com/achetezdelart) famous Paris\' art gallery. I am so thrilled to work for the first time with an art gallery and looking forward to do more collaboration in the future! The physical art is the 8 frames, plotted with 3 fountain pens on Bristol A4 paper (250g), and offered when buying the NFT.\n\n\n## 24+ hours of near non-stop plotting!\n\nOnce the coding was done, the hard part was the precision work of plotting 8 frames, each taking 2 hours to achieve. With all the fail and retry there were, it took me more than a day to finish it all. The sun strokes takes about 10 minutes but the rest takes around 100 minutes.\n\n<video loop autoplay controls src="/images/plots/164-plotting-speed-x200.mp4" width="100%"></video>\n\n## Zoom photos\n\n<img src="/images/plots/164zoom.jpg" width="100%" />\n\n## "Proof of Plot", a very time-consuming creation process\n\nThe creation process of this plot loop was one of the most challenging one, among all of the other plots I have done so far. The fact each frame takes about 2 hours to plot with 2 manual actions (changing the fountain pens) makes any mistake very punishing! You can\'t faster the 2 hours much without risking the paper to suffer faced to the number of stroke of the fountain pen!\n\n### Fail and retry\n\nYet, plotting is a fail and retry process, so I like to show you 2 failures first among 4 of my first prototype fails:\n\n<img width="50%" src="/images/plots/164-fail1.jpg"><img width="50%" src="/images/plots/164-fail2.jpg">\n\nFor anyone familiar with plot and fountain pens this is indeed one of the worse nightmare to deal with: too much stroke-crowded area is going to badly end up with literally digging through the paper.\n\n### Quick technique to solve this problem\n\nA very simple technique I call the "passage counter" technique. It\'s simply the use of a 2D Grid where each cell have a counter that you increment when a line goes through it, when it reaches 3 (or more) that\'s where you start raising the pen in these crowded area.\n\n<img width="300px" src="/images/plots/164-grid.png">\n\nIt works great with the limitation that too much up and down of your pen is both time consuming but also can be hurting the paper too, there there is a tradeoff to find.\n\n### Some interesting creative coding techniques used\n\n#### sun rays projection\n\nFor the sun rays, I\'ve used a simple radial projection that collides with the mountain lines.\nI had to make lines randomly starting at different places to avoid the effect to be too condensed at the beginning (problem of radial projection is your lines get more and more distanced). I wanted it to not be that "random" so i\'ve used a simple prime number formula: distance to center of sun is added of an extra `8. + ((i * 29) % 121) as f64` where `i` is the ray index.\n\n#### sun oscillation\n\nI didn\'t wanted to make the sun motion too realistic but I wanted a visible motion that would fit with the mountains and project rays from different positions. It also had to be looping (which a sunset/sunrise wouldn\'t allow)\n\nTherefore, I went with a simple trigonometry formula:\n\n```rust\nlet sunp = (\n  w / 2. + 75. * (2. * PI * sunphase).cos(),\n  50. - 30. * (2. * PI * sunphase).sin().abs()\n);\n```\n\n#### mountain oscillation and noise shape\n\nThe noise algorithm I used was much more accomplished than in [plot#108](/plots/108) even though that historical plot one is interesting too.\n\nI learned recently the power of \'domain warping\' on applied on noise and I applied it here, at least mainly on the 1D of the wave. It creates more "local minima" on the shape and creates a more interesting animation.\n\nIt\'s important to also note that noise/perlin noise, is quite challenging to "loop" and the way I did this is interpolation between 3 states. I have simply done this:\n\n```rust\nlet n1 = perlin.get([ a, b, opts.seed + i as f64 * divergence + 200.2 ]);\nlet n2 = perlin.get([ a, b, opts.seed + i as f64 * divergence + 300.514 ]);\nlet n3 = perlin.get([ a, b, opts.seed + i as f64 * divergence + 400.31 ]);\nlet n = 0.8 * \n    (\n        n1 * (2. * PI * p).cos() +\n        n2 * (2. * PI * (p + 0.33)).cos() +\n        n3 * (2. * PI * (p + 0.66)).cos()\n    ) +\n    // global disp\n    0.2 * perlin.get([\n        freq * xp,\n        freq * y,\n        opts.seed\n    ]);\n```\n\nwhere **a** and **b** are noise themselves to apply the "domain warping" magic.'},uCoZ:function(e,n,t){"use strict";t.r(n),n.default=""},uOdg:function(e,n,t){"use strict";var a=t("Ga6R");function i(e,n,t,a,i){this.name=e,this.buffer=n,this.position=t,this.line=a,this.column=i}i.prototype.getSnippet=function(e,n){var t,i,o,r,s;if(!this.buffer)return null;for(e=e||4,n=n||75,t="",i=this.position;i>0&&-1==="\0\r\n\x85\u2028\u2029".indexOf(this.buffer.charAt(i-1));)if(i-=1,this.position-i>n/2-1){t=" ... ",i+=5;break}for(o="",r=this.position;r<this.buffer.length&&-1==="\0\r\n\x85\u2028\u2029".indexOf(this.buffer.charAt(r));)if((r+=1)-this.position>n/2-1){o=" ... ",r-=5;break}return s=this.buffer.slice(i,r),a.repeat(" ",e)+t+s+o+"\n"+a.repeat(" ",e+this.position-i+t.length)+"^"},i.prototype.toString=function(e){var n,t="";return this.name&&(t+='in "'+this.name+'" '),t+="at line "+(this.line+1)+", column "+(this.column+1),e||(n=this.getSnippet())&&(t+=":\n"+n),t},e.exports=i},uWG4:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "How I learned Backbone.js, Three.js, GLSL in one week"\nauthor: Gaetan\ndescription: I learned to use Backbone.js and Three.js (a famous library on top of WebGL) to make a FPS in only one week.\nthumbnail: /images/2012/07/dta1.png\nlayout: post\npermalink: /2012/07/how-i-learned-backbone-js-three-js-glsl-in-one-week/\ntags:\n  - gamedev\n  - GLSL\n  - WebGL\n---\n\n[1]: http://youcanmakevideogames.com/\n[2]: http://7dfps.org/\n[3]: http://www.ludumdare.com/\n[4]: http://gre.github.io/dta\n[8]: http://caniuse.com/#search=webgl\n[12]: http://www.egonelbre.com/js/jsfx/\n[16]: http://www.opengl.org/documentation/glsl/\n[17]: http://glsl.heroku.com/\n[19]: https://github.com/gre/dta/blob/master/app/models/models.scala\n[20]: http://playframework.org/\n\n![](/images/2012/07/dta1.png)\n\nLast week was the [7dfps challenge][2], an open challenge where participants had to make a FPS in only one week.\nSuch contest are very very interesting for those who want to experiment with things. Challenging yourself is IMO the best way to learn new things. You may also know the famous [\u201cLudum Dare\u201d contest][3].\n\nI learned to use Backbone.js and Three.js (a famous library on top of WebGL) in only one week, so you have no excuse to not be able to do the same!\n\n[-> You can make games!][1]\n\n> \u201cIf Lawnmower Man f\\*\\*\\*\\*d Tron on the bonnet of a tank\u201d  \n> **_YouBigNugget_**\n\nI\u2019ve only used web technologies, no need of any plugin, just a recent browser like Chrome / Firefox.\n\nThis is the result:\n\n<iframe width="640" height="360" src="http://www.youtube.com/embed/g9CldBI9C6E?feature=player_embedded" frameborder="0" allowfullscreen></iframe>\n\nand you can play it here:\n\n**[Play the game][4]**\n\n\x3c!--more--\x3e\n\n## Overview of a one week game development\n\n### Backbone.js, for the model, events and class inherence\n\nI\u2019m a fan of the \u201cdo it yourself\u201d idea, not using any library or only using small 140byt.es codes. But the frequent issue with that is (1) always doing the same thing again and again, (2) taking a lot of time on the architecture, and not finishing anything. When you have a due date, relying on libraries and frameworks could save you a lot of time.  \nI\u2019ve choose Backbone.js for its Model architecture with class inherence, a get/set system, and also its event system bound to model instances, the destroy function with the \u201cdestroy\u201d event to bind on,\u2026 It was also a new library to learn for me.\n\n#### Models\n\nHere is the class diagram of the game:\n\n![not available](/images/2012/07/f5dea341.jpg)\n\n### Learning Three.js, a 3D library on top of WebGL.\n\nWebGL is [more and more supported by browsers][8].  \nWebGL means OpenGL in the web. It allows to make efficient and hardware accelerated 3D computation.\n\nHere is the same, not using any library but using pure WebGL wasn\u2019t possible in one week! This is why I\u2019ve chosen to use Three.js, probably today the most popular WebGL library.  \nI was impressed how Three.js is finally not so hard to use, knowing some basic 3D concepts from my old Blender days.\n\nYou create a `Scene`, add a `Camera`, add Meshes to the scene, A `Mesh` has a `Material` and a `Geometry`, \u2026 everything very straighforward.\n\nOne challenging part was when trying to compute global world position relative to a given object position, for instance to compute the Bullet initial position and orientation from the Tank position and orientation.\n\nFortunately I\u2019ve got some help ![:)][4] and got the answer: multiply your vector with the worldMatrix of the mesh.\n\n<blockquote class="twitter-tweet" data-in-reply-to="212609230891524096" width="550" lang="fr"><p>@<a href="https://twitter.com/greweb">greweb</a> Should be calculatable quite easily. Multiply the position vector by the object\u2019s matrixWorld property.</p>\n<p>&mdash; Paul Lewis (@aerotwist) <a href="https://twitter.com/aerotwist/status/212617930024816641" data-datetime="2012-06-12T18:50:39+00:00">Juin 12, 2012</a></p></blockquote>\n\n<blockquote class="twitter-tweet" data-in-reply-to="212609230891524096" width="550" lang="fr"><p>@<a href="https://twitter.com/greweb">greweb</a> var position = new THREE.Vector3().getPositionFromMatrix( object.matrixWorld );</p>\n<p>&mdash; Mr.doob (@mrdoob) <a href="https://twitter.com/mrdoob/status/212648943673290752" data-datetime="2012-06-12T20:53:53+00:00">Juin 12, 2012</a></p></blockquote>\n\n### Playing with AI\n\nLike TankKeyboardControls, I\u2019ve created a new \u201cTankControls\u201d for computer tanks: **TankRandomControls** was the first dumb one, it just does random things:\n\n```javascript\nfunction TankRandomControls () {\nvar self = this;\nself.moveForward = false;\nself.moveBackward = false;\nself.moveLeft = false;\nself.moveRight = false;\nself.fire = false;\nself.fireMissile = false;\nvar i = ;\nsetInterval (function () { // take random decisions every 0.5 second\n  i;\nself.moveForward = i%3== && Math.random() > 0.2;\nself.moveBackward = !self.moveForward && Math.random() > 0.5;\nself.moveLeft = Math.random() < 0.1;\nself.moveRight = Math.random() < 0.1;\nself.fire = Math.random() > 0.2;\nself.fireMissile = Math.random() < 0.2;\n}, 500);\n}\n```\n\n**TankRemoteControls** was the second one using some simple AI rules:\n\n- Try to avoid walls and objects\n- Either do random things or target a tank (more likely)\n- Target the closest tank, update target every 5 seconds\n- Turn the tank to the target tank, shoot bullets and missiles\n- Move forward if the target is far away / Move backward if the target is too close\n\nSee the source code here: .\n\n### Sounds\n\nI\u2019ve used [JSFX][12], an experimental library, were you can generate sounds based on a few parameters.  \nIt\u2019s a 8-bit sound generator perfect for generate old-school sounds.\n\nSo you can create each sound in Javascript like this:\n\n```javascript\nSOUNDS = {\n  bullet: jsfxlib.createWave([\n    "noise",\n    7.0,\n    0.18,\n    0.0,\n    0.082,\n    0.0,\n    0.222,\n    20.0,\n    800,\n    2400.0,\n    -0.428,\n    0.0,\n    0.0,\n    0.01,\n    0.0003,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n    0.992,\n    0.0,\n    0.0,\n    0.22,\n    0.0,\n  ]),\n  missile: jsfxlib.createWave([\n    "noise",\n    0.0,\n    0.12,\n    0.0,\n    0.546,\n    0.0,\n    0.856,\n    64.0,\n    250,\n    1063.0,\n    0.28,\n    0.086,\n    0.024,\n    5.4329,\n    0.3565,\n    0.466,\n    -0.638,\n    0.058,\n    0.008,\n    0.0,\n    0.0,\n    -0.114,\n    0.216,\n    0.98,\n    -0.984,\n    1.0,\n    0.307,\n    0.988,\n  ]),\n  explosion: jsfxlib.createWave([\n    "noise",\n    1.0,\n    0.4,\n    0.02,\n    0.682,\n    1.746,\n    1.97,\n    100.0,\n    378.0,\n    2242.0,\n    -0.55,\n    -0.372,\n    0.024,\n    0.4899,\n    -0.1622,\n    0.262,\n    0.34,\n    0.724,\n    0.0205,\n    -0.102,\n    0.0416,\n    -0.098,\n    0.1,\n    0.805,\n    0.094,\n    0.428,\n    0.0,\n    -0.262,\n  ]),\n  collideWall: jsfxlib.createWave([\n    "noise",\n    0.0,\n    0.4,\n    0.0,\n    0.056,\n    0.0,\n    0.296,\n    20.0,\n    560.0,\n    2400.0,\n    -0.482,\n    0.0,\n    0.0,\n    0.01,\n    0.0003,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n    1.0,\n    0.0,\n    0.0,\n    0.0,\n    0.0,\n  ]),\n};\n// ...\n// SOUNDS.bullet.play()\n```\n\nThe jsfxlib.createWave function returns a HTML5 Audio element and you can play with its API (.play(), .pause(), \u2026).  \nBut doing this way, you will not be able to play a sound at the same time so I\u2019ve made a buffer system which duplicate N times the sound in different audio elements.  \nI have also try to generate different sounds to randomize it a little.\n\nSee the full source code here: .\n\n### Post Processing Effects with GLSL shaders\n\nI was very impressed by the power of GLSL for its possibilities and efficiency.  \nGLSL are definitely the indispensable thing you need to add a better atmosphere in your games.\n\n#### Before\n\n![](/images/2012/06/before.png)\n\n#### After\n\n![](/images/2012/06/after_.png)\n\nand when getting shot:\n\n![](/images/2012/06/after.png)\n\nThese effects are done by combining these two GLSL effects.  \nHere is the GLSL code of these effects.\n\n#### The radio noise effect\n\n<script src="https://gist.github.com/2950478.js?file=radionoise.frag"><\/script>\n\n#### The shot interference\n\n<script src="https://gist.github.com/2950478.js?file=perturbation.frag"><\/script>\n\n### Wait! what is this crazy \u201cGLSL\u201d language?\n\nGLSL is an OpenGL language close to the C syntax design to have a direct control of the graphic pipeline. You can directly add passes to the rendering process with GLSL shaders.  \nGLSL gives you a lot of very useful types (like vectors, matrix, \u2026) and functions (like smoothstep, \u2026). [Read the spec][16] to know more about it.  \nI also recommend you to experiment the [GLSL Sandbox][17]. You can see awesome demos and their codes shared by people made with GLSL. It also have an online IDE to easily code and instantly test your shaders.\n\n### WebGL and Three.js integration\n\nYou can use GLSL in different ways with Three.js. You can add a GLSL shader to an object material, and you can also add GLSL shaders on top of the Canvas (post-processing). We will only see how to add GLSL shaders as a post processing render on the entire Canvas.\n\nFortunately Three.js have some utils classes to make the GLSL shaders integration easier.\n\nI have been inspired from the awesome work done here: .\n\nThere is a lot of code out there, so I\u2019ve try to extract the minimum required for mixing the 2 GLSL shaders for a post-processing on the entire canvas of a Three.js scene:\n\n<iframe style="width: 100%; height: 400px;" src="http://jsfiddle.net/jggvJ/7/embedded/" frameborder="0" width="320" height="240"></iframe>\n\nAs you can see, you can easily inject your own Javascript variables in a GLSL shader to make a bridge between the JS and the GLSL code and so having quite generic and configurable shaders.  \nQuite cool!\n\n### Adding game UI\n\nWeb, with HTML and CSS, allows to have different containers, layers, positioning systems,\u2026  \nPerfect! For the game UI, we used different elements:\n\n![](/images/2012/06/ui.png)\n\nRadar and Damage are implemented with an independent Canvas while Level is a simple text div.\n\nFor instance, this is Damage (I called LifeIndicator):\n\n```javascript\n(function(){\n\nvar LifeIndicator = function (nodeId) {\nthis.canvas = document.getElementById(nodeId);\nthis.ctx = this.canvas.getContext("2d");\nthis.life = 1;\nthis.render();\n}\n\nLifeIndicator.prototype.setLife = function (life) {\nthis.life = life;\nthis.render();\n}\n\nLifeIndicator.prototype.render = function () {\nvar c = this.ctx;\nvar w = c.canvas.width, h = c.canvas.height;\nc.clearRect(, , w, h);\n// TODO\nvar g = Math.floor(255*this.life);\nvar r = 255-g;\nc.fillStyle = "rgb(" r "," g ",0)";\nvar wt = 6;\nvar ht = 12;\nc.fillRect((w-wt)/2, , wt, ht);\nc.fillRect(, ht, w, h);\n}\n\nwindow.LifeIndicator = LifeIndicator;\n\n}());\n```\n\n## Play Framework integration\n\nI was planning to make a multiplayer game but I couldn\u2019t find the time for this.  \nI use Play Framework 2 and its power and concepts for handling streams (even if I don\u2019t use it yet).  \nThe only part I can show you for now is the game map generation. For making a multiplayer game, I needed to have the game state on server side to be able to submit game infos (map, players, \u2026) to new players.\n\nThis is a few scala code to generate a nice distribution of random objects in the map:\n\n```scala\nobject Game {\n\xa0 def createRandom: Game = {\n\xa0 \xa0 val random = new Random()\n\xa0 \xa0 val half = 5000\n\xa0 \xa0 val size = 2*half\n\xa0 \xa0 val split = 4\n\xa0 \xa0 val objects =\n\xa0 \xa0 Range(, split).map { xi =>\n\xa0 \xa0 \xa0 Range(, split).map { yi =>\n\xa0 \xa0 \xa0 \xa0 val s = size.toDouble / split.toDouble\n\xa0 \xa0 \xa0 \xa0 val x = -half.toDouble math.round(s*(xi random.nextDouble));\n\xa0 \xa0 \xa0 \xa0 val y = -half.toDouble math.round(s*(yi random.nextDouble));\n\xa0 \xa0 \xa0 \xa0 var sizeRandom = random.nextDouble\n\xa0 \xa0 \xa0 \xa0 val w = 200.*math.ceil((1-sizeRandom)*8.);\n\xa0 \xa0 \xa0 \xa0 val h = 200.*math.ceil(sizeRandom*8.);\n\xa0 \xa0 \xa0 \xa0 RectObj(Vec3(x,y,), w, h)\n\xa0 \xa0 \xa0 }.toList\n\xa0 \xa0 }.toList.flatten\n\xa0 \xa0 Game( (Vec3(-half, -half, ), Vec3(half, half, )), List(), objects, List() )\n\xa0 }\n}\n\ncase class Game (bounds: Tuple2[Vec3, Vec3], chars: List[Char], objects: List[GameObj], dynamics: List[GameDyn])\n...\n```\n\n[See the full source][19] (some code may not be used).\n\n## Still an unfinished game\n\nThere is more things to do now:\n\n- More visual effects\n- More sound effects\n- A better collision system (using a physic engine?)\n- Multiplayer\n- A better gameplay with some goals, different kind of games, \u2026\n\n### Initial multiplayer objective rescheduled\n\nMy initial game release was focus on the game core, graphisms and gameplay.\n\nI was unfortunately not ready enough to make the multi-player real-time part for the first week sprint but I have some though on the subject.  \nI was asking myself what are the best way to make the game synchronisation between clients while trying to keep as much client-side code as possible. I wanted a scalable decentralized game. I had some though on how to solve this issue. For instance, when a client shoots, he sends a \u201cshoot\u201d event with the timestamp, server just streams events (with a tick frequency) sent by clients and clients replay the game exactly the same way everywhere (using all these time-based events) with some interpolation with the current time.  \nI need to think more about this now, and try to use [PlayFramework][20].\n\n## Source code\n\n[http://github.com/gre/dta](http://github.com/gre/dta)\n\n**[EDIT] You may be mainly interested by the [main.js][21]. It shows how powerful the even-driven programming is, for plugging components together.  \n**\n\n[21]: https://github.com/gre/dta/blob/master/app/assets/javascripts/main.js\n\n## Special thanks\n\n[@mrspeaker][22] for helping me with Three.js & also collision system,  \n[@mrdoob][23] & [@aerotwist][24] for replying to my newbies questions,  \nguys on IRC (#three.js),  \nand of-course 7dfps guys.\n\n[22]: http://twitter.com/mrspeaker\n[23]: http://twitter.com/mrdoob\n[24]: http://twitter.com/aerotwist\n'},uWLs:function(e,n,t){"use strict";t.r(n),n.default=""},ufYd:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: HTML5 Canvas as a color converter\nauthor: Gaetan\ndescription: We can implement an anythingToRGBA converter in 10 lines of Javascript!\nthumbnail: /images/2012/05/color-alpha-options.png\nlayout: post\npermalink: /2012/05/html5-canvas-as-a-color-converter/\ntags:\n  - canvas\n  - javascript\n  - color\n---\n\n [2]: http://gre.github.io/illuminated.js/\n [3]: https://github.com/bgrins/spectrum\n [4]: http://www.w3.org/TR/css3-color/\n\n<img src="/images/2012/05/color-alpha-options.png" alt="" class="thumbnail-left" />\n\nI\u2019m currently working on the User Interface of a scene editor for my [Illuminated.js library][2] with some color and alpha picker.\n\nHTML5 now have the `<input type="color" />` and `<input type="range" />` which is nice. It works on Chrome and there are some [polyfills][3] to make it working on older browsers.\n\nWe will now see how we can easily **retrieve a rgba color from such an UI**, regardless of the color format given by the color picker and **combine the alpha component from the alpha range picker**.\n\n> We can implement an **anythingToRGBA converter** in 10 lines of Javascript!\n\n## What?\n\nBasically, for instance, you have this: `"#ff6432"` and `0.8`\n\nand you want this: `"rgba(255,100,50,0.8)"`\n\nwhich is this color: <span style="background: #ff6432; display: inline-block; width: 50px">&nbsp;</span>.\n\n> Well, of course, we could use a library with regexp parsers!\n\nBut there is a lot of different formats available especially if you want to convert a color from [CSS][4]!\n\nOnly for the <span style="color:blue">blue</span> color, you have at least 7 different representations: `#00F`, `#0000FF`, `rgb(0,0,255)`, `rgba(0,0,255,1)`, `hsl(255,100%,50%)`, `hsla(255,100%,50%,1)`,  \nand\u2026 `blue`!\n\n> Ouch, so let\u2019s make a huge converter library!\n\nNope! \n\nAll of these are color formats are supported by CSS and also Canvas.  \n**So, why not just re-using what the browser can do?**\n\n\x3c!--more--\x3e\n\n\n## How?\n\nBecause we have access to Canvas in Javascript, **we can implement an anythingToRGBA converter in a few line of Javascript**:\n\n```javascript\nvar getRGBA = (function(){  \n\xa0 var canvas = document.createElement("canvas");  \n\xa0 canvas.width = canvas.height = 1;  \n\xa0 var ctx = canvas.getContext("2d");  \n\xa0 return function (color, alpha) {  \n\xa0 \xa0 ctx.clearRect(,,1,1);  \n\xa0 \xa0 ctx.fillStyle = color;  \n\xa0 \xa0 ctx.fillRect(,,1,1);  \n\xa0 \xa0 var d = ctx.getImageData(,,1,1).data;  \n\xa0 \xa0 return \'rgba(\' [ d[], d[1], d[2], alpha ] \')\';  \n\xa0 }  \n}());\n```\n\nYou have now a ready to use Javascript color library! \n\n`getRGBA("#ff6432", 0.8)` will returns `"rgba(255,100,50,0.8)"`.  \n`getRGBA("red", 0.5)` will returns `"rgba(255,0,0,0.5)"`.\n\nYou can \u201cstandardize\u201d your color and use it anywhere!\n\n**Feel free to adapt the code to any other desired format.**\n\nWe can easily make the reverse (give a rgba color and get the #RRGGBB and alpha values):\n\n```javascript\nvar extractColorAndAlpha = (function(){  \n\xa0 var canvas = document.createElement("canvas");  \n\xa0 canvas.width = canvas.height = 1;  \n\xa0 var ctx = canvas.getContext("2d");  \n  \n\xa0 function toHex (value) {   \n\xa0 \xa0 var s = value.toString(16);   \n\xa0 \xa0 if(s.length==1) s = "0" s;  \n\xa0 \xa0 return s;  \n\xa0 }  \n  \n\xa0 return function (color) {  \n\xa0 \xa0 ctx.clearRect(,,1,1);  \n\xa0 \xa0 ctx.fillStyle = color;  \n\xa0 \xa0 ctx.fillRect(,,1,1);  \n\xa0 \xa0 var d = ctx.getImageData(,,1,1).data;  \n\xa0 \xa0 return {  \n\xa0 \xa0 \xa0 color: "#" toHex(d[]) toHex(d[1]) toHex(d[2]),  \n\xa0 \xa0 \xa0 alpha: Math.round(1000*d[3]/255)/1000  \n\xa0 \xa0 };  \n\xa0 }  \n}());\n```\n'},ugXF:function(e,n,t){"use strict";t.r(n),n.default=""},v2OP:function(e,n,t){"use strict";t.r(n),n.default=""},v9De:function(e,n,t){"use strict";t.r(n),n.default=""},vDz1:function(e,n,t){"use strict";t.r(n),n.default="---\ntitle: Same Game Gravity for iPad, iPhone, Android, Facebook, Chrome, and Web!\ndescription: Same Game Gravity is today available on iPad, iPhone, Android, Web, Facebook Apps and Chrome Web Store.\nthumbnail: /images/2011/07/promo.png\nauthor: Gaetan\nlayout: post\npermalink: /2011/07/same-game-gravity-for-ipad-iphone-android-facebook-chrome-and-web/\ntags:\n  - mobile\n  - gamedev\n  - canvas\n---\n\n [1]: /2011/07/same-game-gravity-for-ipad-iphone-android-facebook-chrome-and-web/\n [4]: http://gre.github.io/same-game-gravity\n [5]: http://itunes.apple.com/us/app/same-game-gravity-for-ipad/id446790701\n [6]: http://itunes.apple.com/us/app/same-game-gravity/id445606743\n [7]: http://market.android.com/details?id=fr.gaetanrenaudeau.samegame.free\n [8]: http://gre.github.io/same-game-gravity\n [9]: http://apps.facebook.com/samegamegravity/\n [10]: https://chrome.google.com/webstore/detail/eibjpmiiheipmgfhffjpdmojoagccijb\n\nsee also [Same Game Gravity Technical Notes][1].\n \n# [Click to play][4]\n\n![](/images/2011/07/promo.png)\n\n\n[Same Game Gravity][4] is today available on **[iPad][5], [iPhone][6], [Android][7], [Web][8], [Facebook Apps][9] and [Chrome Web Store][10]**.\n\n![](/images/2011/07/same_platform.png)\n\n> Un principe simple remis au go\xfbt du jour. Tr\xe9s bon!! *(bobylito)*\n\n> Great twist (excuse the pun) on the \u201csame\u201d game! *(mrspeaker)*\n\n> A fresh spin on Same Game the use of gravity is pretty clever. *(erwan)*\n\nSame Game Gravity is a mind-bending ball removal puzzle game where you try to remove all of the balls from the board. Balls can only be removed when they are grouped with more balls of the same color. The balls are influenced by gravity. On mobile, you change gravity by rotating your mobile, on desktop you have arrows.\n\n\x3c!--more--\x3e\n\n## The game gravity\n\nRotate your device to apply gravity and change balls arrangement!\n\n![gravity example](/images/2011/07/gravity_exemple.png)\n\n\n\n### A pioneering scores system based on social networks\n\n  \n\n\nPlayers share their scores through **Twitter** or directly **from the game** (for the Facebook version). The **user name** and the **avatar** are directly taken from these social networks. \nYou can easily compare your scores and contact other players with social networks!\n\n"},vFoq:function(e,n,t){"use strict";t.r(n),n.default=""},vHLE:function(e,n,t){"use strict";t.r(n),t.d(n,"default",(function(){return h}));var a=t("nKUr"),i=t("q1tI"),o=t("g4pe"),r=t.n(o),s=(t("YFqc"),t("AJhG"),t("W9HR"),t("rQ2n")),l=t("ZzT5");t("hmBY"),t("b0oO"),t("GL4Q"),t("TKux"),t("ZwJn"),t("hb5E"),t("DlQD");t("YP5u");const c="/candidates/{index}.gif",u=Array(76).fill(null).map(((e,n)=>n));function h(){const e="elector_"+c,n=Object(i.useMemo)((()=>{try{const n=localStorage[e];if(n){const e=JSON.parse(n);if(e.length===u.length)return e}}catch(n){console.error(n)}}),[]),{0:t,1:o}=Object(i.useState)(n||u.map((()=>null))),{0:h,1:d}=Object(i.useState)((()=>g())),{0:p,1:m}=Object(i.useState)((()=>Array(4).fill(0)));function g(){const e=t.map(((e,n)=>[e,n])).filter((e=>null===e[0])).map((e=>e[1])).sort((()=>Math.random()-.5));console.log("unsorted",e);let n=0;if(0===e.length){const e=t.map(((e,n)=>[e,n])).sort(((e,n)=>n[0]-e[0]));let a=e[0][0],i=0;for(let t=0;t<e.length;t++){const o=e[t][0];if(o===a?i++:(i=0,a=o),i>=3){n=a;break}}}return e.concat(u.filter((e=>(t[e]||0)>=n)).sort(((e,a)=>1.1*(Math.random()-.5)+(Number((t[e]||0)>=n)-Number((t[a]||0)>=n))))).slice(0,4)}Object(i.useEffect)((()=>{n&&o(n)}),[n]),Object(i.useEffect)((()=>{localStorage[e]=JSON.stringify(t)}),[e,t]);return Object(a.jsx)(l.a,{children:Object(a.jsxs)(s.a,{children:[Object(a.jsxs)(r.a,{children:[Object(a.jsx)("title",{withBreadcrumb:!0,children:"Elector"}),Object(a.jsx)("link",{rel:"icon",href:"/favicon.ico"})]}),Object(a.jsx)("div",{style:{display:"grid",gridTemplateColumns:"repeat(2, 1fr)",marginBottom:20},children:h.map(((e,n)=>{var i;return Object(a.jsxs)("div",{children:[Object(a.jsx)("img",{width:"100%",src:c.replace("{index}",e)}),Object(a.jsxs)("div",{style:{textAlign:"center"},children:[Object(a.jsxs)("strong",{children:["#",e," (",null!==(i=t[e])&&void 0!==i?i:"?",")"]}),["+1","0","-1"].map(((e,t)=>Object(a.jsxs)("label",{children:[Object(a.jsx)("input",{onChange:()=>{m((e=>e.map(((e,a)=>a===n?1-t:e))))},checked:p[n]===1-t,type:"radio",name:n})," ",e]},t)))]})]},e)}))}),Object(a.jsx)("button",{onClick:()=>{o((e=>e.map(((e,n)=>{const t=h.findIndex((e=>e===n));return-1===t?e:e+p[t]})))),m(Array(4).fill(0)),setTimeout((()=>d(g())),50)},children:"NEXT"}),Object(a.jsxs)("div",{children:[Object(a.jsx)("h2",{children:"scoreboard"}),Object(a.jsx)("ul",{children:t.map(((e,n)=>[e,n])).filter((e=>null!==e[0])).sort(((e,n)=>n[0]-e[0])).map((([e,n])=>Object(a.jsxs)("li",{children:["#",n,": ",String(e)]},n)))})]})]})})}},vLLl:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Yellow fibers"\nthumbnail: /images/plots/115.jpg\ntags:\n  - fibers\n---\n\nThis is a continuation of exploration started at [plot#112](/plots/112).\nHad a great try of ink "Amber" by Diamine. Fountain pens on A4 bristol card.\n'},wBBG:function(e,n,t){"use strict";t.r(n),n.default=""},wLwo:function(e,n,t){"use strict";t.r(n),n.default=""},wdUm:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: \'Qep2.: Deferred objects, Qimage\'\ndescription: \'This second article on Q will introduce you how to easily turn a callback API into a promise API using Deferred objects. It will also present the new W3C specification of Promise and finish with the implementation of Qimage, a simple Image Promise wrapper.\'\nthumbnail: /images/2013/07/qimage_then_thumbnail.jpg\nauthor: Gaetan\nlayout: post\ntags:\n - AWOP\n - javascript\n - promise\n - Q\n - library\n---\n\n[0]: /pages/a-world-of-promises/\n[1]: http://github.com/kriskowal/q\n[2]: http://github.com/gre/qimage\n[3]: http://wiki.commonjs.org/wiki/Promises/A\n[4]: http://dom.spec.whatwg.org/#promises\n[5]: http://wiki.commonjs.org/wiki/Promises/B\n[6]: http://wiki.commonjs.org/wiki/Promises/D\n[7]: https://npmjs.org/package/qimage\n\n# A [World Of Promises][0], episode 2\n\n<img src="/images/2013/07/qimage_then_thumbnail.jpg" alt="" class="thumbnail-right" style="width: 200px" />\n\n*This second article on [Q][1] will introduce you how to easily \nturn a callback API into a promise API using Deferred objects.\nIt will also present the new W3C specification of Promise and finish\nwith the implementation of [Qimage][2], a simple Image Promise wrapper.*\n\n\x3c!--more--\x3e\n\n## Deferred objects\n\n[Q][1] splits the concept of Promise in two parts: one part is the **Deferred object**, another is the **Promise object**.\n\nA **Deferred object** is an object which just aims to control the state of a Promise.\nIt allows to do one of the two following actions (one time only):\n\n* `.resolve(value)`: moving from *pending* to ***fulfilled* with a value**.\n* `.reject(error)`: moving from *pending* to ***rejected* with an error**.\n\n<img src="/images/2013/07/promise.png" style="max-width: 300px; width: 100%" />\n\nA **Promise object** can be obtained from a Deferred object via the `promise` field.\nIn [Q][1], a Promise is **read-only**: you can basically only do `.then` with it \nand there is no such `resolve` or `reject` method on a Promise.\n\n > a Deferred is "resolvable", a Promise is "thenable".\n\n***N.B.***: *this separation also exists in other languages but with different names (for instance in Scala: Promise / Future).*\n\n### `Q.defer()`\n\nThe method Q.defer() will return a new **Deferred object** initialized in a *pending* state.\n\n```javascript\nvar d = Q.defer();\nsetTimeout(function () {\n  d.resolve(42);\n}, 500);\nvar promise = d.promise;\n// ...\npromise.then(function (value) {\n  console.log("the universe = "+value);\n});\n```\n\nNote that the [Promises/A][3] spec only specifies the concept of **Promise**.\nIt does not defines the "Deferred" part.\nUp to the Promise library to implement its own way of resolving / rejecting the value of a Promise.\n\nThere is also [Promises/B][5] and [Promises/D][6] to define that though.\n\n### About the DOM.Promise specification\n\na [new DOM specification draft][4] has born recently and is a bit different from the Q style,\nthe "Deferred" object (called a **Resolver**) is given as an argument of the function given at Promise instanciation.\n\n```javascript\nvar promise = new /*DOM.*/Promise(function (resolver) {\n  setTimeout(function () {\n    resolver.resolve(42);\n  }, 500);\n});\npromise.then(function (value) {\n  console.log("the universe = "+value);\n});\n```\n\n## Qimage: Wrapping the Image API\n\nWe will now show you how to easily **wrap the DOM Image API into a Promise API with Q**.\nBefore showing the implementation, let\'s explore the possibilities of such API.\n\n**`Qimage (url: String) => Promise[DOM Image]`**\n\nHere is how we want our `Qimage` API to look like:\n\n```javascript\nvar promise = Qimage("http://imagesource.com/image.png");\npromise.then(function (image) {\n  // image instanceof Image\n}, function (error) {\n  // error instanceof Error\n});\n```\n\nWe can use it like this:\n\n```javascript\nQimage("images/foo.png").then(function (img) {\n  document.body.appendChild(img);\n}, function (error) {\n  document.body.innerHTML = "Unable to load the image";\n});\n```\n\nNow we define `Qimage` as a Promise library, **we can then use all the power of Promises,\ncombine Promises together, chain different Promise APIs**...\n\n```javascript\nQ.all([\n  Qimage("res1.png"),\n  Qimage("res2.png"),\n  Qimage("res3.png")\n])\n.spread(function (res1, res2, res3) {\n  document.body.appendChild(res1);\n  document.body.appendChild(res2);\n  document.body.appendChild(res3);\n});\n```\n\nThis wrapper makes a simple but powerful Image Loading library module.\n\n### Implementation\n\nHere is how `Qimage` works:\n\n```javascript\nvar Qimage = function (url) {\n  var d = Q.defer();\n  var img = new Image();\n  img.onload = function () {\n    d.resolve(img);\n  };\n  img.onabort = function (e) {\n    d.reject(e);\n  };\n  img.onerror = function (err) {\n    d.reject(err);\n  };\n  img.src = url;\n  return d.promise;\n};\n```\n\n...and that\'s it!\n\nNote that **the Deferred object is isolated** in the `Qimage` function scope.\n\nOnly the (read-only) Promise is accessible from the outside when returned by the function.\n\n**How simple is wrapping a callback API into a Promise API!**\n\n---\n\n[Qimage][2] is released as a micro-lib and available on [Github][2] and [NPM][7].\n\n## Next episode\n\nNext episode will feature **`requestAnimationFrame`**, \n*a fundamental function generally used for performing efficient Javascript animations*.\nWe will show you **QanimationFrame** and how we can use it as a **Promisified "wait for DOM to be ready" API**.\n\n'},wfFZ:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: Be careful with JS numbers!\ndescription: Javascript doesn\u2019t have integer type but lets you think it has. In Javascript, all numbers are floating numbers and are prone to floating point approximation.\nauthor: Gaetan\nlayout: post\npermalink: /2013/01/be-careful-with-js-numbers/\ntags:\n  - float\n  - javascript\n---\n\n [3]: http://wtfjs.com/\n [4]: https://en.wikipedia.org/wiki/Floating_point\n [6]: http://news.ycombinator.com/item?id=5051525\n [7]: http://silentmatt.com/biginteger/\n\n<blockquote class="twitter-tweet" lang="fr"><p>@<a href="https://twitter.com/greweb">greweb</a> : Let\'s do a kickstarter to build the 1st space rocket running on embedded Javascript... I think we can discover new physics rules!</p>&mdash; mandubian (@mandubian) <a href="https://twitter.com/mandubian/status/289422662101504000">10 janvier 2013</a></blockquote>\n\nIt is [common][3] in Javascript to have unexpected behaviors, but this one is particulary vicious.\n\n> 10000000000000000 === 10000000000000001\n\n**Javascript doesn\u2019t have integer type but lets you think it has.** `parseInt` and `parseFloat` built-in functions, the fact that \u201c1\u2033 is displayed as \u201c1\u2033 and not as \u201c1.0\u2033 (like many languages) contribute to the general misunderstood.\n\n**In Javascript, all numbers are floating numbers and are prone to [floating point approximation][4].**\n\nWhen you write `var i = 1;`, and you console.log it, Javascript is nice, you obtain `1` and not `1.0000000000000001`. \n\nBut you can experiment that, in Javascript, `1.0000000000000001 === 1` is true\u2026\n\n> I hear you, telling me that *this sounds OK, floating point approximation rules, right?*\n\nBut the same thing occurs for big numbers:\n\n```javascript\n10000000000000000 === 10000000000000001\n```\n\nOh **F\\*\\*K** !\n\n[edit] where in python:  \n![](https://pbs.twimg.com/media/BAg2wRyCIAAGuXW.png:large)\n\n## Termination of loops\n\nThe following is worse:\n\n<script src="https://gist.github.com/4504986.js"><\/script>\n\nis logging `10000000000000000` forever!\n\nBecause 10000000000000001 can\u2019t exist in Javascript with approximations, 10000000000000001 is 10000000000000000, so you can\u2019t increment this value, and you are stuck in this crazy f\\*\\*king loop. \n\nConclusion, *Program termination proof* sounds hard to reach in Javascript!\n\n\x3c!--more--\x3e\n\n## How many numbers in a 1000 range?\n\nBetween 10000000000000000 and 10000000000001000, there are actually 750 Javascript integers.\n\n<script src="https://gist.github.com/4505510.js"><\/script>\n\n## Real World Example\n\nThe issue can actually **lead to real web application disaster**. Imagine if your database use Long for id (well like almost every databases in the world, like twitter does), and **if you use the id as number in Javascript and not as string**, you can have strange behaviors like never being able to represent and access a resource from the Javascript or worse!\n\n<script src="https://gist.github.com/4505517.js"><\/script>\n\n## TL;DR. The lesson\n\nThis is not something new, floating point approximation, but the way Javascript fix values to round the approximations mislead us.\n\nNow, simple thing, **Avoid numbers when approximation is not permitted** like for resource id (especially when you retrieve it from a server).\n\nThis probably impacts your JSON APIs because it\u2019s the last thing you had think of!\n\nOtherwise, **if you need to manipulate big integers in Javascript use a library for that**.\n\nExample: [http://silentmatt.com/biginteger/][7]\n\n[EDIT]  \n9007199254740993 (which is 2^53 1) is the smallest not representable integer in Javascript. In other words, you can trust Javascript numbers before this integer!\n\n[EDIT 2]  \n[Thanks to 0\xd70 on HackerNews][6] who told me the twitter id issue example really happened in a previous twitter API: \n'},xNY0:function(e,n,t){"use strict";t.r(n),n.default=""},xgUO:function(e,n,t){"use strict";t.r(n),n.default=""},xi4s:function(e,n,t){"use strict";t.r(n),n.default=""},yCvz:function(e,n,t){"use strict";t.r(n),n.default=""},yF2V:function(e,n,t){"use strict";t.r(n),n.default=""},yJmW:function(e,n,t){"use strict";t.r(n),n.default=""},yMwX:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle:  Relay, scrolling connections\ndescription: implement a component handling the scroll of a list to pull more data of a Graphql Connection with Relay\nauthor: Gaetan\nlayout: post\ntags:\n  - react\n  - relay\n---\n\n[Relay]: https://github.com/facebook/relay\n[Relay-spec]: https://facebook.github.io/relay/docs/graphql-relay-specification.html#content\n\n\n[Relay][Relay] doesn\'t solve for you how you should render your components. Relay is "universal" and doesn\'t even assume it will be running in a browser context. It focuses only on providing an abstraction to work with GraphQL \u2013 the same way React focuses only on rendering. Each library solves one single problem at a time *(and hell, both are complex enough problem to solve already)*.\n\nBecause these libraries are very generic, it\'s now up to the community to solve the "more specific" parts. Just search on NPM and you can find tons of React libraries already, some might help you to solve part of the problem you want to solve.\n\nThis article demonstrates one use-case: **implementing a component handling the scroll of a list to pull more data** of a GraphQL connection with Relay.\n\n\x3c!--more--\x3e\n\n## Usage\n\nIn React you should think in term of components that subdivide individual task to solve. To solve scrolling a connection you should just need this:\n\n```js\n<InfiniteScrollable relay={relay}>\n  ...\n</InfiniteScrollable>\n```\n\nHere is a real use-case we have at [projectseptember](https://projectseptember.com).\n\n\n```js\nimport React, {\n  Component,\n  PropTypes,\n} from "react";\nimport Relay from "react-relay";\nimport List from "material-ui/List";\nimport Content from "./Content";\n\nclass ContentStream extends Component {\n  static propTypes = {\n    relay: PropTypes.object.isRequired,\n    user: PropTypes.object,\n  };\n  render () {\n    const { user, relay } = this.props;\n    return (\n      <InfiniteScrollable relay={relay}>\n        <List>\n          {user.stream.edges.map(e =>\n            <Content content={e.node} key={e.cursor} />\n          )}\n        </List>\n      </InfiniteScrollable>\n    );\n  }\n}\n\nexport default Relay.createContainer(ContentStream, {\n  initialVariables: {\n    first: 50,\n  },\n  fragments: {\n    user: () => Relay.QL`\nfragment on User {\n  stream (first:$first) {\n    edges {\n      cursor\n      node {\n        ${Content.getFragment("content")}\n      }\n    }\n  }\n}\n    `\n  }\n});\n```\n\nWe don\'t have to express how to "pull for more data" in that code. In fact, this is delegated to `InfiniteScrollable` and we never have to think again about it.\n\n\n## InfiniteScrollable implementation\n\nRelay enforces to implement [a subset of GraphQL spec](https://facebook.github.io/relay/docs/graphql-relay-specification.html#content), like the Connection API. It\'s a good thing because we can also rely on this fact, and what we only need is the `relay` object to implement a generic pull-on-scroll.\n\n\n```js\nimport {\n  Component,\n  PropTypes,\n} from "react";\nimport {findDOMNode} from "react-dom";\n\nconst regex = /(auto|scroll)/;\n\nconst style = (node, prop) =>\n  getComputedStyle(node, null).getPropertyValue(prop);\n\nconst scroll = (node) =>\n  regex.test(\n    style(node, "overflow") +\n    style(node, "overflow-y") +\n    style(node, "overflow-x"));\n\nconst scrollparent = (node) =>\n  !node || node===document.body\n  ? document.body\n  : scroll(node)\n    ? node\n    : scrollparent(node.parentNode);\n\nconst resizeEventOn = n => n===document.body ? window : n;\n\nexport default class InfiniteScrollable extends Component {\n  static propTypes = {\n    children: PropTypes.any.isRequired,\n    relay: PropTypes.object,\n    style: PropTypes.object,\n    loadPixelsInAdvance: PropTypes.number,\n    relayVariable: PropTypes.string,\n    chunkSize: PropTypes.number,\n    // loadMore could even be generalize, this component works if you provide loadMore instead of relay\n    loadMore: PropTypes.func, // (can) returns a promise\n  };\n  static defaultProps = {\n    loadPixelsInAdvance: 1000,\n    relayVariable: "first",\n    chunkSize: 50,\n  };\n\n  state = { loading: false };\n\n  resizeBoundOnDom = null;\n\n  componentDidMount () {\n    this.syncScrollBodyListener(this.props);\n    this.checkScroll();\n  }\n\n  componentWillUnmount () {\n    this.unbindResizeEvent();\n  }\n\n  componentDidUpdate () {\n    this.syncScrollBodyListener();\n  }\n\n  unbindResizeEvent () {\n    if (this.resizeBoundOnDom) {\n      this.resizeBoundOnDom.removeEventListener("scroll", this.checkScroll);\n      this.resizeBoundOnDom = null;\n    }\n  }\n\n  getScrollParent () {\n    return scrollparent(findDOMNode(this));\n  }\n\n  syncScrollBodyListener = () => {\n    const resizeBoundOnDom = resizeEventOn(this.getScrollParent());\n    if (resizeBoundOnDom !== this.resizeBoundOnDom) {\n      this.unbindResizeEvent();\n      resizeBoundOnDom.addEventListener("scroll", this.checkScroll);\n    }\n  };\n\n  loadMoreUsingRelay = () => {\n    const { relay, relayVariable, chunkSize } = this.props;\n    return new Promise((resolve, reject) =>\n     relay.setVariables({\n       [relayVariable]: relay.variables[relayVariable] + chunkSize\n     }, readyState => {\n       if (readyState.error) reject(readyState.error);\n       if (readyState.done) resolve();\n     }));\n  };\n\n  checkScroll = () => {\n    if (this.state.loading) return;\n    const container = this.getScrollParent();\n    if (!container) return;\n    const { height } = container.getBoundingClientRect();\n    const { scrollHeight, scrollTop } = container;\n    const bottom = scrollTop + height;\n    const { loadPixelsInAdvance } = this.props;\n    const advance = bottom - scrollHeight + loadPixelsInAdvance;\n    if (advance > 0) {\n      this.setState({ loading: true }, () =>\n        Promise.resolve({ advance, bottom, scrollHeight, height, scrollTop, loadPixelsInAdvance })\n        .then(this.props.loadMore || this.loadMoreUsingRelay)\n        .then(\n          () => this.setState({ loading: false }), // technically could recall checkScroll here. in second callback of setState. fork it, try it, adapt it !\n          e => (console.warn(e), this.setState({ loading: false }))\n        ));\n    }\n  };\n\n  render () {\n    // you might want to render a spinner?\n    // children might be a function?\n    // etc..\n    // these are some variations we could have from this starting point\n    return this.props.children;\n  }\n}\n```\n\n\nThis is a **possible implementation** of this problem. You might want to add more things based on your needs. For instance you could automatically render a loading spinner... or a million other things! Please try it, fork it, give feedback :)\n\nIt is also possible to implement it as a High Order Component (HOC): [https://github.com/facebook/relay/issues/1377](https://github.com/facebook/relay/issues/1377).\n'},yPMl:function(e,n,t){var a={"./2010-02-03-tutoriel-canvas-realiser-une-banniere-animee-en-quelques-lignes-de-code.md":"BHSx","./2010-02-20-the-same-game-in-html5-canvas.md":"c8aL","./2010-03-14-sass-levolution-du-css.md":"Ogqt","./2010-04-03-realiser-une-maquette-web-avec-le-css-3.md":"h8Le","./2010-04-04-automatiser-lexportation-dun-site-statique-avec-wget.md":"PjKD","./2010-05-05-css3-transitions-available-on-firefox-3-7.md":"6Q0G","./2011-01-05-how-to-make-dlink-dwa-140-perfectly-work-on-linux.md":"grKd","./2011-03-12-html-canvas-pour-les-neophytes.md":"k1ej","./2011-04-24-releasing-same-game-gravity-android.md":"nlun","./2011-06-01-automating-web-app-development-for-multiple-platforms.md":"side","./2011-07-12-same-game-gravity-for-ipad-iphone-android-facebook-chrome-and-web.md":"vDz1","./2011-07-12-same-game-gravity-technical-notes.md":"2VMy","./2011-07-30-improve-your-web-navigation-experience-flexible-nav-jquery-library.md":"3SEp","./2011-10-15-how-to-deploy-your-play-applications-on-archlinux-with-daemons.md":"pPTr","./2012-02-04-css-selector-based-templating-example-with-javascript.md":"ieJe","./2012-02-29-bezier-curve-based-easing-functions-from-concept-to-implementation.md":"niBl","./2012-03-06-chart-libraries-headaches-finding-the-best-grid-step.md":"etif","./2012-03-12-30-minutes-to-make-a-multi-user-real-time-paint-with-play-2-framework-canvas-and-websocket.md":"p5BC","./2012-03-17-play-painter-how-ive-improved-the-30-minutes-prototyped-version.md":"kHt+","./2012-04-09-blender-as-a-2d-game-map-editor-proof-of-concept.md":"96bJ","./2012-04-26-work-in-progress.md":"DpoN","./2012-05-03-html5-canvas-as-a-color-converter.md":"ufYd","./2012-05-10-illuminated-js-2d-lights-and-shadows-rendering-engine-for-html5-applications.md":"2bZF","./2012-05-12-minimize-your-javascript-files-with-curl.md":"4EJ6","./2012-07-03-how-i-learned-backbone-js-three-js-glsl-in-one-week.md":"uWG4","./2012-08-01-zound-a-playframework-2-audio-streaming-experiment-using-iteratees.md":"jxws","./2012-11-12-play-framework-enumerator-outputstream.md":"cPD4","./2013-01-10-be-careful-with-js-numbers.md":"wfFZ","./2013-01-30-playcli-play-iteratees-unix-pipe.md":"91iZ","./2013-02-11-glsl-js-a-javascript-glsl-library-dry-efficient.md":"1UPy","./2013-05-07-playframework-simple-deployment-scripts.md":"pjVY","./2013-07-10-q-a-promise-library.md":"jCcY","./2013-07-13-deferred.md":"wdUm","./2013-07-17-QanimationFrame.md":"eFEr","./2013-07-30-zound-live.md":"Sb+6","./2013-08-05-zanimo.md":"dAja","./2013-08-08-zound-wip-v1.md":"qLlP","./2013-08-21-FM-audio-api.md":"ZKtb","./2013-09-04-beez.md":"KHjv","./2013-09-17-timelapse.md":"Pfac","./2013-09-28-webaudioapi.md":"NvIL","./2013-11-12-functional-rendering.md":"mzFX","./2014-01-12-promisify-your-games.md":"/vfr","./2014-03-12-panzer-dragoon-1k.md":"0mXd","./2014-05-04-ld29.md":"KKCg","./2014-09-14-ibex.md":"iF92","./2014-09-22-ibex-cellular-automata.md":"DoYn","./2014-10-16-webglparis.md":"G+m4","./2015-08-04-making-performant-react-applications.md":"Myxv","./2015-10-01-introducing-gl-react.md":"XWFM","./2016-06-19-glreactconf.md":"VV7m","./2016-07-01-projectseptember-opengl.md":"CybH","./2016-09-19-relay-scrolling-connections.md":"yMwX","./2016-12-03-gl-react-v3.md":"BF22","./2021-04-08-cryptoaliens.md":"cckB","./2021-04-09-cryptoaliens-tech.md":"DsvB","./2021-05-01-plot-loops.md":"gTYa","./2021-05-03-relics.md":"R4Of"};function i(e){var n=o(e);return t(n)}function o(e){if(!t.o(a,e)){var n=new Error("Cannot find module '"+e+"'");throw n.code="MODULE_NOT_FOUND",n}return a[e]}i.keys=function(){return Object.keys(a)},i.resolve=o,e.exports=i,i.id="yPMl"},yQP0:function(e,n,t){"use strict";t.r(n),n.default="---\ntweet: https://twitter.com/greweb/status/1381669604737552386\ntags:\n  - planet-holes\n---\n"},yVRA:function(e,n,t){"use strict";t.r(n),n.default="---\ntweet: https://twitter.com/greweb/status/1382252141952303106\ntags:\n  - planet-holes\n---\n"},z6oG:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Clothes"\nthumbnail: /images/plots/109.jpg\ntags:\n  - fibers\n---\n\nThis is a continuation of exploration started at [plot#107](/plots/107), but this time alternating between horizontal and vertical lines. As before, it uses a tiny bit of perlin noise to diverge a bit the lines. The randomness distribution has been customized to approach more the edges.\n\nI switched to fountain pen for better precision. Only using one ink... But what an ink! _"Bloody Brexit" by Diamine._\n\n<img src="/images/plots/bloodybrexit.jpg" width="100%" />\n'},zAwM:function(e,n,t){"use strict";var a=t("NdRM");e.exports=new a("tag:yaml.org,2002:js/undefined",{kind:"scalar",resolve:function(){return!0},construct:function(){},predicate:function(e){return"undefined"===typeof e},represent:function(){return""}})},zEwe:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Parametric shield"\nthumbnail: "/images/plots/126.jpg"\ndescription: "yet another parametric spiral perturbated by perlin noise!"\ntags:\n  - parametric\n  - perlin\n---\n\nyet another parametric spiral perturbated by perlin noise!\n'},zWTV:function(e,n,t){"use strict";t.r(n),n.default=""},zYy3:function(e,n,t){"use strict";t.r(n),n.default=""},zaAt:function(e,n,t){"use strict";t.r(n),n.default='---\ntitle: "Perlin mountains"\nthumbnail: /images/plots/108.jpg\nobjkts:\n  - 36604\nplotterfiles:\n  - https://plotterfiles.com/profile/files/5e43a751-6fef-4abc-a92d-253fe5c890c8\ntags:\n  - perlin\n  - mountains\n---\n\n<img width="100%" src="/images/plots/108.gif" />\n\nIt took me 107 previous days of plotting to come up with an elegant idea: searching the best plot among many different variants can easily be done by working instead on a video of that plot! Then you can chose a frame to plot, it is both practical as well as you get a nice animation for free!\n\nSome code snippet for video generation.\n\n```bash\n# generate all .svg in results, then:\ncd results\nmkdir pngs\nfor f in *.svg; do convert $f pngs/${f%.*}.png; done\nffmpeg -r 24 -i pngs/%d.png -pix_fmt yuv420p -vf "pad=ceil(iw/2)*2:ceil(ih/2)*2" out.mp4\n```\n'}},[["iyOL",0,1,6,2,3,4,5]]]);